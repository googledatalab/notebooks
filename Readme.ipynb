{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to Google Cloud Datalab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks for using [Google Cloud Datalab](https://cloud.google.com/datalab)!\n",
    "\n",
    "This notebook serves as your guide to the documentation and samples that accompany Datalab. It describes how you can use interactive notebooks, Python, and BigQuery SQL to explore, visualize, analyze and transform your data within the [Google Cloud Platform](https://cloud.google.com).\n",
    "\n",
    "As an aside, you'll notice that this content, itself, is distributed in notebook form - very much like the ones you can use to make your data analysis iterative, self-documenting, and shareable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Please browse through the following notebooks for a basic orientation to Datalab and how it works.\n",
    "\n",
    "* [**Introduction to Notebooks**](./intro/Introduction to Notebooks.ipynb) - introduces the interactive notebook metaphor and how it works in the Datalab environment.\n",
    "\n",
    "\n",
    "* [**Introduction to Python**](./intro/Introduction to Python.ipynb) - Python is essential to working in Datalab. This notebook provides a quick overview of the Python environment with links to online, in-depth language tutorials (if you're new to Python).\n",
    "\n",
    "\n",
    "* [**Using Datalab - Accessing Cloud Data**](./intro/Using Datalab - Accessing Cloud Data.ipynb) - This notebook briefly describes the Datalab environment, including how the Datalab workspace is configured as well as important information about authorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorials\n",
    "\n",
    "This set of notebooks describes using the product and its set of features, including the tools and Python APIs that you can use within notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google BigQuery\n",
    "\n",
    "* [**Hello BigQuery**](./tutorials/BigQuery/Hello BigQuery.ipynb) - Datalab puts Google BigQuery at your fingertips. For the most basic example, start here.\n",
    "\n",
    "\n",
    "* [**BigQuery Commands**](./tutorials/BigQuery/BigQuery Commands.ipynb) - Use simple, declarative commands to do everything, from exploring to interactively analyzing, transforming, and visualizing your data.\n",
    "\n",
    "\n",
    "* [**BigQuery Magic Commands and DML**](./tutorials/BigQuery/BigQuery Magic Commands and DML.ipynb) - Use features of [BigQuery Standard SQL](https://cloud.google.com/bigquery/docs/reference/standard-sql//) and [BigQuery SQL Data Manipulation Language (beta)](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language).\n",
    "\n",
    "\n",
    "* [**BigQuery APIs**](./tutorials/BigQuery/BigQuery APIs.ipynb) - Use an extensive and intuitive library of Python APIs, designed with notebooks in mind, to query data and work with BigQuery objects, such as DataSets, Tables and Schemas.\n",
    "\n",
    "\n",
    "* [**BigQuery Parameterization**](./tutorials/BigQuery/BigQuery Parameterization.ipynb) - Use parameter syntax to define re-usable and customizable SQL queries.\n",
    "\n",
    "\n",
    "* [**SQL and Pandas DataFrames**](./tutorials/BigQuery/SQL and Pandas DataFrames.ipynb) - Use BigQuery SQL together with Python data analysis libraries, such as pandas.\n",
    "\n",
    "\n",
    "* [**SQL Query Composition**](./tutorials/BigQuery/SQL Query Composition.ipynb) - Use nested SQL statements and big joins to harness the full power of BigQuery, building these one step at a time.\n",
    "\n",
    "\n",
    "* [**Importing and Exporting Data**](./tutorials/BigQuery/Importing and Exporting Data.ipynb) - Use declarative commands or APIs to get data in and out of BigQuery.\n",
    "\n",
    "\n",
    "* [**UDFs in BigQuery**](./tutorials/BigQuery/UDFs in BigQuery.ipynb) - An introduction to using UDFs (user-defined functions) to perform custom transformations not possible through plain SQL.\n",
    "\n",
    "\n",
    "* [**UDF Testing in the Notebook**](./tutorials/BigQuery/UDF Testing in the Notebook.ipynb) - How to test UDF functions in the notebook using Javascript code cells.\n",
    "\n",
    "\n",
    "* [**UDFs using Code in Cloud Storage**](./tutorials/BigQuery/UDFs using Code in Cloud Storage.ipynb) - How to share common code used by UDFs by moving it to Javascript files in Cloud Storage.\n",
    "\n",
    "\n",
    "* [**Using External Tables from BigQuery**](./tutorials/BigQuery/Using External Tables from BigQuery.ipynb) - How to query CSV and JSON files stored in Cloud Storage directly from BigQuery SQL without loading them into BigQuery tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage\n",
    "\n",
    "* [**Storage Commands**](./tutorials/Storage/Storage Commands.ipynb) - Use simple, declarative commands to quickly manage your Cloud Storage objects.\n",
    "\n",
    "\n",
    "* [**Storage APIs**](./tutorials/Storage/Storage APIs.ipynb) - Use the equivalent Python APIs, designed with notebooks in mind, to read and write data to Google Cloud Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stackdriver Monitoring\n",
    "\n",
    "The tutorials for this module use a sample project. This project is not readable by everyone. In order to execute the tutorials, you will have to set a default project, and make sure that it has at least one GCE Instance.\n",
    "* [**Getting Started**](./tutorials/Stackdriver Monitoring/Getting started.ipynb) - Datalab allows you to access and analyze the monitoring data. For an overview of how to access the time series data, start here.\n",
    "\n",
    "\n",
    "* [**Group Metrics**](./tutorials/Stackdriver Monitoring/Group metrics.ipynb) - How to list Stackdriver groups, and query time series data for a given group.\n",
    "\n",
    "\n",
    "* [**Time-shifted Data**](./tutorials/Stackdriver Monitoring/Time-shifted data.ipynb) - How to compare today's metric data against the past week by time-shifting the time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "* [**Interactive Charts with Google Charting APIs**](./tutorials/Data/Interactive Charts with Google Charting APIs.ipynb) - Google Charts provide a rich selection of interactive charts, rendered on the client using JavaScript and SVG. In addition to standard charts, such as bar charts, line charts, and pie charts, this notebook provides map viewers, time-series viewers, sankey diagrams, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples\n",
    "\n",
    "This set of notebooks builds on the techniques and concepts illustrated in the documentation, and puts them to practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "* [**Basic RNN TensorFlow Model Trained on Simulated Data**](./samples/TensorFlow/Basic RNN TensorFlow Model Trained on Simulated Data.ipynb) - demonstrates how to build a basic RNN TensorFlow model to predict time series data.\n",
    "\n",
    "\n",
    "* [**LSTM Punctuation Model With TensorFlow**](./samples/TensorFlow/LSTM Punctuation Model With TensorFlow.ipynb) - demonstrates using TensorFlow to build a LSTM model that can predict punctuations given text.\n",
    "\n",
    "\n",
    "* [**Image-to-Captions Model with TensorFlow**](./samples/TensorFlow/Image-to-Captions Model with TensorFlow.ipynb) - demonstrates using TensorFlow to build an image to text model which can generate captions given images.\n",
    "\n",
    "\n",
    "* [**Machine Learning with Financial Data**](./samples/TensorFlow/Machine Learning with Financial Data.ipynb) - demonstrates an accessible, non-trivial example of machine learning with financial time series on Google Cloud Platform (GCP).\n",
    "\n",
    "\n",
    "* [**Text Classification with TensorFlow**](./samples/TensorFlow/Text Classification with TensorFlow.ipynb) - demonstrates two models built with TensorFlow to do text classifications on 20 newsgroup data. One is feed-forward and the other is recurrent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLToolbox\n",
    "\n",
    "* [**Machine Learning with MLToolbox: Iris (Classification)**](./samples/ML Toolbox/Classification/Iris) - demonstrates Google Cloud Datalab structured data package for building and running a Tensorflow classification model locally.\n",
    "\n",
    "\n",
    "* [**Machine Learning with MLToolbox: Census (Regression)**](./samples/ML Toolbox/Regression/Census) - demonstrates building a model to predict income using US census data using Google Cloud Datalab structured data package, both locally and in cloud.\n",
    "\n",
    "\n",
    "* [**Machine Learning with MLToolbox: Flower (Image Classification)**](./samples/ML Toolbox/Image Classification/Flower) - demonstrates building a model to classify 5 types of flowers with Google Cloud Datalab image classification package, both locally and in cloud, using about 3000 images.\n",
    "\n",
    "\n",
    "* [**Machine Learning with MLToolbox: Coast (Image Classification)**](./samples/ML Toolbox/Image Classification/Coast) - demonstrates building a model to classify 18 types of coastlines with Google Cloud Datalab image classification package, both locally and in cloud, using about 10000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigQuery\n",
    "\n",
    "* [**Anomaly Detection in HTTP Logs**](./samples/Anomaly Detection in HTTP Logs.ipynb) - demonstrates using SQL to convert raw HTTP logs stored in BigQuery into a time-series that can be used for detecting anomalies in a web application.\n",
    "\n",
    "\n",
    "* [**Conversion Analysis with Google Analytics Data.ipynb**](./samples/Conversion Analysis with Google Analytics Data.ipynb) - demonstrates using custom analysis and visualization over analytics telemetry data exported into BigQuery.\n",
    "\n",
    "\n",
    "* [**Programming Language Correlation**](./samples/Programming Language Correlation.ipynb) - demonstrates using the combination of SQL and Python data analysis using pandas to determine how programming languages correlate (or not) by tapping into OSS developer activity at GitHub.\n",
    "\n",
    "\n",
    "* [**Exploring Genomics Data**](./samples/Exploring Genomics Data.ipynb) - demostrates browsing and understanding gene data provided in the form of publicly accessible BigQuery data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Updating Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datalab documentation is distributed as notebooks which are automatically updated at time of installation. In order to update, please save all open notebooks, close the running sessions, then re-run the installation script. It will pull the latest notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Committing and Refreshing\n",
    "\n",
    "Once you have updated the local copy of the documents, you can commit them within the git repository.\n",
    "\n",
    "Next, make sure to refresh your notebooks to load the latest and updated documents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
