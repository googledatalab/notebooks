{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"about\"></a>\n",
    "About this notebook\n",
    "======\n",
    "\n",
    "This notebook assumes you have ran the local Census Regression notebook and you have not deleted the LOCAL_ROOT folder. In this notebook, we will use batch prediction on a pre-trained Tensorflow model on CloudML. This notebook will does not assume that the notebook \"4. Census Regression Cloud Prediction\" was executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "Setting things up\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datalab_solutions.structured_data as sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the versions of structured_data and TF we have. Make sure TF is 1.0.0, and SD is 0.0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf 1.0.0\n",
      "sd 0.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "import datalab.mlalpha as mlalpha\n",
    "\n",
    "print('tf ' + str(tf.__version__))\n",
    "print('sd ' + str(sd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will write files during preprocessing, training, and prediction. Please give a root folder you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://cloud-ml-dev-census-regression-datalab/...\n",
      "ServiceException: 409 Bucket cloud-ml-dev-census-regression-datalab already exists.\n"
     ]
    }
   ],
   "source": [
    "LOCAL_ROOT = './census_regression_workspace' # This should be the same as what was used in the local census notebook\n",
    "CLOUD_ROOT = 'gs://' + datalab_project_id() + '-census-regression-datalab'\n",
    "\n",
    "if not file_io.file_exists(LOCAL_ROOT):\n",
    "  raise ValueErro('LOCAL_ROOT not found. Did you run the local notebook?')\n",
    "!gsutil mb {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us put the csv files on GCS and the output of preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./census_regression_workspace/train_data.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/predict_data.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/eval_data.csv [Content-Type=text/csv]...\n",
      "/ [3/3 files][200.1 KiB/200.1 KiB] 100% Done                                    \n",
      "Operation completed over 3 objects/200.1 KiB.                                    \n",
      "Copying file://./census_regression_workspace/training/model/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/model/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/model/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/model/assets.extra/transforms.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/model/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/assets.extra/transforms.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/graph.pbtxt [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-2000.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-1.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-2000.meta [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-2000.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/checkpoint [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/events.out.tfevents.1487873150.f5b2bd485b01 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-1.meta [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-1.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/eval/events.out.tfevents.1487873175.f5b2bd485b01 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1487873181183/assets.extra/transforms.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/eval/events.out.tfevents.1487873161.f5b2bd485b01 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1487873181183/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1487873178087/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1487873181183/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1487873181183/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1487873178087/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1487873181183/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1487873178087/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1487873178087/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1487873178087/assets.extra/transforms.json [Content-Type=application/json]...\n",
      "/ [31/31 files][ 10.5 MiB/ 10.5 MiB] 100% Done                                  \n",
      "Operation completed over 31 objects/10.5 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp {os.path.join(LOCAL_ROOT, '*_data.csv')} {CLOUD_ROOT}\n",
    "!gsutil -m cp -r {os.path.join(LOCAL_ROOT, 'training')} {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-census-regression-datalab/training/evaluation_model/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/training/model/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/training/staging/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/training/train/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {CLOUD_ROOT}/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"local_preprocessing\"></a>\n",
    "Cloudml Batch Prediction\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch prediction has two modes. In the 'evaluation' mode, the input data is expected to 100% match the training schema, meaning the target column should exist in the data. In 'prediction' mode, the input data files must match the training schema except that the target column is missing. Note that cloudml batch prediction can be slow on small datasets because it takes a while for a Dataflow job to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -r {CLOUD_ROOT}/batch_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://cloud-ml-dev-census-regression-datalab/batch_prediction/staging/sd.tar.gz\n",
      "Starting cloud batch prediction.\n",
      "gs://cloud-ml-dev-census-regression-datalab/eval_data.csv\n",
      "<type 'unicode'>\n",
      "Dataflow Job submitted, see Job structured-data-batch-prediction-20170223194250 at https://console.developers.google.com/dataflow?project=cloud-ml-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/apache_beam/coders/typecoders.py:136: UserWarning:\n",
      "\n",
      "Using fallback coder for typehint: Any.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sd.cloud_batch_predict(\n",
    "  training_ouput_dir=os.path.join(CLOUD_ROOT, 'training'),\n",
    "  prediction_input_file=os.path.join(CLOUD_ROOT, 'eval_data.csv'),\n",
    "  output_dir=str(os.path.join(CLOUD_ROOT, 'batch_prediction')),\n",
    "  mode='evaluation',\n",
    "  output_format='json'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(str(os.path.join(CLOUD_ROOT, 'batch_prediction')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When prediction is done, {CLOUD_ROOT}/batch_prediction should contain the prediction files and an errors file (that should be empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/staging/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls  {CLOUD_ROOT}/batch_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning things up\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to delete the files you made on GCS, uncomment and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!gsutil rm -fr {CLOUD_ROOT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
