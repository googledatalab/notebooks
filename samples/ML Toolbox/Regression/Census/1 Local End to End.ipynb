{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will cover the core parts of the machine learning workflow, running locally within the Google Cloud Datalab environment. Local development and validation is recommended when as a starting point, using a sample of the full dataset, to have a short development-validation cycle, and quicker iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace Setup\n",
    "\n",
    "The first step is setup the workspace for use within this notebook - the python libraries, and the local directory containing the data inputs and outputs produced over the course of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import google.datalab.ml as ml\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plot\n",
    "import mltoolbox.regression.dnn as regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local development workspace will be in `/content/datalab/workspace/census` by default.\n",
    "\n",
    "Note that the `/content/datalab` directory is physically located within the data disk mounted into the Datalab instance, but outside of the git repository containing notebooks, which makes it suitable for storing data files and generated files that are useful to keep around while you are working on a project, but do not belong in the source repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workspace_path = '/content/datalab/workspace/census'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p {workspace_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: If you have previously run this notebook, and want to start from scratch, then you run the next cell to delete and create that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf {workspace_path} && mkdir {workspace_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we will copy the data into this workspace. Generally, in your own work, you will need to create a representative sample dataset to use for local development, while leaving the full dataset to use when running on the service. For purposes of the sample, which uses a relatively small dataset, we'll copy it down in entirety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!gsutil -q cp gs://cloud-datalab-samples/census/ss14psd.csv {workspace_path}/data/census.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8000\r\n",
      "-rw-r--r-- 1 root root 8189323 Mar  7 19:07 census.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {workspace_path}/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "Its a good idea to load data and inspect it to build an understanding of the structure, as well as preparation steps that will be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8626 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>SPORDER</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>ST</th>\n",
       "      <th>ADJINC</th>\n",
       "      <th>PWGTP</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>CITWP</th>\n",
       "      <th>...</th>\n",
       "      <th>pwgtp71</th>\n",
       "      <th>pwgtp72</th>\n",
       "      <th>pwgtp73</th>\n",
       "      <th>pwgtp74</th>\n",
       "      <th>pwgtp75</th>\n",
       "      <th>pwgtp76</th>\n",
       "      <th>pwgtp77</th>\n",
       "      <th>pwgtp78</th>\n",
       "      <th>pwgtp79</th>\n",
       "      <th>pwgtp80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>25</td>\n",
       "      <td>01</td>\n",
       "      <td>00400</td>\n",
       "      <td>46</td>\n",
       "      <td>1008425</td>\n",
       "      <td>00038</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>00011</td>\n",
       "      <td>00010</td>\n",
       "      <td>00008</td>\n",
       "      <td>00032</td>\n",
       "      <td>00040</td>\n",
       "      <td>00038</td>\n",
       "      <td>00033</td>\n",
       "      <td>00040</td>\n",
       "      <td>00068</td>\n",
       "      <td>00090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>467</td>\n",
       "      <td>01</td>\n",
       "      <td>00600</td>\n",
       "      <td>46</td>\n",
       "      <td>1008425</td>\n",
       "      <td>00120</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>00119</td>\n",
       "      <td>00039</td>\n",
       "      <td>00034</td>\n",
       "      <td>00119</td>\n",
       "      <td>00125</td>\n",
       "      <td>00104</td>\n",
       "      <td>00119</td>\n",
       "      <td>00102</td>\n",
       "      <td>00184</td>\n",
       "      <td>00038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>490</td>\n",
       "      <td>01</td>\n",
       "      <td>00500</td>\n",
       "      <td>46</td>\n",
       "      <td>1008425</td>\n",
       "      <td>00172</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>00049</td>\n",
       "      <td>00045</td>\n",
       "      <td>00148</td>\n",
       "      <td>00163</td>\n",
       "      <td>00313</td>\n",
       "      <td>00174</td>\n",
       "      <td>00153</td>\n",
       "      <td>00165</td>\n",
       "      <td>00158</td>\n",
       "      <td>00126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>490</td>\n",
       "      <td>02</td>\n",
       "      <td>00500</td>\n",
       "      <td>46</td>\n",
       "      <td>1008425</td>\n",
       "      <td>00113</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>00037</td>\n",
       "      <td>00032</td>\n",
       "      <td>00107</td>\n",
       "      <td>00125</td>\n",
       "      <td>00249</td>\n",
       "      <td>00107</td>\n",
       "      <td>00105</td>\n",
       "      <td>00094</td>\n",
       "      <td>00091</td>\n",
       "      <td>00079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>676</td>\n",
       "      <td>01</td>\n",
       "      <td>00300</td>\n",
       "      <td>46</td>\n",
       "      <td>1008425</td>\n",
       "      <td>00023</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>00022</td>\n",
       "      <td>00006</td>\n",
       "      <td>00035</td>\n",
       "      <td>00030</td>\n",
       "      <td>00028</td>\n",
       "      <td>00027</td>\n",
       "      <td>00020</td>\n",
       "      <td>00042</td>\n",
       "      <td>00019</td>\n",
       "      <td>00011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RT SERIALNO SPORDER   PUMA  ST   ADJINC  PWGTP AGEP CIT CITWP   ...    \\\n",
       "0  P       25      01  00400  46  1008425  00038   85   1         ...     \n",
       "1  P      467      01  00600  46  1008425  00120   62   1         ...     \n",
       "2  P      490      01  00500  46  1008425  00172   64   1         ...     \n",
       "3  P      490      02  00500  46  1008425  00113   67   1         ...     \n",
       "4  P      676      01  00300  46  1008425  00023   89   1         ...     \n",
       "\n",
       "  pwgtp71 pwgtp72 pwgtp73 pwgtp74 pwgtp75 pwgtp76 pwgtp77 pwgtp78 pwgtp79  \\\n",
       "0   00011   00010   00008   00032   00040   00038   00033   00040   00068   \n",
       "1   00119   00039   00034   00119   00125   00104   00119   00102   00184   \n",
       "2   00049   00045   00148   00163   00313   00174   00153   00165   00158   \n",
       "3   00037   00032   00107   00125   00249   00107   00105   00094   00091   \n",
       "4   00022   00006   00035   00030   00028   00027   00020   00042   00019   \n",
       "\n",
       "  pwgtp80  \n",
       "0   00090  \n",
       "1   00038  \n",
       "2   00126  \n",
       "3   00079  \n",
       "4   00011  \n",
       "\n",
       "[5 rows x 284 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(os.path.join(workspace_path, 'data/census.csv'), dtype=str)\n",
    "print '%d rows' % len(df_data)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The census data contains a large number of columns. Only a few are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Transformations\n",
    "\n",
    "The raw census data requires a number of transformations before it is usable for machine learning:\n",
    "\n",
    "1. Apply understanding of the domain and the problem to determine which data to include or join, as well as which data to filter out if it is adding noise. In the case of census, we'll pick just a few of the many columns present in the dataset.\n",
    "2. Handle missing values, or variations in formatting.\n",
    "3. Apply other transformations in support of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code is packaged as a function that can be reused if you need to apply to future\n",
    "# datasets, esp. to prediction data, to ensure consistent transformations are applied.\n",
    "\n",
    "def transform_data(df):\n",
    "  interesting_columns = ['WAGP','SERIALNO','AGEP','COW','ESP','ESR','FOD1P','HINS4','INDP',\n",
    "                         'JWMNP', 'JWTR', 'MAR', 'POWPUMA', 'PUMA', 'RAC1P', 'SCHL',\n",
    "                         'SCIENGRLP', 'SEX', 'WKW']\n",
    "  df = df[interesting_columns]\n",
    "  \n",
    "  # Replace whitespace with NaN, and NaNs with empty string\n",
    "  df = df.replace('\\s+', np.nan, regex=True).fillna('')\n",
    "\n",
    "  # Filter out the rows without an income, i.e. there is no target value to learn from\n",
    "  df = df[df.WAGP != '']\n",
    "  df['WAGP'] = df.WAGP.astype(np.int64) / 1000.0\n",
    "\n",
    "  # Filter out rows with income values we don't care about, i.e. outliers\n",
    "  # Filter out rows with less than 10K and more than 150K\n",
    "  df = df[(df.WAGP >= 10.0) & (df.WAGP < 150.0)]\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAGP</th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>ESP</th>\n",
       "      <th>ESR</th>\n",
       "      <th>FOD1P</th>\n",
       "      <th>HINS4</th>\n",
       "      <th>INDP</th>\n",
       "      <th>JWMNP</th>\n",
       "      <th>JWTR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>POWPUMA</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WKW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>467</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2102</td>\n",
       "      <td>2</td>\n",
       "      <td>6990</td>\n",
       "      <td>015</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>00590</td>\n",
       "      <td>00600</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>490</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>8090</td>\n",
       "      <td>015</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>00590</td>\n",
       "      <td>00500</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1225</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>5301</td>\n",
       "      <td>2</td>\n",
       "      <td>9680</td>\n",
       "      <td>015</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>00100</td>\n",
       "      <td>00100</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1225</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>8680</td>\n",
       "      <td>020</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>00100</td>\n",
       "      <td>00100</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1438</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>6170</td>\n",
       "      <td>030</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>00100</td>\n",
       "      <td>00100</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    WAGP SERIALNO AGEP COW ESP ESR FOD1P HINS4  INDP JWMNP JWTR MAR POWPUMA  \\\n",
       "1   70.0      467   62   1       1  2102     2  6990   015   01   3   00590   \n",
       "2   19.0      490   64   2       1           2  8090   015   01   1   00590   \n",
       "6   70.0     1225   32   5       4  5301     2  9680   015   01   1   00100   \n",
       "7   18.0     1225   30   1       1           2  8680   020   01   1   00100   \n",
       "11  45.0     1438   55   1       1           2  6170   030   01   1   00100   \n",
       "\n",
       "     PUMA RAC1P SCHL SCIENGRLP SEX WKW  \n",
       "1   00600     1   21         2   1   1  \n",
       "2   00500     1   18             2   1  \n",
       "6   00100     1   21         2   1   1  \n",
       "7   00100     1   16             2   1  \n",
       "11  00100     1   16             1   1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = transform_data(df_data)\n",
    "print '%d rows' % len(df_data)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataSets\n",
    "\n",
    "Once the data is ready, the next step is to split data into training and evaluation datasets. In this sample, rows are split randomly in an 80/20 manner. Additionally, the schema is also saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_schema(df):\n",
    "  fields = []\n",
    "  for name, dtype in zip(df.columns, df.dtypes):\n",
    "    if dtype in (np.str, np.object):\n",
    "      fields.append({'name': name, 'type': 'STRING'})\n",
    "    elif dtype in (np.int32, np.int64, np.float32, np.float64):\n",
    "      fields.append({'name': name, 'type': 'FLOAT'})\n",
    "    else:\n",
    "      raise ValueError('Unsupported column type \"%s\" in column \"%s\"' % (str(dtype), name))\n",
    "  return fields\n",
    "\n",
    "def create_datasets(df):\n",
    "  # Numbers in the range of [0, 1)\n",
    "  random_values = np.random.rand(len(df))\n",
    "\n",
    "  # Split data into %80, 20% partitions\n",
    "  df_train = df[random_values < 0.8]\n",
    "  df_eval = df[random_values >= 0.8]\n",
    "\n",
    "  return df_train, df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_eval = create_datasets(df_data)\n",
    "schema = create_schema(df_data)\n",
    "\n",
    "training_data_path = os.path.join(workspace_path, 'data/train.csv')\n",
    "eval_data_path = os.path.join(workspace_path, 'data/eval.csv')\n",
    "schema_path = os.path.join(workspace_path, 'data/schema.json')\n",
    "\n",
    "df_train.to_csv(training_data_path, header=False, index=False)\n",
    "df_eval.to_csv(eval_data_path, header=False, index=False)\n",
    "\n",
    "with open(schema_path, 'w') as f:\n",
    "  f.write(json.dumps(schema, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8208\r\n",
      "-rw-r--r-- 1 root root 8189323 Mar  7 19:07 census.csv\r\n",
      "-rw-r--r-- 1 root root   37358 Mar  7 19:07 eval.csv\r\n",
      "-rw-r--r-- 1 root root     998 Mar  7 19:07 schema.json\r\n",
      "-rw-r--r-- 1 root root  166197 Mar  7 19:07 train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {workspace_path}/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create DataSet objects which are reference to one or more files identified by a path (or path pattern) along with associated schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = ml.CsvDataSet(file_pattern=training_data_path, schema_file=schema_path)\n",
    "eval_data = ml.CsvDataSet(file_pattern=eval_data_path, schema_file=schema_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Data\n",
    "\n",
    "When building a model, a number of pieces of information about the training data are required - for example, the list of entries or vocabulary of a categorical/discrete column, or aggregate statistics like min and max for numerical columns. These require a full pass over the training data, and is usually done once, and needs to be repeated once if you change the schema in a future iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze: completed\n"
     ]
    }
   ],
   "source": [
    "analysis_path = os.path.join(workspace_path, 'analysis')\n",
    "\n",
    "regression.analyze(dataset=train_data, output_dir=analysis_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of analysis is a numerical_analysis file that contains analysis from the numerical columns, and a vocab file from each categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema.json\tvocab_ESR.csv\t vocab_JWTR.csv     vocab_SCHL.csv\r\n",
      "stats.json\tvocab_FOD1P.csv  vocab_MAR.csv\t    vocab_SCIENGRLP.csv\r\n",
      "vocab_AGEP.csv\tvocab_HINS4.csv  vocab_POWPUMA.csv  vocab_SERIALNO.csv\r\n",
      "vocab_COW.csv\tvocab_INDP.csv\t vocab_PUMA.csv     vocab_SEX.csv\r\n",
      "vocab_ESP.csv\tvocab_JWMNP.csv  vocab_RAC1P.csv    vocab_WKW.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {analysis_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "All the data is in place to start training. A model learns to predict the target value (the income), based on the different pieces of input data (the various columns or features). The target and inputs are defined as features derived from the input data by applying a set of transforms to the columns.\n",
    "\n",
    "Additionally there is a special key column - this is any column in the data that can be used to uniquely identify instances. The value of this column is ignored during training, but this value is quite useful when using the resulting model during prediction as discussed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = {\n",
    "  \"WAGP\": {\"transform\": \"target\"},\n",
    "  \"SERIALNO\": {\"transform\": \"key\"},\n",
    "  \"AGEP\": {\"transform\": \"embedding\", \"embedding_dim\": 2},  # Age\n",
    "  \"COW\": {\"transform\": \"one_hot\"},                         # Class of worker\n",
    "  \"ESP\": {\"transform\": \"embedding\", \"embedding_dim\": 2},   # Employment status of parents\n",
    "  \"ESR\": {\"transform\": \"one_hot\"},                         # Employment status\n",
    "  \"FOD1P\": {\"transform\": \"embedding\", \"embedding_dim\": 3}, # Field of degree\n",
    "  \"HINS4\": {\"transform\": \"one_hot\"},                       # Medicaid\n",
    "  \"INDP\": {\"transform\": \"embedding\", \"embedding_dim\": 5},  # Industry\n",
    "  \"JWMNP\": {\"transform\": \"embedding\", \"embedding_dim\": 2}, # Travel time to work\n",
    "  \"JWTR\": {\"transform\": \"one_hot\"},                        # Transportation\n",
    "  \"MAR\": {\"transform\": \"one_hot\"},                         # Marital status\n",
    "  \"POWPUMA\": {\"transform\": \"one_hot\"},                     # Place of work\n",
    "  \"PUMA\": {\"transform\": \"one_hot\"},                        # Area code\n",
    "  \"RAC1P\": {\"transform\": \"one_hot\"},                       # Race\n",
    "  \"SCHL\": {\"transform\": \"one_hot\"},                        # School\n",
    "  \"SCIENGRLP\": {\"transform\": \"one_hot\"},                   # Science\n",
    "  \"SEX\": {\"transform\": \"one_hot\"},\n",
    "  \"WKW\": {\"transform\": \"one_hot\"}                          # Weeks worked\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1972.13, step = 1\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 1970.59\n",
      "INFO:tensorflow:global_step/sec: 9.33124\n",
      "INFO:tensorflow:loss = 379.253, step = 101\n",
      "INFO:tensorflow:global_step/sec: 155.005\n",
      "INFO:tensorflow:loss = 300.617, step = 201\n",
      "INFO:tensorflow:global_step/sec: 160.271\n",
      "INFO:tensorflow:loss = 254.483, step = 301\n",
      "INFO:tensorflow:global_step/sec: 155.987\n",
      "INFO:tensorflow:loss = 305.954, step = 401\n",
      "INFO:tensorflow:global_step/sec: 138.363\n",
      "INFO:tensorflow:loss = 258.562, step = 501\n",
      "INFO:tensorflow:global_step/sec: 127.4\n",
      "INFO:tensorflow:loss = 260.071, step = 601\n",
      "INFO:tensorflow:global_step/sec: 131.207\n",
      "INFO:tensorflow:loss = 222.711, step = 701\n",
      "INFO:tensorflow:global_step/sec: 127.116\n",
      "INFO:tensorflow:loss = 313.373, step = 801\n",
      "INFO:tensorflow:global_step/sec: 127.924\n",
      "INFO:tensorflow:loss = 168.303, step = 901\n",
      "INFO:tensorflow:global_step/sec: 120.85\n",
      "INFO:tensorflow:loss = 359.195, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 129.045\n",
      "INFO:tensorflow:loss = 314.938, step = 1101\n",
      "INFO:tensorflow:global_step/sec: 130.644\n",
      "INFO:tensorflow:loss = 341.975, step = 1201\n",
      "INFO:tensorflow:global_step/sec: 130.906\n",
      "INFO:tensorflow:loss = 279.281, step = 1301\n",
      "INFO:tensorflow:global_step/sec: 126.796\n",
      "INFO:tensorflow:loss = 406.446, step = 1401\n",
      "INFO:tensorflow:global_step/sec: 128.594\n",
      "INFO:tensorflow:loss = 439.866, step = 1501\n",
      "INFO:tensorflow:global_step/sec: 130.572\n",
      "INFO:tensorflow:loss = 282.947, step = 1601\n",
      "INFO:tensorflow:global_step/sec: 126.294\n",
      "INFO:tensorflow:loss = 202.999, step = 1701\n",
      "INFO:tensorflow:global_step/sec: 126.199\n",
      "INFO:tensorflow:loss = 208.936, step = 1801\n",
      "INFO:tensorflow:global_step/sec: 126.454\n",
      "INFO:tensorflow:loss = 314.666, step = 1901\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 360.278\n",
      "Training: completed\n"
     ]
    }
   ],
   "source": [
    "training_path = os.path.join(workspace_path, 'training')\n",
    "regression.train(train_dataset=train_data, eval_dataset=eval_data,\n",
    "                 output_dir=training_path,\n",
    "                 analysis_dir=analysis_path,\n",
    "                 features=features,\n",
    "                 max_steps=2000,\n",
    "                 layer_sizes=[5, 5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "\n",
    "A training job produces various summary events containing values of metrics (eg. throughput and loss) over the course of its execution. These events can be observed in TensorBoard while the job executes or after it is executed.\n",
    "\n",
    "In this sample, training was short, and has completed. In the general case, especially for longer cloud training jobs, it is more interesting to launch TensorBoard while the training job continues to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 8565. Click <a href=\"/_proxy/33423/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard_pid = ml.TensorBoard.start(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml.TensorBoard.stop(tensorboard_pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Trained Model\n",
    "\n",
    "It is interesting to get a sense of all the outputs produced during training, in addition to the summary event files, visualized in the previous step. In particular, note that the model is produced in a `model` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/datalab/workspace/census/training/model:\r\n",
      "assets.extra  saved_model.pb  variables\r\n",
      "\r\n",
      "/content/datalab/workspace/census/training/model/assets.extra:\r\n",
      "features.json  schema.json\r\n",
      "\r\n",
      "/content/datalab/workspace/census/training/model/variables:\r\n",
      "variables.data-00000-of-00001  variables.index\r\n"
     ]
    }
   ],
   "source": [
    "!ls -R {training_path}/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Once a model has been trained, it is necessary to evaluate it and understand how well it is performing. In order to evaluate a model, batch prediction jobs can be run against the one or more evaluation datasets that you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch predict: completed\n"
     ]
    }
   ],
   "source": [
    "evaluation_path = os.path.join(workspace_path, 'evaluation')\n",
    "\n",
    "# Note the use of evaluation mode (as opposed to prediction mode). This is used to indicate the data being\n",
    "# predicted on does contain a target value column (prediction data is missing that column).\n",
    "regression.batch_predict(training_dir=training_path,\n",
    "                         prediction_input_file=eval_data_path,\n",
    "                         output_dir=evaluation_path,\n",
    "                         output_format='json',\n",
    "                         mode='evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 44\r\n",
      "-rw-r--r-- 1 root root     0 Mar  7 19:10 errors-00000-of-00001.txt\r\n",
      "-rw-r--r-- 1 root root 44106 Mar  7 19:10 predictions-00000-of-00001.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {evaluation_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>predicted</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1225</td>\n",
       "      <td>15.199446</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1438</td>\n",
       "      <td>42.575989</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2536</td>\n",
       "      <td>55.555511</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2892</td>\n",
       "      <td>19.345251</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4767</td>\n",
       "      <td>48.008057</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIALNO  predicted  target\n",
       "0      1225  15.199446    18.0\n",
       "1      1438  42.575989    45.0\n",
       "2      2536  55.555511    62.0\n",
       "3      2892  19.345251    16.0\n",
       "4      4767  48.008057    58.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.read_json(os.path.join(evaluation_path, 'predictions-00000-of-00001.json'), lines=True)\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 19.074\n"
     ]
    }
   ],
   "source": [
    "mse = metrics.mean_squared_error(df_eval['target'], df_eval['predicted'])\n",
    "rmse = math.sqrt(mse)\n",
    "print 'Root Mean Squared Error: %.3f' % rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAF7CAYAAAAAH4u2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACr/j/ONiVEFR3shwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ef0953f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_eval['error'] = df_eval['predicted'] - df_eval['target']\n",
    "_ = plot.hist(df_eval['error'], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root mean squared error and distribution of errors indicates how the model is performing at an aggregate level as well as indicative of the span of error values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Now that a model has been trained, and saved on-disk, it can be reloaded using TensorFlow, and be used to produce predictions, i.e. produce the income value given a set of new instances, or features that were not previously present in the training data. This mechanism can also help validate the model - it can be used to produce predictions for one or more evaluation datasets.\n",
    "\n",
    "Note that prediction data must be of the same type (input format, and order of columns) as the data that was used for training. The only difference is the first column, the target income value, is absent.\n",
    "\n",
    "Since the model is a regression model, a single value is the output of the prediction.\n",
    "\n",
    "Also note that second column in our schema was specified as a key column. This value of the key will accompany the output values, so they can be joined with the input instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /content/datalab/workspace/census/data/prediction.csv\n"
     ]
    }
   ],
   "source": [
    "%file {workspace_path}/data/prediction.csv\n",
    "SERIALNO,AGEP,COW,ESP,ESR,FOD1P,HINS4,INDP,JWMNP,JWTR,MAR,POWPUMA,PUMA,RAC1P,SCHL,SCIENGRLP,SEX,WKW\n",
    "490,64,2,0,1,0,2,8090,015,01,1,00590,00500,1,18,0,2,1\n",
    "1225,32,5,0,4,5301,2,9680,015,01,1,00100,00100,1,21,2,1,1\n",
    "1226,30,1,0,1,0,2,8680,020,01,1,00100,00100,1,16,0,2,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>ESP</th>\n",
       "      <th>ESR</th>\n",
       "      <th>FOD1P</th>\n",
       "      <th>HINS4</th>\n",
       "      <th>INDP</th>\n",
       "      <th>JWMNP</th>\n",
       "      <th>JWTR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>POWPUMA</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WKW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8090</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>590</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1225</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5301</td>\n",
       "      <td>2</td>\n",
       "      <td>9680</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8680</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIALNO  AGEP  COW  ESP  ESR  FOD1P  HINS4  INDP  JWMNP  JWTR  MAR  \\\n",
       "0       490    64    2    0    1      0      2  8090     15     1    1   \n",
       "1      1225    32    5    0    4   5301      2  9680     15     1    1   \n",
       "2      1226    30    1    0    1      0      2  8680     20     1    1   \n",
       "\n",
       "   POWPUMA  PUMA  RAC1P  SCHL  SCIENGRLP  SEX  WKW  \n",
       "0      590   500      1    18          0    2    1  \n",
       "1      100   100      1    21          2    1    1  \n",
       "2      100   100      1    16          0    2    1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_instances = pd.read_csv(os.path.join(workspace_path, 'data/prediction.csv'))\n",
    "df_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>22.995327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1225</td>\n",
       "      <td>42.653973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226</td>\n",
       "      <td>8.211700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIALNO  predicted\n",
       "0       490  22.995327\n",
       "1      1225  42.653973\n",
       "2      1226   8.211700"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions = regression.predict(training_dir=training_path, data=df_instances)\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>ESP</th>\n",
       "      <th>ESR</th>\n",
       "      <th>FOD1P</th>\n",
       "      <th>HINS4</th>\n",
       "      <th>INDP</th>\n",
       "      <th>JWMNP</th>\n",
       "      <th>JWTR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>POWPUMA</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WKW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERIALNO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>22.995327</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8090</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>590</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>42.653973</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5301</td>\n",
       "      <td>2</td>\n",
       "      <td>9680</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>8.211700</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8680</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted  AGEP  COW  ESP  ESR  FOD1P  HINS4  INDP  JWMNP  JWTR  \\\n",
       "SERIALNO                                                                    \n",
       "490       22.995327    64    2    0    1      0      2  8090     15     1   \n",
       "1225      42.653973    32    5    0    4   5301      2  9680     15     1   \n",
       "1226       8.211700    30    1    0    1      0      2  8680     20     1   \n",
       "\n",
       "          MAR  POWPUMA  PUMA  RAC1P  SCHL  SCIENGRLP  SEX  WKW  \n",
       "SERIALNO                                                        \n",
       "490         1      590   500      1    18          0    2    1  \n",
       "1225        1      100   100      1    21          2    1    1  \n",
       "1226        1      100   100      1    16          0    2    1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index the instances DataFrame using the SERIALNO column, and join the predictions\n",
    "# DataFrame using the same column.\n",
    "df_instances.set_index(keys=['SERIALNO'], inplace=True)\n",
    "df_predictions.set_index(keys=['SERIALNO'], inplace=True)\n",
    "\n",
    "df_data = df_predictions.join(other=df_instances)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "This notebook covered key stages of the workflow locally - data preparation, data analysis, training, and prediction. Once there is a working model, the next step is to use the full dataset, and scale to much larger data volumes by performing these steps in cloud using BigQuery, Machine Learning Engine, and Dataflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
