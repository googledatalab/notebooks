{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Cloud Machine Learning Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the second of a set of steps to run machine learning on the cloud. In this step, we will use the data and associated analysis metadata prepared in the [previous notebook](./2 Service Preprocess.ipynb) and continue with training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace Setup\n",
    "\n",
    "The first step is to setup the workspace that we will use within this notebook - the python libraries, and the Google Cloud Storage bucket that will be used to contain the inputs and outputs produced over the course of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import google.datalab as datalab\n",
    "import google.datalab.ml as ml\n",
    "import mltoolbox.regression.dnn as regression\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The storage bucket was created in the previous notebook. We'll re-declare it here, so we can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "storage_bucket = 'gs://' + datalab.Context.default().project_id + '-datalab-workspace/'\n",
    "storage_region = 'us-central1'\n",
    "\n",
    "workspace_path = os.path.join(storage_bucket, 'census')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and DataSets\n",
    "\n",
    "We'll also enumerate our data and declare DataSets for use during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-users-datalab-workspace/census/data/:\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/data/eval.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/data/schema.json\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/data/train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -r {workspace_path}/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(workspace_path, 'data/train.csv')\n",
    "eval_data_path = os.path.join(workspace_path, 'data/eval.csv')\n",
    "schema_path = os.path.join(workspace_path, 'data/schema.json')\n",
    "\n",
    "train_data = ml.CsvDataSet(file_pattern=train_data_path, schema_file=schema_path)\n",
    "eval_data = ml.CsvDataSet(file_pattern=eval_data_path, schema_file=schema_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "We had previously analyzed training data to produce statistics and vocabularies. These will be used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_path = os.path.join(workspace_path, 'analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-users-datalab-workspace/census/analysis/schema.json\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/stats.json\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_AGEP.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_COW.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_ESP.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_ESR.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_FOD1P.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_HINS4.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_INDP.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_JWMNP.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_JWTR.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_MAR.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_POWPUMA.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_PUMA.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_RAC1P.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_SCHL.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_SCIENGRLP.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_SERIALNO.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_SEX.csv\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/analysis/vocab_WKW.csv\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {analysis_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Training in cloud is accomplished by submitting jobs to Cloud Machine Learning Engine. When submitting jobs, it is a good idea to name each job, so it can be looked up easily (names do need to be unique within the scope of a project).\n",
    "\n",
    "Additionally you'll want to pick a region where your job will run. Usually this is in the same region as where your training data resides.\n",
    "\n",
    "Finally, you'll want to pick a scale tier. The [documentation](https://cloud.google.com/ml/reference/rest/v1beta1/projects.jobs#ScaleTier) describes different scale tiers or custom cluster setups you can use with ML Engine. For the purposes of this sample, a simple single node cluster suffices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = ml.CloudTrainingConfig(region=storage_region, scale_tier='BASIC')\n",
    "\n",
    "training_job_name = 'census_regression_' + str(int(time.time()))\n",
    "training_path = os.path.join(workspace_path, 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = {\n",
    "  \"WAGP\": {\"transform\": \"target\"},\n",
    "  \"SERIALNO\": {\"transform\": \"key\"},\n",
    "  \"AGEP\": {\"transform\": \"embedding\", \"embedding_dim\": 2},  # Age\n",
    "  \"COW\": {\"transform\": \"one_hot\"},                         # Class of worker\n",
    "  \"ESP\": {\"transform\": \"embedding\", \"embedding_dim\": 2},   # Employment status of parents\n",
    "  \"ESR\": {\"transform\": \"one_hot\"},                         # Employment status\n",
    "  \"FOD1P\": {\"transform\": \"embedding\", \"embedding_dim\": 3}, # Field of degree\n",
    "  \"HINS4\": {\"transform\": \"one_hot\"},                       # Medicaid\n",
    "  \"INDP\": {\"transform\": \"embedding\", \"embedding_dim\": 5},  # Industry\n",
    "  \"JWMNP\": {\"transform\": \"embedding\", \"embedding_dim\": 2}, # Travel time to work\n",
    "  \"JWTR\": {\"transform\": \"one_hot\"},                        # Transportation\n",
    "  \"MAR\": {\"transform\": \"one_hot\"},                         # Marital status\n",
    "  \"POWPUMA\": {\"transform\": \"one_hot\"},                     # Place of work\n",
    "  \"PUMA\": {\"transform\": \"one_hot\"},                        # Area code\n",
    "  \"RAC1P\": {\"transform\": \"one_hot\"},                       # Race\n",
    "  \"SCHL\": {\"transform\": \"one_hot\"},                        # School\n",
    "  \"SCIENGRLP\": {\"transform\": \"one_hot\"},                   # Science\n",
    "  \"SEX\": {\"transform\": \"one_hot\"},\n",
    "  \"WKW\": {\"transform\": \"one_hot\"}                          # Weeks worked\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: To facilitate re-running this notebook, any previous training outputs are first deleted, if they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!gsutil rm -rf {training_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The job submitted below can take a few minutes to complete. Once you have submitted, you can continue with more steps in the notebook, until the call to `job.wait()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://cloud-ml-users-datalab-workspace/census/training/staging/trainer.tar.gz\n",
      "Job request send. View status of job at\n",
      "https://console.developers.google.com/ml/jobs?project=cloud-ml-users\n"
     ]
    }
   ],
   "source": [
    "job = regression.train_async(train_dataset=train_data, eval_dataset=eval_data,\n",
    "                             features=features,\n",
    "                             analysis_dir=analysis_path,\n",
    "                             output_dir=training_path,\n",
    "                             max_steps=2000,\n",
    "                             layer_sizes=[5, 5, 5],\n",
    "                             job_name=training_job_name,\n",
    "                             cloud=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a job is submitted to ML Engine, a few things happen. The code for the job is staged in Google Cloud Storage, and a job definition is submitted to the service.\n",
    "\n",
    "The service queues the job, and thereafter the job can be monitored in the console (status and logs), as well as using TensorBoard. The service also provisions computation resources based on the choice of scale tier, installs your code package and its dependencies, and starts your training process. Thereafter, the service monitors the job for completion, and retries if necessary.\n",
    "\n",
    "The first step in the process - launching a training cluster - can take a few minutes. It is recommended to use `BASIC` tier to first validate jobs on cloud and use that for faster iteration to benefit from quicker job starts, and then launch larger scaled jobs where the overhead of launching a cluster is small relative to the life of the job itself.\n",
    "\n",
    "You can check the progress of the job using the link to the console page above, as well as its logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "\n",
    "TensorBoard can be launched against your training output directory. As summaries are produced from your running job, they will show up in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tensorboard_pid = ml.TensorBoard.start(training_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Trained Model\n",
    "\n",
    "Once training is completed, the resulting trained model is saved and placed into Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job census_regression_1488915059 completed"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait for the job to be complete before proceeding.\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-users-datalab-workspace/census/training/model/:\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/saved_model.pb\n",
      "\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/assets.extra/:\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/assets.extra/\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/assets.extra/features.json\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/assets.extra/schema.json\n",
      "\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/variables/:\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/variables/\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/variables/variables.data-00000-of-00001\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -r {training_path}/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml.TensorBoard.stop(tensorboard_pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "Once a model has been created, the next step is to evaluate it, possibly against multiple evaluation steps. We'll continue with this step in the [next notebook](./4 Service Evaluate.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
