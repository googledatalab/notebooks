{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a Model and Predicting with Cloud Machine Learning Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the final step in a series of notebooks for doing machine learning on cloud. The [previous notebook](./4 Service Evaluate.ipynb), demonstrated evaluating a model. In a real-world scenario, it is likely that there are multiple evaluation datasets, as well as multiple models that need to be evaluated, before there is a model suitable for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace Setup\n",
    "The first step is to setup the workspace that we will use within this notebook - the python libraries, and the Google Cloud Storage bucket that will be used to contain the inputs and outputs produced over the course of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import google.datalab as datalab\n",
    "import google.datalab.ml as ml\n",
    "import mltoolbox.regression.dnn as regression\n",
    "import os\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The storage bucket was created earlier. We'll re-declare it here, so we can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "storage_bucket = 'gs://' + datalab.Context.default().project_id + '-datalab-workspace/'\n",
    "storage_region = 'us-central1'\n",
    "\n",
    "workspace_path = os.path.join(storage_bucket, 'census')\n",
    "training_path = os.path.join(workspace_path, 'training')\n",
    "\n",
    "model_name = 'census'\n",
    "model_version = 'v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Lets take a quick look at the model that was previously produced as a result of the training job. This is the model that was evaluated, and is going to be deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-users-datalab-workspace/census/training/model/:\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/saved_model.pb\n",
      "\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/assets.extra/:\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/assets.extra/\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/assets.extra/features.json\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/assets.extra/schema.json\n",
      "\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/variables/:\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/variables/\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/variables/variables.data-00000-of-00001\n",
      "gs://cloud-ml-users-datalab-workspace/census/training/model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -r {training_path}/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "Cloud Machine Learning Engine provides APIs to deploy and manage models. The first step is to create a named model resource, which can be referred to by name. The second step is to deploy the trained model binaries as a version within the model resource.\n",
    "\n",
    "**NOTE**: These steps can take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!gcloud ml-engine models create {model_name} --regions {storage_region}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating version (this might take a few minutes)......done.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine versions create {model_version} --model {model_name} --origin {training_path}/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the model is ready for batch prediction jobs. It is also automatically exposed as an HTTP endpoint for performing online prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Prediction\n",
    "\n",
    "Online prediction is accomplished by issuing HTTP requests to the specific model version endpoint. Instances to be predicted are formatted as JSON in the request body. The structure of instances depend on the model. The census model in this sample was trained using data formatted as CSV, and so the model expects inputs as CSV formatted strings.\n",
    "\n",
    "Prediction results are returned as JSON in the response.\n",
    "\n",
    "HTTP requests must contain an OAuth token auth header to succeed. In the Datalab notebook, the OAuth token corresponding to the environment is accessible without a requiring OAuth flow. Actual applications will need to determine the best strategy for acquringing OAuth tokens, generally using [Application Default Credentials](https://developers.google.com/identity/protocols/application-default-credentials)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'SERIALNO': u'490', u'predicted': 26.395479202270508},\n",
       " {u'SERIALNO': u'1225', u'predicted': 68.57681274414062},\n",
       " {u'SERIALNO': u'1226', u'predicted': 13.854779243469238}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = 'https://ml.googleapis.com/v1/projects/{project}/models/{model}/versions/{version}:predict'\n",
    "url = api.format(project=datalab.Context.default().project_id,\n",
    "                 model=model_name,\n",
    "                 version=model_version)\n",
    "\n",
    "headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'Authorization': 'Bearer ' + datalab.Context.default().credentials.get_access_token().access_token\n",
    "}\n",
    "\n",
    "body = {\n",
    "  'instances': [\n",
    "    '490,64,2,0,1,0,2,8090,015,01,1,00590,00500,1,18,0,2,1',\n",
    "    '1225,32,5,0,4,5301,2,9680,015,01,1,00100,00100,1,21,2,1,1',\n",
    "    '1226,30,1,0,1,0,2,8680,020,01,1,00100,00100,1,16,0,2,1'\n",
    "  ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=body, headers=headers)\n",
    "predictions = response.json()['predictions']\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite simple to issue these requests using your HTTP library of choice. Actual applications should include the logic to handle errors, including retries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Prediction\n",
    "\n",
    "While online prediction is optimized for low-latency requests over small lists of instances, batch prediction is designed for high-throughput prediction for large datasets. The same model can be used for both.\n",
    "\n",
    "Batch prediction jobs can also be submitted via the API. They are easily submitted via the gcloud tool as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/instances.csv\n"
     ]
    }
   ],
   "source": [
    "%file /tmp/instances.csv\n",
    "490,64,2,0,1,0,2,8090,015,01,1,00590,00500,1,18,0,2,1\n",
    "1225,32,5,0,4,5301,2,9680,015,01,1,00100,00100,1,21,2,1,1\n",
    "1226,30,1,0,1,0,2,8680,020,01,1,00100,00100,1,16,0,2,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_data_path = os.path.join(workspace_path, 'data/prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!gsutil -q cp /tmp/instances.csv {prediction_data_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch prediction job must have a unique name within the scope of a project. The specified name below may need to be changed if you are re-running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_name = 'census_prediction_' + str(int(time.time()))\n",
    "prediction_path = os.path.join(workspace_path, 'predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: A batch prediction job can take a few minutes, due to overhead of provisioning resources, which is reasonable for large jobs, but can far exceed the time to complete a tiny dataset such as the one used in this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2017-03-07T20:00:36Z'\r\n",
      "jobId: census_prediction_1488916830\r\n",
      "predictionInput:\r\n",
      "  dataFormat: TEXT\r\n",
      "  inputPaths:\r\n",
      "  - gs://cloud-ml-users-datalab-workspace/census/data/prediction.csv\r\n",
      "  outputPath: gs://cloud-ml-users-datalab-workspace/census/predictions\r\n",
      "  region: us-central1\r\n",
      "  runtimeVersion: '1.0'\r\n",
      "  versionName: projects/cloud-ml-users/models/census/versions/v1\r\n",
      "predictionOutput:\r\n",
      "  outputPath: gs://cloud-ml-users-datalab-workspace/census/predictions\r\n",
      "state: QUEUED\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs submit prediction {job_name} --model {model_name} --version {model_version} --data-format TEXT --input-paths {prediction_data_path} --output-path {prediction_path} --region {storage_region}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status of the job can be inspected in the [Cloud Console](https://console.cloud.google.com/mlengine/jobs). Once it is completed, the outputs should be visible in the specified output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-users-datalab-workspace/census/predictions/prediction.errors_stats-00000-of-00001\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/predictions/prediction.results-00000-of-00002\r\n",
      "gs://cloud-ml-users-datalab-workspace/census/predictions/prediction.results-00001-of-00002\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {prediction_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"SERIALNO\": \"490\", \"predicted\": 26.395479202270508}\n",
      "{\"SERIALNO\": \"1225\", \"predicted\": 68.57681274414062}\n",
      "{\"SERIALNO\": \"1226\", \"predicted\": 13.854779243469238}\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat {prediction_path}/prediction*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This covers the end-to-end workflow from data preparation to training to deployment and prediction using a combination of the Datalab ML Toolbox with out-of-box models, Cloud Machine Learning Engine, BigQuery and Dataflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
