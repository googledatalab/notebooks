{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the data\n",
    "\n",
    "In this sequence of notebooks, we will build a classification model using the StackOverflow 2017 survey dataset. This data comes from a survey of StackOverflow users. It contains many interesting features about the types of software developers that use StackOverflow. This dataset does not represent a real world prediction problem, as new data is unlikely to be generated. However it is a nice example to show processing of different feature types.\n",
    "\n",
    "One of the columns in the data describes the class of software developer of the survey responder: \"Student\", \"Professional developer\", \"Used to be a professional developer\",and \"Professional non-developer who sometimes writes code\". We will use the other columns in the data to predict this developer label class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data\n",
    "\n",
    "See https://www.kaggle.com/stackoverflow/so-survey-2017 for a longer overview of stackoverflow dataset. The survey has about 64,000 responses from their users. Note that the data was taken from StackOverflow and licensed under the ODbL license. See the Kaggle website for more information.\n",
    "\n",
    "\n",
    "Download the survey results data and schema to /content/datalab/workspace/structured_data_classification_stackoverflow or another location. If you use a different location, you have to change the workspace path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = '/content/datalab/workspace/structured_data_classification_stackoverflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze_output\t      schema.json\t\t training_output\r\n",
      "batch_predict_output  survey_results_public.csv  transform_output\r\n",
      "clean_input\t      survey_results_schema.csv  transforms.json\r\n",
      "eval.csv\t      train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls $WORKSPACE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to make a decision about how we are going to model the data. For each column, we have to ask if it represents a numerical value, 1 categorical value, or many categories. This is not always clear, as there could be many ways to use a column in a model. \n",
    "\n",
    "For example, consider the \"disagree, somewhat disagree, somewhat agree, agree\" type questions in a linear model. There are at least two options to how we could use those columns. We could encode each option as a categorical value. If we do this, we loose the natural ordering (disagree seems like it should have a smaller value than agree), and so our model has to learn this relationship. Also, there is a variable for each categorical value, making the linear model large and easy to overfit. Another option is to convert these values into a numerical column (using say disagree=-2, somewhat disagree=-1, somewhat agree=1, agree=2), and now the linear model just has to learn one weight. However, the difference between two categories is now important. Is it correct that 'agree' is weigthted twice as strongly as 'somewhat agree'? In general, categorical values should be encoded as categories because this produces more variables in the model which makes it easier to learn relationships. Picking how to encode data columns is part of feature engineering, and it is domain an problem specfic.\n",
    "\n",
    "In this notebook, we will do the simplest thing\n",
    "\n",
    "* columns with one categorical response will be encoded with a one-hot vector. Example: encode the day of the week with a vector of length 7. The value 'Monday' is encoded as [1, 0, 0, 0, 0, 0, 0].\n",
    "* columns with multiple categorical responses will be encoded with bag-of-words vector. Example: encode which programming languages are used from the list ['Java', 'Python', 'C++', 'JavaScript'] as a vector of length 4. The value 'Java C++' is encoded as [1, 0, 1, 0].\n",
    "* columns with numerical values will be encoded as numbers with no transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import six\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survey_results_path = os.path.join(WORKSPACE_PATH, 'survey_results_public.csv')\n",
    "survey_schema_path = os.path.join(WORKSPACE_PATH, 'survey_results_schema.csv')\n",
    "\n",
    "# Clean data \n",
    "clean_folder = os.path.join(WORKSPACE_PATH, 'clean_input')\n",
    "train_data_path = os.path.join(clean_folder, 'train.csv')\n",
    "eval_data_path = os.path.join(clean_folder, 'eval.csv')\n",
    "schema_path = os.path.join(clean_folder, 'schema.json')\n",
    "transform_path = os.path.join(clean_folder, 'transforms.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p $clean_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(survey_results_path) or not os.path.isfile(survey_schema_path):\n",
    "    print('Error: the data files are missing!')\n",
    "    print('Download the data and schema files from https://www.kaggle.com/stackoverflow/so-survey-2017')\n",
    "    print('and put them into the folder ' + WORKSPACE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get CSV headers as a list of column names.\n",
    "with open(survey_schema_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) # skip header\n",
    "    headers = [r[0] for r in reader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the data with MLWorkbench, the data needs to be cleaned in a few ways:\n",
    "\n",
    "* missing values sould be missing in the csv file, not 'NA'. \n",
    "* for multiple categorical columns, the data has each value separated by a semicolon but  mlworkbench separates tokens by spaces\n",
    "* some columns have non-ascii values, but only ascii is supported.\n",
    "\n",
    "We will use the two functions below to fix the ascii and multiple categorical encoding issue. The missing/NA issue is fixed by Pandas when the data is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_multi_label_cols(v):\n",
    "    \"\"\"Make labels 1 token long.\n",
    "    Example:\n",
    "        Before: Stock options; Annual bonus; Vacation/days off; Equipment; Meals\n",
    "        After: Stock_options Annual_bonus Vacation/days_off Equipment Meals\n",
    "    \"\"\"\n",
    "    if isinstance(v, float):\n",
    "      return v\n",
    "    v = v.replace('; ', ';')\n",
    "    v = v.replace(' ', '_')\n",
    "    v = v.replace(';', ' ')\n",
    "    return v\n",
    "\n",
    "def convert_to_ascii(v):\n",
    "    \"\"\"Remove non-ascii characters.\"\"\"\n",
    "    if isinstance(v, (float, int)):\n",
    "      return v\n",
    "    return filter(lambda x: x in set(string.printable), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We divide the data columns into how we will transform them.\n",
    "single_label_cols = []\n",
    "numerical_cols = []\n",
    "multi_label_cols = []\n",
    "key_cols = []\n",
    "target_col = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "hiddenCell": true
   },
   "outputs": [],
   "source": [
    "key_cols.append('Respondent')\n",
    "target_col = 'Professional'\n",
    "single_label_cols.append('ProgramHobby')\n",
    "single_label_cols.append('Country')\n",
    "single_label_cols.append('University')\n",
    "single_label_cols.append('EmploymentStatus')\n",
    "single_label_cols.append('FormalEducation')\n",
    "single_label_cols.append('MajorUndergrad')\n",
    "single_label_cols.append('HomeRemote')\n",
    "single_label_cols.append('CompanySize') # bucket range\n",
    "single_label_cols.append('CompanyType')\n",
    "single_label_cols.append('YearsProgram') # bucket range\n",
    "single_label_cols.append('YearsCodedJob') # bucket range\n",
    "single_label_cols.append('YearsCodedJobPast') # bucket range\n",
    "multi_label_cols.append('DeveloperType')\n",
    "single_label_cols.append('WebDeveloperType')\n",
    "multi_label_cols.append('MobileDeveloperType')\n",
    "multi_label_cols.append('NonDeveloperType')\n",
    "numerical_cols.append('CareerSatisfaction')\n",
    "numerical_cols.append('JobSatisfaction')\n",
    "single_label_cols.append('ExCoderReturn')\n",
    "single_label_cols.append('ExCoderNotForMe')\n",
    "single_label_cols.append('ExCoderBalance')\n",
    "single_label_cols.append('ExCoder10Years')\n",
    "single_label_cols.append('ExCoderBelonged')\n",
    "single_label_cols.append('ExCoderSkills')\n",
    "single_label_cols.append('ExCoderWillNotCode')\n",
    "single_label_cols.append('ExCoderActive')\n",
    "single_label_cols.append('PronounceGIF')\n",
    "single_label_cols.append('ProblemSolving')\n",
    "single_label_cols.append('BuildingThings')\n",
    "single_label_cols.append('LearningNewTech')\n",
    "single_label_cols.append('BoringDetails')\n",
    "single_label_cols.append('JobSecurity')\n",
    "single_label_cols.append('DiversityImportant')\n",
    "single_label_cols.append('AnnoyingUI')\n",
    "single_label_cols.append('FriendsDevelopers')\n",
    "single_label_cols.append('RightWrongWay')\n",
    "single_label_cols.append('UnderstandComputers')\n",
    "single_label_cols.append('SeriousWork')\n",
    "single_label_cols.append('InvestTimeTools')\n",
    "single_label_cols.append('WorkPayCare')\n",
    "single_label_cols.append('KinshipDevelopers')\n",
    "single_label_cols.append('ChallengeMyself')\n",
    "single_label_cols.append('CompetePeers')\n",
    "single_label_cols.append('ChangeWorld')\n",
    "single_label_cols.append('JobSeekingStatus')\n",
    "numerical_cols.append('HoursPerWeek')\n",
    "single_label_cols.append('LastNewJob') # bucket range\n",
    "single_label_cols.append('AssessJobIndustry')\n",
    "single_label_cols.append('AssessJobRole')\n",
    "single_label_cols.append('AssessJobExp')\n",
    "single_label_cols.append('AssessJobDept')\n",
    "single_label_cols.append('AssessJobTech')\n",
    "single_label_cols.append('AssessJobProjects')\n",
    "single_label_cols.append('AssessJobCompensation')\n",
    "single_label_cols.append('AssessJobOffice')\n",
    "single_label_cols.append('AssessJobCommute')\n",
    "single_label_cols.append('AssessJobRemote')\n",
    "single_label_cols.append('AssessJobLeaders')\n",
    "single_label_cols.append('AssessJobProfDevel')\n",
    "single_label_cols.append('AssessJobDiversity')\n",
    "single_label_cols.append('AssessJobProduct')\n",
    "single_label_cols.append('AssessJobFinances')\n",
    "multi_label_cols.append('ImportantBenefits')\n",
    "single_label_cols.append('ClickyKeys')\n",
    "multi_label_cols.append('JobProfile')\n",
    "single_label_cols.append('ResumePrompted')\n",
    "single_label_cols.append('LearnedHiring')\n",
    "single_label_cols.append('ImportantHiringAlgorithms')\n",
    "single_label_cols.append('ImportantHiringTechExp')\n",
    "single_label_cols.append('ImportantHiringCommunication')\n",
    "single_label_cols.append('ImportantHiringOpenSource')\n",
    "single_label_cols.append('ImportantHiringPMExp')\n",
    "single_label_cols.append('ImportantHiringCompanies')\n",
    "single_label_cols.append('ImportantHiringTitles')\n",
    "single_label_cols.append('ImportantHiringEducation')\n",
    "single_label_cols.append('ImportantHiringRep')\n",
    "single_label_cols.append('ImportantHiringGettingThingsDone')\n",
    "single_label_cols.append('Currency')\n",
    "single_label_cols.append('Overpaid')\n",
    "single_label_cols.append('TabsSpaces')\n",
    "single_label_cols.append('EducationImportant')\n",
    "multi_label_cols.append('EducationTypes')\n",
    "multi_label_cols.append('SelfTaughtTypes')\n",
    "single_label_cols.append('TimeAfterBootcamp')\n",
    "multi_label_cols.append('CousinEducation')\n",
    "single_label_cols.append('WorkStart')\n",
    "multi_label_cols.append('HaveWorkedLanguage')\n",
    "multi_label_cols.append('WantWorkLanguage')\n",
    "multi_label_cols.append('HaveWorkedFramework')\n",
    "multi_label_cols.append('WantWorkFramework')\n",
    "multi_label_cols.append('HaveWorkedDatabase')\n",
    "multi_label_cols.append('WantWorkDatabase')\n",
    "multi_label_cols.append('HaveWorkedPlatform')\n",
    "multi_label_cols.append('WantWorkPlatform')\n",
    "multi_label_cols.append('IDE')\n",
    "single_label_cols.append('AuditoryEnvironment')\n",
    "multi_label_cols.append('Methodology')\n",
    "single_label_cols.append('VersionControl')\n",
    "single_label_cols.append('CheckInCode')\n",
    "single_label_cols.append('ShipIt')\n",
    "single_label_cols.append('OtherPeoplesCode')\n",
    "single_label_cols.append('ProjectManagement')\n",
    "single_label_cols.append('EnjoyDebugging')\n",
    "single_label_cols.append('InTheZone')\n",
    "single_label_cols.append('DifficultCommunication')\n",
    "single_label_cols.append('CollaborateRemote')\n",
    "multi_label_cols.append('MetricAssess')\n",
    "single_label_cols.append('EquipmentSatisfiedMonitors')\n",
    "single_label_cols.append('EquipmentSatisfiedCPU')\n",
    "single_label_cols.append('EquipmentSatisfiedRAM')\n",
    "single_label_cols.append('EquipmentSatisfiedStorage')\n",
    "single_label_cols.append('EquipmentSatisfiedRW')\n",
    "single_label_cols.append('InfluenceInternet')\n",
    "single_label_cols.append('InfluenceWorkstation')\n",
    "single_label_cols.append('InfluenceHardware')\n",
    "single_label_cols.append('InfluenceServers')\n",
    "single_label_cols.append('InfluenceTechStack')\n",
    "single_label_cols.append('InfluenceDeptTech')\n",
    "single_label_cols.append('InfluenceVizTools')\n",
    "single_label_cols.append('InfluenceDatabase')\n",
    "single_label_cols.append('InfluenceCloud')\n",
    "single_label_cols.append('InfluenceConsultants')\n",
    "single_label_cols.append('InfluenceRecruitment')\n",
    "single_label_cols.append('InfluenceCommunication')\n",
    "single_label_cols.append('StackOverflowDescribes')\n",
    "numerical_cols.append('StackOverflowSatisfaction')\n",
    "multi_label_cols.append('StackOverflowDevices')\n",
    "single_label_cols.append('StackOverflowFoundAnswer')\n",
    "single_label_cols.append('StackOverflowCopiedCode')\n",
    "single_label_cols.append('StackOverflowJobListing')\n",
    "single_label_cols.append('StackOverflowCompanyPage')\n",
    "single_label_cols.append('StackOverflowJobSearch')\n",
    "single_label_cols.append('StackOverflowNewQuestion')\n",
    "single_label_cols.append('StackOverflowAnswer')\n",
    "single_label_cols.append('StackOverflowMetaChat')\n",
    "single_label_cols.append('StackOverflowAdsRelevant')\n",
    "single_label_cols.append('StackOverflowAdsDistracting')\n",
    "single_label_cols.append('StackOverflowModeration')\n",
    "single_label_cols.append('StackOverflowCommunity')\n",
    "single_label_cols.append('StackOverflowHelpful')\n",
    "single_label_cols.append('StackOverflowBetter')\n",
    "single_label_cols.append('StackOverflowWhatDo')\n",
    "single_label_cols.append('StackOverflowMakeMoney')\n",
    "single_label_cols.append('Gender')\n",
    "single_label_cols.append('HighestEducationParents')\n",
    "multi_label_cols.append('Race')\n",
    "single_label_cols.append('SurveyLong')\n",
    "single_label_cols.append('QuestionsInteresting')\n",
    "single_label_cols.append('QuestionsConfusing')\n",
    "single_label_cols.append('InterestedAnswers')\n",
    "numerical_cols.append('Salary')\n",
    "numerical_cols.append('ExpectedSalary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check we didn't miss a column\n",
    "assert len(single_label_cols + multi_label_cols + numerical_cols + key_cols + [target_col]) == len(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanup_df(df):\n",
    "    \"\"\"Updates a dataframe reference.\"\"\"\n",
    "    for col in headers:\n",
    "        if col == 'Currency':\n",
    "            df[col] = df[col].apply(convert_to_ascii)\n",
    "    \n",
    "        if col == 'Race':\n",
    "            df[col] = df[col].apply(convert_to_ascii)\n",
    "    \n",
    "        if col in multi_label_cols:\n",
    "            df[col] = df[col].apply(update_multi_label_cols)\n",
    "\n",
    "df_all = pd.read_csv(survey_results_path, header=0, names=headers)\n",
    "cleanup_df(df_all)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data into 80% for training, and 20% for testing\n",
    "random_index = []\n",
    "for i in range(len(df_all)):\n",
    "    if random.random() < 0.8:\n",
    "        random_index.append(True)\n",
    "    else:\n",
    "        random_index.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array(random_index)\n",
    "df_train = df_all[x]\n",
    "df_eval = df_all[np.logical_not(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the new data sets\n",
    "df_train.to_csv(train_data_path, header=False, index=False)\n",
    "df_eval.to_csv(eval_data_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out the schema. Categorical columns must be string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schema = []\n",
    "for h in headers:\n",
    "    entry = {'name': h}\n",
    "    if h in numerical_cols:\n",
    "        entry['type']= 'FLOAT'\n",
    "    elif h in key_cols:\n",
    "        entry['type'] = 'INTEGER'\n",
    "    else:\n",
    "        entry['type'] = 'STRING'\n",
    "    schema.append(entry)\n",
    "\n",
    "with open(schema_path, 'w') as f:\n",
    "    f.write(json.dumps(schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out transforms. As an exercise, try changing some transforms. For example, replace 'bag_of_words' for 'tfidf' or 'one_hot' with 'embedding'. Run '%%ml analyze --help' in a cell to see the list of transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transforms = {}\n",
    "for h in headers:\n",
    "    if h in numerical_cols:\n",
    "        transform = 'scale'\n",
    "    elif h in key_cols:\n",
    "        transform = 'key'\n",
    "    elif h == target_col:\n",
    "        transform = 'target'\n",
    "    elif h in multi_label_cols:\n",
    "        transform = 'bag_of_words'\n",
    "    elif h in single_label_cols:\n",
    "        transform = 'one_hot'\n",
    "    else:\n",
    "        print('Error: %s is an unknown label' % h)\n",
    "        break\n",
    "    transforms[h] = {'transform': transform}\n",
    "  \n",
    "with open(transform_path, 'w') as f:\n",
    "    f.write(json.dumps(transforms))\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "Now that we have cleaned version of the csv file, we are ready to being the standward workflow for building and deploying TensorFlow models with Datalab's ML Workbench. Please proceed to the next notebook in this sequence. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
