{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data\n",
    "\n",
    "See https://www.kaggle.com/stackoverflow/so-survey-2017 for an overview of stackoverflow dataset. It is a survey of about 64,000 responses from their users. We are going to use it to predict what kind of a developer the surveyee is.\n",
    "\n",
    "\n",
    "Download the survey results data to /content/datalab/workspace/structured_data_classification_stackoverflow or another location, but you have to chagne the workspace path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = '/content/datalab/workspace/structured_data_classification_stackoverflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey_results_public.csv  survey_results_schema.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls $WORKSPACE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to make a decision about how we are going to model the data. For each column, we have to ask if it represents a numerical value, 1 categorical value, or many categories. This is not always clear, as there could be many ways to use a column in a model. \n",
    "\n",
    "For example, consider the 'disagree, somewhat disagree, somewhat agree, agree\" type questions in a linear model, there are at least two options to how we use those columns. We could encode each option as a categorical value. If we do this, we loose the natural ordering (disagree seems like it should have a smaller value than agree), and so our model has to learn this relationship. Also, there is a variable for each categorical value, making the linear model large and easy to overfit. Another option is to convert these values into a numerical column (using say disagree=-2, somewhat disagree=-1, somewhat agree=1, agree=2), and now the linear model just has to learn one weight. However, the difference between two categories is now important. Is it correct that 'agree' is weigthted twice as strongly as 'somewhat agree'? Picking how to encode data columns is part of feature engineering, and it is domain an problem specfic.\n",
    "\n",
    "In this notebook, we will do the simplest thing\n",
    "\n",
    "* columns with one categorical response will be encoded with a one-hot vector\n",
    "* columns with multiple categorical responses will be encoded with bag-of-words vector\n",
    "* columns with numerical values will be encoded as numbers with no transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import six\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survey_results_path = os.path.join(WORKSPACE_PATH, 'survey_results_public.csv')\n",
    "survey_schema_path = os.path.join(WORKSPACE_PATH, 'survey_results_schema.csv')\n",
    "\n",
    "# Clean data \n",
    "train_data_path = os.path.join(WORKSPACE_PATH, 'train.csv')\n",
    "eval_data_path = os.path.join(WORKSPACE_PATH, 'eval.csv')\n",
    "schema_path = os.path.join(WORKSPACE_PATH, 'schema.json')\n",
    "transform_path = os.path.join(WORKSPACE_PATH, 'transforms.json')\n",
    "\n",
    "# For analyze step\n",
    "analyze_output = os.path.join(WORKSPACE_PATH, 'analyze_output')\n",
    "\n",
    "# For the transform step\n",
    "transform_output = os.path.join(WORKSPACE_PATH, 'transform_output')\n",
    "transformed_train_pattern = os.path.join(transform_output, 'features_train*')\n",
    "transformed_eval_pattern = os.path.join(transform_output, 'features_eval*')\n",
    "\n",
    "# For the training step\n",
    "training_output = os.path.join(WORKSPACE_PATH, 'training_output')\n",
    "\n",
    "# For the prediction steps\n",
    "batch_predict_output = os.path.join(WORKSPACE_PATH, 'batch_predict_output')\n",
    "evaluation_model = os.path.join(training_output, 'evaluation_model')\n",
    "regular_model = os.path.join(training_output, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(survey_results_path) or not os.path.isfile(survey_schema_path):\n",
    "  print('Error: the data files are missing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get CSV headers as a list of column names.\n",
    "with open(survey_schema_path, 'r') as f:\n",
    "  reader = csv.reader(f)\n",
    "  next(reader) # skip header\n",
    "  headers = [r[0] for r in reader]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the data with MLWorkbench, the data needs to be cleaned in a few ways:\n",
    "\n",
    "* missing values sould be missing in the csv file, not 'NA'. \n",
    "* for multiple categorical columns, the data has each value separated by a semicolon but  mlworkbench separates tokens by spaces\n",
    "* some columns have non-ascii values, but only ascii is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_multi_label_cols(v):\n",
    "  \"\"\"Make labels 1 token long.\n",
    "  Example:\n",
    "      Before: Stock options; Annual bonus; Vacation/days off; Equipment; Meals\n",
    "      After: Stock_options Annual_bonus Vacation/days_off Equipment Meals\n",
    "  \"\"\"\n",
    "  if isinstance(v, float):\n",
    "    return v\n",
    "  v = v.replace('; ', ';')\n",
    "  v = v.replace(' ', '_')\n",
    "  v = v.replace(';', ' ')\n",
    "  return v\n",
    "\n",
    "def convert_to_ascii(v):\n",
    "  \"\"\"Remove non-ascii characters.\"\"\"\n",
    "  if isinstance(v, (float, int)):\n",
    "    return v\n",
    "  return filter(lambda x: x in set(string.printable), v)\n",
    "  #return re.sub(r'[^\\x00-\\x7f]',r'', v)  # remove non-ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_label_cols = []\n",
    "numerical_cols = []\n",
    "multi_label_cols = []\n",
    "key_cols = []\n",
    "target_col = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "hiddenCell": true
   },
   "outputs": [],
   "source": [
    "key_cols.append('Respondent')\n",
    "target_col = 'Professional'\n",
    "single_label_cols.append('ProgramHobby')\n",
    "single_label_cols.append('Country')\n",
    "single_label_cols.append('University')\n",
    "single_label_cols.append('EmploymentStatus')\n",
    "single_label_cols.append('FormalEducation')\n",
    "single_label_cols.append('MajorUndergrad')\n",
    "single_label_cols.append('HomeRemote')\n",
    "single_label_cols.append('CompanySize') # bucket range\n",
    "single_label_cols.append('CompanyType')\n",
    "single_label_cols.append('YearsProgram') # bucket range\n",
    "single_label_cols.append('YearsCodedJob') # bucket range\n",
    "single_label_cols.append('YearsCodedJobPast') # bucket range\n",
    "multi_label_cols.append('DeveloperType')\n",
    "single_label_cols.append('WebDeveloperType')\n",
    "multi_label_cols.append('MobileDeveloperType')\n",
    "multi_label_cols.append('NonDeveloperType')\n",
    "numerical_cols.append('CareerSatisfaction')\n",
    "numerical_cols.append('JobSatisfaction')\n",
    "single_label_cols.append('ExCoderReturn')\n",
    "single_label_cols.append('ExCoderNotForMe')\n",
    "single_label_cols.append('ExCoderBalance')\n",
    "single_label_cols.append('ExCoder10Years')\n",
    "single_label_cols.append('ExCoderBelonged')\n",
    "single_label_cols.append('ExCoderSkills')\n",
    "single_label_cols.append('ExCoderWillNotCode')\n",
    "single_label_cols.append('ExCoderActive')\n",
    "single_label_cols.append('PronounceGIF')\n",
    "single_label_cols.append('ProblemSolving')\n",
    "single_label_cols.append('BuildingThings')\n",
    "single_label_cols.append('LearningNewTech')\n",
    "single_label_cols.append('BoringDetails')\n",
    "single_label_cols.append('JobSecurity')\n",
    "single_label_cols.append('DiversityImportant')\n",
    "single_label_cols.append('AnnoyingUI')\n",
    "single_label_cols.append('FriendsDevelopers')\n",
    "single_label_cols.append('RightWrongWay')\n",
    "single_label_cols.append('UnderstandComputers')\n",
    "single_label_cols.append('SeriousWork')\n",
    "single_label_cols.append('InvestTimeTools')\n",
    "single_label_cols.append('WorkPayCare')\n",
    "single_label_cols.append('KinshipDevelopers')\n",
    "single_label_cols.append('ChallengeMyself')\n",
    "single_label_cols.append('CompetePeers')\n",
    "single_label_cols.append('ChangeWorld')\n",
    "single_label_cols.append('JobSeekingStatus')\n",
    "numerical_cols.append('HoursPerWeek')\n",
    "single_label_cols.append('LastNewJob') # bucket range\n",
    "single_label_cols.append('AssessJobIndustry')\n",
    "single_label_cols.append('AssessJobRole')\n",
    "single_label_cols.append('AssessJobExp')\n",
    "single_label_cols.append('AssessJobDept')\n",
    "single_label_cols.append('AssessJobTech')\n",
    "single_label_cols.append('AssessJobProjects')\n",
    "single_label_cols.append('AssessJobCompensation')\n",
    "single_label_cols.append('AssessJobOffice')\n",
    "single_label_cols.append('AssessJobCommute')\n",
    "single_label_cols.append('AssessJobRemote')\n",
    "single_label_cols.append('AssessJobLeaders')\n",
    "single_label_cols.append('AssessJobProfDevel')\n",
    "single_label_cols.append('AssessJobDiversity')\n",
    "single_label_cols.append('AssessJobProduct')\n",
    "single_label_cols.append('AssessJobFinances')\n",
    "multi_label_cols.append('ImportantBenefits')\n",
    "single_label_cols.append('ClickyKeys')\n",
    "multi_label_cols.append('JobProfile')\n",
    "single_label_cols.append('ResumePrompted')\n",
    "single_label_cols.append('LearnedHiring')\n",
    "single_label_cols.append('ImportantHiringAlgorithms')\n",
    "single_label_cols.append('ImportantHiringTechExp')\n",
    "single_label_cols.append('ImportantHiringCommunication')\n",
    "single_label_cols.append('ImportantHiringOpenSource')\n",
    "single_label_cols.append('ImportantHiringPMExp')\n",
    "single_label_cols.append('ImportantHiringCompanies')\n",
    "single_label_cols.append('ImportantHiringTitles')\n",
    "single_label_cols.append('ImportantHiringEducation')\n",
    "single_label_cols.append('ImportantHiringRep')\n",
    "single_label_cols.append('ImportantHiringGettingThingsDone')\n",
    "single_label_cols.append('Currency')\n",
    "single_label_cols.append('Overpaid')\n",
    "single_label_cols.append('TabsSpaces')\n",
    "single_label_cols.append('EducationImportant')\n",
    "multi_label_cols.append('EducationTypes')\n",
    "multi_label_cols.append('SelfTaughtTypes')\n",
    "single_label_cols.append('TimeAfterBootcamp')\n",
    "multi_label_cols.append('CousinEducation')\n",
    "single_label_cols.append('WorkStart')\n",
    "multi_label_cols.append('HaveWorkedLanguage')\n",
    "multi_label_cols.append('WantWorkLanguage')\n",
    "multi_label_cols.append('HaveWorkedFramework')\n",
    "multi_label_cols.append('WantWorkFramework')\n",
    "multi_label_cols.append('HaveWorkedDatabase')\n",
    "multi_label_cols.append('WantWorkDatabase')\n",
    "multi_label_cols.append('HaveWorkedPlatform')\n",
    "multi_label_cols.append('WantWorkPlatform')\n",
    "multi_label_cols.append('IDE')\n",
    "single_label_cols.append('AuditoryEnvironment')\n",
    "multi_label_cols.append('Methodology')\n",
    "single_label_cols.append('VersionControl')\n",
    "single_label_cols.append('CheckInCode')\n",
    "single_label_cols.append('ShipIt')\n",
    "single_label_cols.append('OtherPeoplesCode')\n",
    "single_label_cols.append('ProjectManagement')\n",
    "single_label_cols.append('EnjoyDebugging')\n",
    "single_label_cols.append('InTheZone')\n",
    "single_label_cols.append('DifficultCommunication')\n",
    "single_label_cols.append('CollaborateRemote')\n",
    "multi_label_cols.append('MetricAssess')\n",
    "single_label_cols.append('EquipmentSatisfiedMonitors')\n",
    "single_label_cols.append('EquipmentSatisfiedCPU')\n",
    "single_label_cols.append('EquipmentSatisfiedRAM')\n",
    "single_label_cols.append('EquipmentSatisfiedStorage')\n",
    "single_label_cols.append('EquipmentSatisfiedRW')\n",
    "single_label_cols.append('InfluenceInternet')\n",
    "single_label_cols.append('InfluenceWorkstation')\n",
    "single_label_cols.append('InfluenceHardware')\n",
    "single_label_cols.append('InfluenceServers')\n",
    "single_label_cols.append('InfluenceTechStack')\n",
    "single_label_cols.append('InfluenceDeptTech')\n",
    "single_label_cols.append('InfluenceVizTools')\n",
    "single_label_cols.append('InfluenceDatabase')\n",
    "single_label_cols.append('InfluenceCloud')\n",
    "single_label_cols.append('InfluenceConsultants')\n",
    "single_label_cols.append('InfluenceRecruitment')\n",
    "single_label_cols.append('InfluenceCommunication')\n",
    "single_label_cols.append('StackOverflowDescribes')\n",
    "numerical_cols.append('StackOverflowSatisfaction')\n",
    "multi_label_cols.append('StackOverflowDevices')\n",
    "single_label_cols.append('StackOverflowFoundAnswer')\n",
    "single_label_cols.append('StackOverflowCopiedCode')\n",
    "single_label_cols.append('StackOverflowJobListing')\n",
    "single_label_cols.append('StackOverflowCompanyPage')\n",
    "single_label_cols.append('StackOverflowJobSearch')\n",
    "single_label_cols.append('StackOverflowNewQuestion')\n",
    "single_label_cols.append('StackOverflowAnswer')\n",
    "single_label_cols.append('StackOverflowMetaChat')\n",
    "single_label_cols.append('StackOverflowAdsRelevant')\n",
    "single_label_cols.append('StackOverflowAdsDistracting')\n",
    "single_label_cols.append('StackOverflowModeration')\n",
    "single_label_cols.append('StackOverflowCommunity')\n",
    "single_label_cols.append('StackOverflowHelpful')\n",
    "single_label_cols.append('StackOverflowBetter')\n",
    "single_label_cols.append('StackOverflowWhatDo')\n",
    "single_label_cols.append('StackOverflowMakeMoney')\n",
    "single_label_cols.append('Gender')\n",
    "single_label_cols.append('HighestEducationParents')\n",
    "multi_label_cols.append('Race')\n",
    "single_label_cols.append('SurveyLong')\n",
    "single_label_cols.append('QuestionsInteresting')\n",
    "single_label_cols.append('QuestionsConfusing')\n",
    "single_label_cols.append('InterestedAnswers')\n",
    "numerical_cols.append('Salary')\n",
    "numerical_cols.append('ExpectedSalary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check we didn't miss a column\n",
    "assert len(single_label_cols + multi_label_cols + numerical_cols + key_cols + [target_col]) == len(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanup_df(df):\n",
    "  for col in headers:\n",
    "    df[col] = df[col].apply(convert_to_ascii)\n",
    "    \n",
    "    if col in multi_label_cols:\n",
    "      df[col] = df[col].apply(update_multi_label_cols)\n",
    "\n",
    "df_all = pd.read_csv(survey_results_path, header=0, names=headers)\n",
    "cleanup_df(df_all)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6232773056004386"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "random_index = []\n",
    "for i in range(len(df_all)):\n",
    "  if random.random() < 0.8:\n",
    "    random_index.append(True)\n",
    "  else:\n",
    "    random_index.append(False)\n",
    "  \n",
    "\n",
    "\n",
    "#df_all.to_csv('/content/datalab/so/cleaned_train.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array(random_index)\n",
    "df_train = df_all[x]\n",
    "df_eval = df_all[np.logical_not(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_train.to_csv(train_data_path, header=False, index=False)\n",
    "df_eval.to_csv(eval_data_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schema = []\n",
    "for h in headers:\n",
    "  entry = {'name': h}\n",
    "  if h in numerical_cols:\n",
    "    entry['type']= 'FLOAT'\n",
    "  elif h in key_cols:\n",
    "    entry['type'] = 'INTEGER'\n",
    "  else:\n",
    "    entry['type'] = 'STRING'\n",
    "  schema.append(entry)\n",
    "  \n",
    "\n",
    "with open(schema_path, 'w') as f:\n",
    "  f.write(json.dumps(schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transforms = {}\n",
    "for h in headers:\n",
    "  if h in numerical_cols:\n",
    "    transform = 'scale'\n",
    "  elif h in key_cols:\n",
    "    transform = 'key'\n",
    "  elif h == target_col:\n",
    "    transform = 'target'\n",
    "  elif h in multi_label_cols:\n",
    "    transform = 'bag_of_words'\n",
    "  elif h in single_label_cols:\n",
    "    transform = 'one_hot'\n",
    "  else:\n",
    "    print('Error: %s is an unknown label' % h)\n",
    "    break\n",
    "  \n",
    "  transforms[h] = {'transform': transform}\n",
    "  \n",
    "with open(transform_path, 'w') as f:\n",
    "  f.write(json.dumps(transforms))\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import google.datalab.contrib.mlworkbench.commands\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding any file patterns...\n",
      "file list computed.\n",
      "Analyzing file /content/datalab/workspace/structured_data_classification_stackoverflow/train.csv...\n",
      "file /content/datalab/workspace/structured_data_classification_stackoverflow/train.csv analyzed.\n"
     ]
    }
   ],
   "source": [
    "%%ml analyze\n",
    "output: $analyze_output\n",
    "training_data:\n",
    "    csv: $train_data_path\n",
    "    schema: $schema\n",
    "features: $transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls $analyze_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each transform step shoud take at most a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -r -f $transform_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-13 21:02:34.845079: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:02:34.845427: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:02:34.846021: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:02:34.846057: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:02:34.846074: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "WARNING:root:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    }
   ],
   "source": [
    "%%ml transform\n",
    "output: $transform_output\n",
    "analysis: $analyze_output\n",
    "prefix: features_train\n",
    "training_data:\n",
    "    csv: $train_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-13 21:07:55.577418: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:07:55.577467: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:07:55.578654: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:07:55.578737: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:07:55.578766: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "WARNING:root:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    }
   ],
   "source": [
    "%%ml transform\n",
    "output: $transform_output\n",
    "analysis: $analyze_output\n",
    "prefix: features_eval\n",
    "training_data:\n",
    "    csv: $eval_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /content/datalab/workspace/structured_data_classification_stackoverflow/transform_output/errors_features_eval-00000-of-00001.txt\r\n",
      "0 /content/datalab/workspace/structured_data_classification_stackoverflow/transform_output/errors_features_train-00000-of-00001.txt\r\n",
      "0 total\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l $transform_output/errors*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f75a83b7710>, '_model_dir': '/content/datalab/workspace/structured_data_classification_stackoverflow/training_output/train', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:268: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "2017-07-13 21:10:08.999840: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:10:08.999877: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:10:08.999902: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:10:08.999922: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-13 21:10:08.999943: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /content/datalab/workspace/structured_data_classification_stackoverflow/training_output/train/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.02217, step = 1\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-13-21:10:24\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/workspace/structured_data_classification_stackoverflow/training_output/train/model.ckpt-1\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-13-21:10:27\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.706584, global_step = 1, loss = 1.28131\n",
      "INFO:tensorflow:Validation (step 100): loss = 1.28131, global_step = 1, accuracy = 0.706584\n",
      "INFO:tensorflow:global_step/sec: 7.08637\n",
      "INFO:tensorflow:loss = 0.145726, step = 101 (14.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.4329\n",
      "INFO:tensorflow:loss = 0.0547353, step = 201 (1.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.4772\n",
      "INFO:tensorflow:loss = 0.144997, step = 301 (1.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.766\n",
      "INFO:tensorflow:loss = 0.0197796, step = 401 (1.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.9727\n",
      "INFO:tensorflow:loss = 0.0137578, step = 501 (1.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.7899\n",
      "INFO:tensorflow:loss = 0.0213923, step = 601 (1.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.4912\n",
      "INFO:tensorflow:loss = 0.0493225, step = 701 (1.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.9136\n",
      "INFO:tensorflow:loss = 0.0282216, step = 801 (1.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.6203\n",
      "INFO:tensorflow:loss = 0.0472284, step = 901 (1.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.6174\n",
      "INFO:tensorflow:loss = 0.119151, step = 1001 (1.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.5114\n",
      "INFO:tensorflow:loss = 0.00523737, step = 1101 (1.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.0303\n",
      "INFO:tensorflow:loss = 0.0230707, step = 1201 (1.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.2465\n",
      "INFO:tensorflow:loss = 0.0119879, step = 1301 (1.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.6255\n",
      "INFO:tensorflow:loss = 0.0359177, step = 1401 (1.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.2992\n",
      "INFO:tensorflow:loss = 0.0118677, step = 1501 (1.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.7239\n",
      "INFO:tensorflow:loss = 0.0259728, step = 1601 (1.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0206\n",
      "INFO:tensorflow:loss = 0.0510993, step = 1701 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.8786\n",
      "INFO:tensorflow:loss = 0.0174603, step = 1801 (1.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.8876\n",
      "INFO:tensorflow:loss = 0.0239931, step = 1901 (1.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.595\n",
      "INFO:tensorflow:loss = 0.0036418, step = 2001 (1.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.4087\n",
      "INFO:tensorflow:loss = 0.00639292, step = 2101 (1.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.5196\n",
      "INFO:tensorflow:loss = 0.0898198, step = 2201 (1.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.8581\n",
      "INFO:tensorflow:loss = 0.0467836, step = 2301 (1.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.1337\n",
      "INFO:tensorflow:loss = 0.029951, step = 2401 (1.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.2062\n",
      "INFO:tensorflow:loss = 0.0112023, step = 2501 (1.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.819\n",
      "INFO:tensorflow:loss = 0.0682854, step = 2601 (1.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.6364\n",
      "INFO:tensorflow:loss = 0.00853891, step = 2701 (1.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.9959\n",
      "INFO:tensorflow:loss = 0.0109381, step = 2801 (2.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6827\n",
      "INFO:tensorflow:loss = 0.0777121, step = 2901 (1.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.9863\n",
      "INFO:tensorflow:loss = 0.00827544, step = 3001 (1.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.064\n",
      "INFO:tensorflow:loss = 0.000887022, step = 3101 (1.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.8037\n",
      "INFO:tensorflow:loss = 0.0334537, step = 3201 (2.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.5843\n",
      "INFO:tensorflow:loss = 0.0512866, step = 3301 (2.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.3179\n",
      "INFO:tensorflow:loss = 0.00638802, step = 3401 (1.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.0591\n",
      "INFO:tensorflow:loss = 0.00140299, step = 3501 (1.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.823\n",
      "INFO:tensorflow:loss = 0.0323066, step = 3601 (1.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.6753\n",
      "INFO:tensorflow:loss = 0.00483707, step = 3701 (1.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.7373\n",
      "INFO:tensorflow:loss = 0.00534589, step = 3801 (1.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.4691\n",
      "INFO:tensorflow:loss = 0.00487623, step = 3901 (1.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.0209\n",
      "INFO:tensorflow:loss = 0.00344864, step = 4001 (1.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.2225\n",
      "INFO:tensorflow:loss = 0.0211403, step = 4101 (1.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.053\n",
      "INFO:tensorflow:loss = 0.00458628, step = 4201 (1.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.488\n",
      "INFO:tensorflow:loss = 0.0517983, step = 4301 (1.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.4123\n",
      "INFO:tensorflow:loss = 0.0177343, step = 4401 (1.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.9378\n",
      "INFO:tensorflow:loss = 0.00805941, step = 4501 (1.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.946\n",
      "INFO:tensorflow:loss = 0.0177224, step = 4601 (1.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7049\n",
      "INFO:tensorflow:loss = 0.021637, step = 4701 (1.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.5093\n",
      "INFO:tensorflow:loss = 0.0159268, step = 4801 (1.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.3264\n",
      "INFO:tensorflow:loss = 0.000202814, step = 4901 (1.554 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /content/datalab/workspace/structured_data_classification_stackoverflow/training_output/train/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00128838.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-13-21:12:01\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/workspace/structured_data_classification_stackoverflow/training_output/train/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-13-21:12:04\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.982449, global_step = 5000, loss = 0.0667044\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/workspace/structured_data_classification_stackoverflow/training_output/train/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/workspace/structured_data_classification_stackoverflow/training_output/train/export/intermediate_prediction_models/1499980333/saved_model.pb\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/workspace/structured_data_classification_stackoverflow/training_output/train/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/workspace/structured_data_classification_stackoverflow/training_output/train/export/intermediate_evaluation_models/1499980343/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "%%ml train\n",
    "output: $training_output\n",
    "analysis: $analyze_output\n",
    "training_data:\n",
    "    transformed: $transformed_train_pattern\n",
    "evaluation_data:\n",
    "    transformed: $transformed_eval_pattern\n",
    "model_args:\n",
    "    model: dnn_classification\n",
    "    hidden-layer-size1: 100\n",
    "    max-steps: 5000\n",
    "    top-n: 2\n",
    "    save-checkpoints-secs: 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head /content/datalab/so/cleaned_eval.csv -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers_string = ','.join(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%ml predict --model /content/datalab/so/model/evaluation_model --headers $headers_string\n",
    "prediction_data:\n",
    "- 2,Student,Yes both,United Kingdom,Yes full-time,Employed part-time,Some college/university study without earning a bachelors degree,Computer science or software engineering,More than half but not all the time,20 to 99 employees,Privately-held limited company not in startup mode,9.0,,,,,,,,,,,,,,,,,With a hard g like gift,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,Other,,Some other way,Important,Important,Important,Important,Somewhat important,Somewhat important,Not very important,Somewhat important,Not very important,Very important,British pounds sterling (),,Spaces,,Online course  Self-taught  Hackathon  Open source contributions,Official documentation  Stack Overflow Q&A  Other,,,10:00 AM,JavaScript  Python  Ruby  SQL,Java  Python  Ruby  SQL,.NET Core,.NET Core,MySQL  SQLite,MySQL  SQLite,Amazon Web Services (AWS),Linux Desktop  Raspberry Pi  Amazon Web Services (AWS),Atom  Notepad++  Vim  PyCharm  RubyMine  Visual Studio  Visual Studio Code,Put on some ambient sounds (e.g. whale songs forest sounds),,Git,Multiple times a day,Agree,Disagree,Strongly disagree,Agree,Somewhat agree,Disagree,Strongly disagree,Customer satisfaction  On time/in budget  Peers rating  Self-rating,Not very satisfied,Satisfied,Satisfied,Satisfied,Somewhat satisfied,Satisfied,No influence at all,No influence at all,No influence at all,No influence at all,No influence at all,No influence at all,No influence at all,No influence at all,No influence at all,No influence at all,No influence at all,I have created a CV or Developer Story on Stack Overflow,8.0,Desktop  iOS browser  iOS app  Android browser  Android app,Several times,Several times,Once or twice,Once or twice,Once or twice,Havent done at all,Several times,At least once each week,Disagree,Strongly disagree,Strongly disagree,Strongly agree,Agree,Strongly agree,Strongly agree,-2.0,Male,A masters degree,White or of European descent,Somewhat agree,Somewhat agree,Disagree,Strongly agree,,37500.0\n",
    "- 4,Professional non-developer who sometimes writes code,Yes both,United States,No,Employed full-time,Doctoral degree,A non-computer-focused engineering discipline,Less than half the time but at least one day each week,10000 or more employees,Non-profit/non-governmental organization or private school/university,14.0,9.0,,,,,Data scientist,6.0,3.0,,,,,,,,,With a soft g like jiff,2.0,2.0,2.0,-1.0,0.0,1.0,1.0,1.0,0.0,-2.0,2.0,1.0,-1.0,2.0,2.0,0.0,1.0,I am actively looking for a job,5.0,Between 2 and 4 years ago,Somewhat important,Somewhat important,Somewhat important,Important,Important,Very important,Important,Very important,Important,Somewhat important,Not very important,Very important,Important,Very important,Very important,Stock options  Annual bonus  Health benefits  Equipment  Private office,Yes,LinkedIn  Other,,A friend family member or former colleague told me,Somewhat important,Somewhat important,Very important,Very important,Somewhat important,Somewhat important,Not very important,Not very important,Important,Very important,,,Spaces,,,,,,9:00 AM,Matlab  Python  R  SQL,Matlab  Python  R  SQL,React,Hadoop  Node.js  React,MongoDB  Redis  SQL Server  MySQL  SQLite,MongoDB  Redis  SQL Server  MySQL  SQLite,Windows Desktop  Linux Desktop  Mac OS  Amazon Web Services (AWS),Windows Desktop  Linux Desktop  Mac OS  Amazon Web Services (AWS),Notepad++  Sublime Text  TextMate  Vim  IPython / Jupyter  NetBeans  PyCharm  Xcode,Turn on some music,Agile,Git,Multiple times a day,Somewhat agree,Agree,Somewhat agree,Somewhat agree,Strongly agree,Disagree,Somewhat agree,,,,,,,,,,,,,,,,,,,I have created a CV or Developer Story on Stack Overflow,10.0,Desktop  iOS browser  iOS app,At least once each week,Several times,At least once each week,Several times,At least once each week,Several times,At least once each day,At least once each day,Agree,Strongly disagree,Strongly disagree,Strongly agree,Strongly agree,Agree,Strongly agree,-1.0,Male,A doctoral degree,White or of European descent,Agree,Agree,Somewhat agree,Strongly agree,,\n",
    "- 5,Professional developer,Yes I program as a hobby,Switzerland,No,Employed full-time,Masters degree,Computer science or software engineering,Never,10 to 19 employees,Privately-held limited company not in startup mode,21.0,10.0,,Mobile developer  Graphics programming  Desktop applications developer,,,,6.0,8.0,,,,,,,,,With a soft g like jiff,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Satisfied,Satisfied,Satisfied,Satisfied,Satisfied,Satisfied,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%ml batch_predict --model /content/datalab/so/model/evaluation_model  --output_dir /content/datalab/so/predict --output_format csv\n",
    "prediction_data:\n",
    "  csv_file_pattern: /content/datalab/so/cleaned_eval.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls /content/datalab/so/predict/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open('/content/datalab/so/predict/predict_results_schema.json', 'r') as f:\n",
    "  predict_schema = json.load(f)\n",
    "  \n",
    "df = pd.read_csv('/content/datalab/so/predict/predict_results_cleaned_eval.csv', header=None, names=[x['name'] for x in predict_schema])\n",
    "correct = sum([1 if row['predicted'] == row['target'] else 0 for index, row in df.iterrows()])\n",
    "accuracy = correct / float(len(df.index))\n",
    "print('accuracy = %f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import ConfusionMatrix\n",
    "\n",
    "cm = ConfusionMatrix.from_csv('/content/datalab/so/predict/predict_results_cleaned_eval.csv', headers=[x['name'] for x in predict_schema])\n",
    "cm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
