{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "\n",
    "This notebook assumes you have ran the local Census Regression notebook and you have not deleted the LOCAL_ROOT folder.In this notebook, we will train a Tensorflow model using the Google Cloud Machine Learning Engine training service. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mltoolbox.regression.dnn as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import google.datalab.ml as ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will write files during training. Please give a root folder you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://cloud-ml-dev-census-regression-datalab/...\n",
      "ServiceException: 409 Bucket cloud-ml-dev-census-regression-datalab already exists.\n"
     ]
    }
   ],
   "source": [
    "LOCAL_ROOT = './census_regression_workspace' # This should be the same as what was used in the local notebook\n",
    "CLOUD_ROOT = 'gs://' + datalab_project_id() + '-census-regression-datalab'\n",
    "\n",
    "# No need to edit anything else in this cell.\n",
    "LOCAL_PREPROCESSING_DIR = os.path.join(LOCAL_ROOT, 'preprocessing')\n",
    "CLOUD_PREPROCESSING_DIR = os.path.join(CLOUD_ROOT, 'preprocessing')\n",
    "\n",
    "CLOUD_TRAINING_DIR = os.path.join(CLOUD_ROOT, 'cloud_training')\n",
    "\n",
    "LOCAL_TRAIN_FILE = os.path.join(LOCAL_ROOT, 'train.csv')\n",
    "CLOUD_TRAIN_FILE = os.path.join(CLOUD_ROOT, 'train.csv')\n",
    "\n",
    "LOCAL_EVAL_FILE = os.path.join(LOCAL_ROOT, 'eval.csv')\n",
    "CLOUD_EVAL_FILE = os.path.join(CLOUD_ROOT, 'eval.csv')\n",
    "\n",
    "LOCAL_SCHEMA_FILE = os.path.join(LOCAL_ROOT, 'schema.json')\n",
    "CLOUD_SCHEMA_FILE = os.path.join(CLOUD_ROOT, 'schema.json')\n",
    "\n",
    "LOCAL_FEATURES_FILE = os.path.join(LOCAL_ROOT, 'features.json')\n",
    "CLOUD_FEATURES_FILE = os.path.join(CLOUD_ROOT, 'features.json')\n",
    "\n",
    "if not file_io.file_exists(LOCAL_ROOT):\n",
    "  raise ValueError('LOCAL_ROOT not found. Did you run the local notebook?')\n",
    "  \n",
    "!gsutil mb {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us put the csv files on GCS and the output of preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./census_regression_workspace/train.csv [Content-Type=text/csv]...\n",
      "/ [1/1 files][162.9 KiB/162.9 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/162.9 KiB.                                    \n",
      "Copying file://./census_regression_workspace/eval.csv [Content-Type=text/csv]...\n",
      "/ [1/1 files][ 18.8 KiB/ 18.8 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/18.8 KiB.                                     \n",
      "Copying file://./census_regression_workspace/features.json [Content-Type=application/json]...\n",
      "/ [1/1 files][  996.0 B/  996.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/996.0 B.                                      \n",
      "Copying file://./census_regression_workspace/schema.json [Content-Type=application/json]...\n",
      "/ [1/1 files][  998.0 B/  998.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/998.0 B.                                      \n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_ESR.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_SERIALNO.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_COW.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_AGEP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_SEX.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/stats.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_SCIENGRLP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_JWTR.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_INDP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_PUMA.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_HINS4.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_SCHL.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_ESP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_RAC1P.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_JWMNP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_FOD1P.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_MAR.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_POWPUMA.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_WKW.csv [Content-Type=text/csv]...\n",
      "-\n",
      "Operation completed over 20 objects/16.8 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp {LOCAL_TRAIN_FILE} {CLOUD_TRAIN_FILE}\n",
    "!gsutil -m cp {LOCAL_EVAL_FILE} {CLOUD_EVAL_FILE}\n",
    "!gsutil -m cp {LOCAL_FEATURES_FILE} {CLOUD_FEATURES_FILE}\n",
    "!gsutil -m cp {LOCAL_SCHEMA_FILE} {CLOUD_SCHEMA_FILE}\n",
    "!gsutil -m cp -r {LOCAL_PREPROCESSING_DIR} {CLOUD_PREPROCESSING_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training using the ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/staging/trainer.tar.gz#1488838034078612...\n",
      "/ [1/1 objects] 100% Done                                                       \n",
      "Operation completed over 1 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -r {CLOUD_TRAINING_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_csv = ml.CsvDataSet(\n",
    "  file_pattern=CLOUD_TRAIN_FILE,\n",
    "  schema_file=CLOUD_SCHEMA_FILE)\n",
    "eval_csv = ml.CsvDataSet(\n",
    "  file_pattern=CLOUD_EVAL_FILE,\n",
    "  schema_file=CLOUD_SCHEMA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctc = ml.CloudTrainingConfig(\n",
    "  region='us-central1',\n",
    "  scale_tier='STANDARD_1' #See https://cloud.google.com/ml/reference/rest/v1beta1/projects.jobs#ScaleTier\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://cloud-ml-dev-census-regression-datalab/cloud_training/staging/trainer.tar.gz\n",
      "Job request send. View status of job at\n",
      "https://console.developers.google.com/ml/jobs?project=cloud-ml-dev\n"
     ]
    }
   ],
   "source": [
    "sd.train(\n",
    "  cloud=ctc,\n",
    "  train_dataset=train_csv,\n",
    "  eval_dataset=eval_csv,\n",
    "  features=CLOUD_FEATURES_FILE,\n",
    "  analysis_dir=CLOUD_PREPROCESSING_DIR,\n",
    "  output_dir=CLOUD_TRAINING_DIR,\n",
    "  max_steps=2000,\n",
    "  layer_sizes=[10, 8, 5],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training is done, CLOUD_TRAINING_DIRshould contain the folders train, model, evaluation_model, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-census-regression-datalab/cloud_training/staging/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls  {CLOUD_TRAINING_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning things up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to delete the files you made on GCS, uncomment and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!gsutil rm -fr {CLOUD_ROOT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
