{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "\n",
    "This notebook assumes you have ran the local Census Regression notebook and you have not deleted the LOCAL_ROOT folder.In this notebook, we will train a Tensorflow model using the Google Cloud Machine Learning Engine training service. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mltoolbox.regression.dnn as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import google.datalab.ml as ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will write files during training. Please give a root folder you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://cloud-ml-dev-census-regression-datalab/...\n",
      "ServiceException: 409 Bucket cloud-ml-dev-census-regression-datalab already exists.\n"
     ]
    }
   ],
   "source": [
    "LOCAL_ROOT = './census_regression_workspace' # This should be the same as what was used in the local notebook\n",
    "CLOUD_ROOT = 'gs://' + datalab_project_id() + '-census-regression-datalab'\n",
    "\n",
    "# No need to edit anything else in this cell.\n",
    "LOCAL_PREPROCESSING_DIR = os.path.join(LOCAL_ROOT, 'preprocessing')\n",
    "CLOUD_PREPROCESSING_DIR = os.path.join(CLOUD_ROOT, 'preprocessing')\n",
    "\n",
    "CLOUD_TRAINING_DIR = os.path.join(CLOUD_ROOT, 'cloud_training')\n",
    "\n",
    "LOCAL_TRAIN_FILE = os.path.join(LOCAL_ROOT, 'train.csv')\n",
    "CLOUD_TRAIN_FILE = os.path.join(CLOUD_ROOT, 'train.csv')\n",
    "\n",
    "LOCAL_EVAL_FILE = os.path.join(LOCAL_ROOT, 'eval.csv')\n",
    "CLOUD_EVAL_FILE = os.path.join(CLOUD_ROOT, 'eval.csv')\n",
    "\n",
    "LOCAL_SCHEMA_FILE = os.path.join(LOCAL_ROOT, 'schema.json')\n",
    "CLOUD_SCHEMA_FILE = os.path.join(CLOUD_ROOT, 'schema.json')\n",
    "\n",
    "LOCAL_FEATURES_FILE = os.path.join(LOCAL_ROOT, 'features.json')\n",
    "CLOUD_FEATURES_FILE = os.path.join(CLOUD_ROOT, 'features.json')\n",
    "\n",
    "if not file_io.file_exists(LOCAL_ROOT):\n",
    "  raise ValueError('LOCAL_ROOT not found. Did you run the local notebook?')\n",
    "  \n",
    "!gsutil mb {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us put the csv files on GCS and the output of preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./census_regression_workspace/train.csv [Content-Type=text/csv]...\n",
      "/ [1/1 files][162.9 KiB/162.9 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/162.9 KiB.                                    \n",
      "Copying file://./census_regression_workspace/eval.csv [Content-Type=text/csv]...\n",
      "/ [1/1 files][ 18.8 KiB/ 18.8 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/18.8 KiB.                                     \n",
      "Copying file://./census_regression_workspace/features.json [Content-Type=application/json]...\n",
      "/ [1/1 files][  996.0 B/  996.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/996.0 B.                                      \n",
      "Copying file://./census_regression_workspace/schema.json [Content-Type=application/json]...\n",
      "/ [1/1 files][  998.0 B/  998.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/998.0 B.                                      \n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_ESP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_COW.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_PUMA.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_SERIALNO.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_SCIENGRLP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_HINS4.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_AGEP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_ESR.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_SCHL.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/numerical_analysis.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_JWTR.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_RAC1P.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_SEX.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_POWPUMA.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_JWMNP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_INDP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_WKW.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_MAR.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocessing/vocab_FOD1P.csv [Content-Type=text/csv]...\n",
      "-\n",
      "Operation completed over 20 objects/16.8 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp {LOCAL_TRAIN_FILE} {CLOUD_TRAIN_FILE}\n",
    "!gsutil -m cp {LOCAL_EVAL_FILE} {CLOUD_EVAL_FILE}\n",
    "!gsutil -m cp {LOCAL_FEATURES_FILE} {CLOUD_FEATURES_FILE}\n",
    "!gsutil -m cp {LOCAL_SCHEMA_FILE} {CLOUD_SCHEMA_FILE}\n",
    "!gsutil -m cp -r {LOCAL_PREPROCESSING_DIR} {CLOUD_PREPROCESSING_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training using the ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/evaluation_model/#1488560966515337...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/evaluation_model/assets.extra/#1488560968322702...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/evaluation_model/assets.extra/schema.json#1488560969263660...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/evaluation_model/assets.extra/transforms.json#1488560970156747...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/evaluation_model/saved_model.pb#1488560967430957...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/evaluation_model/variables/#1488560971530326...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/evaluation_model/variables/variables.data-00000-of-00001#1488560972354468...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/evaluation_model/variables/variables.index#1488560973040578...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/model/#1488560989258126...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/model/assets.extra/#1488560991809101...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/model/assets.extra/schema.json#1488560992695679...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/model/assets.extra/transforms.json#1488560993376197...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/model/saved_model.pb#1488560991053480...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/model/variables/#1488560994158671...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/model/variables/variables.data-00000-of-00001#1488560995182743...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/model/variables/variables.index#1488560995923540...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/#1488560924167399...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/staging/sd.tar.gz#1488560316906507...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/checkpoint#1488560929276487...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/eval/#1488560914638560...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_prediction_models/1488560975606/variables/variables.data-00000-of-00001#1488560982905424...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_evaluation_models/1488560949779/variables/#1488560956864415...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/eval/events.out.tfevents.1488560915.master-8014c42d8a-0-7kjqt#1488560918064344...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/eval/events.out.tfevents.1488560944.master-8014c42d8a-0-7kjqt#1488560947402767...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_prediction_models/1488560975606/variables/variables.index#1488560983560679...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/graph.pbtxt#1488560892546216...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/events.out.tfevents.1488560638.master-8014c42d8a-0-7kjqt#1488560933589924...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/#1488560952388856...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_evaluation_models/#1488560952727254...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_evaluation_models/1488560949779/#1488560953136491...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/model.ckpt-249.data-00002-of-00003#1488560901972203...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_evaluation_models/1488560949779/assets.extra/#1488560962985280...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/model.ckpt-2004.data-00000-of-00003#1488560926820613...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_evaluation_models/1488560949779/assets.extra/transforms.json#1488560963644472...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_evaluation_models/1488560949779/assets.extra/schema.json#1488560965428106...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_prediction_models/1488560975606/assets.extra/#1488560986975930...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_prediction_models/1488560975606/assets.extra/schema.json#1488560988474430...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_evaluation_models/1488560949779/variables/variables.data-00000-of-00001#1488560957595123...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_prediction_models/1488560975606/assets.extra/transforms.json#1488560987701001...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_evaluation_models/1488560949779/variables/variables.index#1488560958813036...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_prediction_models/1488560975606/saved_model.pb#1488560986267201...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_prediction_models/#1488560978020607...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_prediction_models/1488560975606/variables/#1488560982270426...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/model.ckpt-2004.data-00001-of-00003#1488560926321892...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_evaluation_models/1488560949779/saved_model.pb#1488560962132745...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/model.ckpt-249.index#1488560903978751...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/model.ckpt-2004.data-00002-of-00003#1488560925744949...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/model.ckpt-2004.index#1488560927604975...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/model.ckpt-2004.meta#1488560932787830...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/model.ckpt-249.meta#1488560908846220...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/model.ckpt-249.data-00001-of-00003#1488560902598050...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/export/intermediate_prediction_models/1488560975606/#1488560978350968...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/model.ckpt-249.data-00000-of-00003#1488560903252321...\n",
      "/ [53/53 objects] 100% Done 0.00 objects/s                                      \n",
      "Operation completed over 53 objects.                                             \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -r {CLOUD_TRAINING_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_csv = ml.CsvDataSet(\n",
    "  file_pattern=CLOUD_TRAIN_FILE,\n",
    "  schema_file=CLOUD_SCHEMA_FILE)\n",
    "eval_csv = ml.CsvDataSet(\n",
    "  file_pattern=CLOUD_EVAL_FILE,\n",
    "  schema_file=CLOUD_SCHEMA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctc = ml.CloudTrainingConfig(\n",
    "  region='us-central1',\n",
    "  scale_tier='STANDARD_1' #See https://cloud.google.com/ml/reference/rest/v1beta1/projects.jobs#ScaleTier\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://cloud-ml-dev-census-regression-datalab/cloud_training/staging/sd.tar.gz\n",
      "Job request send. View status of job at\n",
      "https://console.developers.google.com/ml/jobs?project=cloud-ml-dev\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Job structured_data_train_170303_194419 completed"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = sd.train(\n",
    "  cloud=ctc,\n",
    "  train_dataset=train_csv,\n",
    "  eval_dataset=eval_csv,\n",
    "  features=CLOUD_FEATURES_FILE,\n",
    "  analysis_output_dir=CLOUD_PREPROCESSING_DIR,\n",
    "  output_dir=CLOUD_TRAINING_DIR,\n",
    "  max_steps=2000,\n",
    "  layer_sizes=[5, 5, 5],\n",
    ")\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training is done, CLOUD_TRAINING_DIRshould contain the folders train, model, evaluation_model, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-census-regression-datalab/cloud_training/evaluation_model/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/cloud_training/model/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/cloud_training/staging/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/cloud_training/train/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls  {CLOUD_TRAINING_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning things up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to delete the files you made on GCS, uncomment and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!gsutil rm -fr {CLOUD_ROOT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
