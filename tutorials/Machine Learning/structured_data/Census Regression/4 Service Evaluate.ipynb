{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "\n",
    "This notebook assumes you have ran the local Census Regression notebook and you have not deleted the LOCAL_ROOT folder. In this notebook, we will evaluate a trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mltoolbox.regression.dnn as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will write files during prediction. Please give a root folder you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://cloud-ml-dev-census-regression-datalab/...\n",
      "ServiceException: 409 Bucket cloud-ml-dev-census-regression-datalab already exists.\n"
     ]
    }
   ],
   "source": [
    "LOCAL_ROOT = './census_regression_workspace' # This should be the same as what was used in the local census notebook\n",
    "CLOUD_ROOT = 'gs://' + datalab_project_id() + '-census-regression-datalab'\n",
    "\n",
    "# No need to edit anything else in this cell.\n",
    "LOCAL_TRAINING_DIR = os.path.join(LOCAL_ROOT, 'training')\n",
    "CLOUD_TRAINING_DIR = os.path.join(CLOUD_ROOT, 'training')\n",
    "\n",
    "LOCAL_EVAL_FILE = os.path.join(LOCAL_ROOT, 'eval.csv')\n",
    "CLOUD_EVAL_FILE = os.path.join(CLOUD_ROOT, 'eval.csv')\n",
    "\n",
    "CLOUD_BATCH_PREDICTION_DIR = os.path.join(CLOUD_ROOT, 'batch_prediction')\n",
    "if not file_io.file_exists(LOCAL_ROOT):\n",
    "  raise ValueError('LOCAL_ROOT not found. Did you run the local notebook?')\n",
    "  \n",
    "!gsutil mb {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us put the csv files on GCS and the output of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./census_regression_workspace/eval.csv [Content-Type=text/csv]...\n",
      "/ [1/1 files][ 18.8 KiB/ 18.8 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/18.8 KiB.                                     \n",
      "Copying file://./census_regression_workspace/training/model/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/features_file.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/model/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/model/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/model/assets.extra/features.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/model/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/assets.extra/features.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-2000.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-2000.meta [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-2000.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/eval/events.out.tfevents.1488837831.e174955b2223 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/events.out.tfevents.1488837807.e174955b2223 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-1.meta [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/checkpoint [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/eval/events.out.tfevents.1488837818.e174955b2223 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-1.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/graph.pbtxt [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1488837837213/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1488837833621/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1488837837213/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1488837837213/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1488837837213/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1488837833621/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1488837833621/assets.extra/features.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1488837837213/assets.extra/features.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1488837833621/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1488837833621/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-1.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "- [32/32 files][  9.9 MiB/  9.9 MiB] 100% Done                                  \n",
      "Operation completed over 32 objects/9.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp {LOCAL_EVAL_FILE} {CLOUD_EVAL_FILE}\n",
    "!gsutil -m cp -r {LOCAL_TRAINING_DIR} {CLOUD_TRAINING_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-census-regression-datalab/training/features_file.json\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/training/evaluation_model/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/training/model/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/training/train/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/training/training/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {CLOUD_TRAINING_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"local_preprocessing\"></a>\n",
    "ML Engine Batch Prediction\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch prediction has two modes. In the 'evaluation' mode, the input data is expected to 100% match the training schema, meaning the target column should exist in the data. In 'prediction' mode, the input data files must match the training schema except that the target column is missing. Note that batch prediction can be slow on small datasets because it takes a while for a Dataflow job to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://cloud-ml-dev-census-regression-datalab/batch_prediction/errors-00000-of-00001.txt#1488570811999869...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/batch_prediction/predictions-00000-of-00003.json#1488570816925705...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/batch_prediction/predictions-00001-of-00003.json#1488570816878741...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/batch_prediction/predictions-00002-of-00003.json#1488570816826694...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/batch_prediction/tmp/staging/structured-data-batch-prediction-20170303194911.1488570551.650125/dataflow_python_sdk.tar#1488570559224650...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/batch_prediction/tmp/staging/structured-data-batch-prediction-20170303194911.1488570551.650125/sd.tar.gz#1488570555895458...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/batch_prediction/tmp/staging/structured-data-batch-prediction-20170303194911.1488570551.650125/extra_packages.txt#1488570556243581...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/batch_prediction/staging/sd.tar.gz#1488570550751594...\n",
      "/ [8/8 objects] 100% Done                                                       \n",
      "Operation completed over 8 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -r {CLOUD_BATCH_PREDICTION_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://cloud-ml-dev-census-regression-datalab/batch_prediction/staging/trainer.tar.gz\n",
      "Dataflow Job submitted, see Job mltoolbox-batch-prediction-20170306220739 at https://console.developers.google.com/dataflow?project=cloud-ml-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/apache_beam/coders/typecoders.py:136: UserWarning: Using fallback coder for typehint: Any.\n",
      "  warnings.warn('Using fallback coder for typehint: %r.' % typehint)\n",
      "WARNING:root:The .whl package \"%s\" is provided in --extra_package. This functionality is not officially supported. Since wheel packages are binary distributions, this package must be binary-compatible with the worker environment (e.g. Python 2.7 running on an x64 Linux host).\n",
      "WARNING:root:The .whl package \"%s\" is provided in --extra_package. This functionality is not officially supported. Since wheel packages are binary distributions, this package must be binary-compatible with the worker environment (e.g. Python 2.7 running on an x64 Linux host).\n"
     ]
    }
   ],
   "source": [
    "sd.batch_predict(\n",
    "  cloud=True,\n",
    "  training_dir=CLOUD_TRAINING_DIR,\n",
    "  prediction_input_file=CLOUD_EVAL_FILE,\n",
    "  output_dir=CLOUD_BATCH_PREDICTION_DIR,\n",
    "  mode='evaluation',\n",
    "  output_format='json'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When prediction is done, {CLOUD_ROOT}/batch_prediction should contain the prediction files and an errors file (that should be empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/errors-00000-of-00001.txt\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/predictions-00000-of-00003.json\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/predictions-00001-of-00003.json\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/predictions-00002-of-00003.json\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/staging/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/tmp/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls  {CLOUD_BATCH_PREDICTION_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning things up\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to delete the files you made on GCS, uncomment and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!gsutil rm -fr {CLOUD_ROOT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
