{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Sample Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# About this notebook\n",
    "\n",
    "\n",
    "This notebook uses the datalab structured data package for building and running a Tensorflow classification problems locally. This notebook uses the classic <a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\">Iris flower data set.</a>\n",
    "\n",
    "In the notebooks that follow, an example of running preprocessing, training, and prediction using the Google Cloud Machine Learning Engine services are given. Note that running the cloud versions of preprocessing, training, and prediction take longer than the local versions. The performance advantage of using the cloud applies to very large data sets, and you don't see it with this sample because the data is small and run time is dominated by setup overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting things up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the versions of datalab_structured_data and TF we have. Make sure TF and SD are 1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"oauth2client.contrib.multistore_file\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import mltoolbox.classification.dnn as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf 1.0.0\n",
      "sd 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import datalab.ml as ml\n",
    "import datalab\n",
    "import json\n",
    "import os\n",
    "print('tf ' + str(tf.__version__))\n",
    "print('sd ' + str(sd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will write files during preprocessing, training, and prediction. Please give a root folder you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Edit LOCAL_ROOT if you want to save files to a different location.\n",
    "# otherwise don't change anything is this cell. If the folder\n",
    "# already exists, it will be deleted.\n",
    "LOCAL_ROOT = './iris_notebook_workspace'\n",
    "\n",
    "# No need to edit anything else in this cell. But if you do, you \n",
    "# might need to chagne the global variables in the cloud notebooks.\n",
    "LOCAL_PREPROCESSING_DIR = os.path.join(LOCAL_ROOT, 'preprocessing')\n",
    "LOCAL_TRAINING_DIR = os.path.join(LOCAL_ROOT, 'training')\n",
    "LOCAL_BATCH_PREDICTION_DIR = os.path.join(LOCAL_ROOT, 'batch_prediction')\n",
    "\n",
    "LOCAL_TRAIN_FILE = os.path.join(LOCAL_ROOT, 'train.csv')\n",
    "LOCAL_EVAL_FILE = os.path.join(LOCAL_ROOT, 'eval.csv')\n",
    "LOCAL_PREDICT_FILE = os.path.join(LOCAL_ROOT, 'predict.csv')\n",
    "\n",
    "LOCAL_SCHEMA_FILE = os.path.join(LOCAL_ROOT, 'schema.json')\n",
    "LOCAL_FEATURES_FILE = os.path.join(LOCAL_ROOT, 'features.json')\n",
    "\n",
    "if file_io.file_exists(LOCAL_ROOT):\n",
    "  file_io.delete_recursively(LOCAL_ROOT)  \n",
    "  \n",
    "file_io.recursive_create_dir(LOCAL_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris dataset is small, so the data is embedded into this notebook. Write the iris data set into 3 files: training, eval, prediction. Note that the prediction dataset does not have target values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./iris_notebook_workspace/train.csv\n"
     ]
    }
   ],
   "source": [
    "%writefile {LOCAL_TRAIN_FILE}\n",
    "Iris-setosa,4,4.6,3.1,1.5,0.2\n",
    "Iris-setosa,20,5.1,3.8,1.5,0.3\n",
    "Iris-setosa,43,4.4,3.2,1.3,0.2\n",
    "Iris-versicolor,88,6.3,2.3,4.4,1.3\n",
    "Iris-versicolor,76,6.6,3,4.4,1.4\n",
    "Iris-versicolor,63,6,2.2,4,1\n",
    "Iris-setosa,47,5.1,3.8,1.6,0.2\n",
    "Iris-virginica,146,6.7,3,5.2,2.3\n",
    "Iris-versicolor,53,6.9,3.1,4.9,1.5\n",
    "Iris-versicolor,71,5.9,3.2,4.8,1.8\n",
    "Iris-virginica,144,6.8,3.2,5.9,2.3\n",
    "Iris-virginica,124,6.3,2.7,4.9,1.8\n",
    "Iris-virginica,122,5.6,2.8,4.9,2\n",
    "Iris-setosa,17,5.4,3.9,1.3,0.4\n",
    "Iris-setosa,7,4.6,3.4,1.4,0.3\n",
    "Iris-versicolor,87,6.7,3.1,4.7,1.5\n",
    "Iris-virginica,131,7.4,2.8,6.1,1.9\n",
    "Iris-setosa,2,4.9,3,1.4,0.2\n",
    "Iris-virginica,147,6.3,2.5,5,1.9\n",
    "Iris-setosa,29,5.2,3.4,1.4,0.2\n",
    "Iris-versicolor,91,5.5,2.6,4.4,1.2\n",
    "Iris-virginica,110,7.2,3.6,6.1,2.5\n",
    "Iris-virginica,121,6.9,3.2,5.7,2.3\n",
    "Iris-setosa,45,5.1,3.8,1.9,0.4\n",
    "Iris-setosa,10,4.9,3.1,1.5,0.1\n",
    "Iris-setosa,36,5,3.2,1.2,0.2\n",
    "Iris-virginica,112,6.4,2.7,5.3,1.9\n",
    "Iris-setosa,46,4.8,3,1.4,0.3\n",
    "Iris-virginica,132,7.9,3.8,6.4,2\n",
    "Iris-versicolor,77,6.8,2.8,4.8,1.4\n",
    "Iris-setosa,6,5.4,3.9,1.7,0.4\n",
    "Iris-versicolor,90,5.5,2.5,4,1.3\n",
    "Iris-virginica,137,6.3,3.4,5.6,2.4\n",
    "Iris-setosa,31,4.8,3.1,1.6,0.2\n",
    "Iris-virginica,120,6,2.2,5,1.5\n",
    "Iris-virginica,138,6.4,3.1,5.5,1.8\n",
    "Iris-setosa,24,5.1,3.3,1.7,0.5\n",
    "Iris-versicolor,96,5.7,3,4.2,1.2\n",
    "Iris-versicolor,68,5.8,2.7,4.1,1\n",
    "Iris-virginica,150,5.9,3,5.1,1.8\n",
    "Iris-setosa,26,5,3,1.6,0.2\n",
    "Iris-versicolor,98,6.2,2.9,4.3,1.3\n",
    "Iris-versicolor,80,5.7,2.6,3.5,1\n",
    "Iris-versicolor,72,6.1,2.8,4,1.3\n",
    "Iris-versicolor,75,6.4,2.9,4.3,1.3\n",
    "Iris-setosa,38,4.9,3.1,1.5,0.1\n",
    "Iris-setosa,35,4.9,3.1,1.5,0.1\n",
    "Iris-versicolor,89,5.6,3,4.1,1.3\n",
    "Iris-versicolor,84,6,2.7,5.1,1.6\n",
    "Iris-versicolor,51,7,3.2,4.7,1.4\n",
    "Iris-virginica,116,6.4,3.2,5.3,2.3\n",
    "Iris-versicolor,54,5.5,2.3,4,1.3\n",
    "Iris-virginica,130,7.2,3,5.8,1.6\n",
    "Iris-virginica,115,5.8,2.8,5.1,2.4\n",
    "Iris-setosa,32,5.4,3.4,1.5,0.4\n",
    "Iris-virginica,104,6.3,2.9,5.6,1.8\n",
    "Iris-versicolor,64,6.1,2.9,4.7,1.4\n",
    "Iris-setosa,18,5.1,3.5,1.4,0.3\n",
    "Iris-versicolor,66,6.7,3.1,4.4,1.4\n",
    "Iris-setosa,15,5.8,4,1.2,0.2\n",
    "Iris-versicolor,52,6.4,3.2,4.5,1.5\n",
    "Iris-virginica,103,7.1,3,5.9,2.1\n",
    "Iris-setosa,9,4.4,2.9,1.4,0.2\n",
    "Iris-versicolor,83,5.8,2.7,3.9,1.2\n",
    "Iris-virginica,135,6.1,2.6,5.6,1.4\n",
    "Iris-virginica,139,6,3,4.8,1.8\n",
    "Iris-versicolor,85,5.4,3,4.5,1.5\n",
    "Iris-virginica,106,7.6,3,6.6,2.1\n",
    "Iris-setosa,27,5,3.4,1.6,0.4\n",
    "Iris-virginica,140,6.9,3.1,5.4,2.1\n",
    "Iris-versicolor,67,5.6,3,4.5,1.5\n",
    "Iris-setosa,12,4.8,3.4,1.6,0.2\n",
    "Iris-versicolor,56,5.7,2.8,4.5,1.3\n",
    "Iris-virginica,113,6.8,3,5.5,2.1\n",
    "Iris-versicolor,62,5.9,3,4.2,1.5\n",
    "Iris-virginica,145,6.7,3.3,5.7,2.5\n",
    "Iris-virginica,111,6.5,3.2,5.1,2\n",
    "Iris-virginica,141,6.7,3.1,5.6,2.4\n",
    "Iris-setosa,34,5.5,4.2,1.4,0.2\n",
    "Iris-versicolor,81,5.5,2.4,3.8,1.1\n",
    "Iris-setosa,8,5,3.4,1.5,0.2\n",
    "Iris-virginica,129,6.4,2.8,5.6,2.1\n",
    "Iris-versicolor,57,6.3,3.3,4.7,1.6\n",
    "Iris-virginica,128,6.1,3,4.9,1.8\n",
    "Iris-virginica,119,7.7,2.6,6.9,2.3\n",
    "Iris-virginica,126,7.2,3.2,6,1.8\n",
    "Iris-versicolor,58,4.9,2.4,3.3,1\n",
    "Iris-virginica,117,6.5,3,5.5,1.8\n",
    "Iris-virginica,127,6.2,2.8,4.8,1.8\n",
    "Iris-setosa,16,5.7,4.4,1.5,0.4\n",
    "Iris-setosa,3,4.7,3.2,1.3,0.2\n",
    "Iris-virginica,108,7.3,2.9,6.3,1.8\n",
    "Iris-virginica,118,7.7,3.8,6.7,2.2\n",
    "Iris-setosa,42,4.5,2.3,1.3,0.3\n",
    "Iris-virginica,142,6.9,3.1,5.1,2.3\n",
    "Iris-setosa,14,4.3,3,1.1,0.1\n",
    "Iris-virginica,134,6.3,2.8,5.1,1.5\n",
    "Iris-versicolor,94,5,2.3,3.3,1\n",
    "Iris-setosa,19,5.7,3.8,1.7,0.3\n",
    "Iris-virginica,133,6.4,2.8,5.6,2.2\n",
    "Iris-virginica,114,5.7,2.5,5,2\n",
    "Iris-versicolor,86,6,3.4,4.5,1.6\n",
    "Iris-versicolor,93,5.8,2.6,4,1.2\n",
    "Iris-versicolor,92,6.1,3,4.6,1.4\n",
    "Iris-virginica,109,6.7,2.5,5.8,1.8\n",
    "Iris-virginica,102,5.8,2.7,5.1,1.9\n",
    "Iris-setosa,41,5,3.5,1.3,0.3\n",
    "Iris-versicolor,60,5.2,2.7,3.9,1.4\n",
    "Iris-virginica,105,6.5,3,5.8,2.2\n",
    "Iris-versicolor,65,5.6,2.9,3.6,1.3\n",
    "Iris-setosa,28,5.2,3.5,1.5,0.2\n",
    "Iris-versicolor,82,5.5,2.4,3.7,1\n",
    "Iris-setosa,25,4.8,3.4,1.9,0.2\n",
    "Iris-versicolor,79,6,2.9,4.5,1.5\n",
    "Iris-setosa,1,5.1,3.5,1.4,0.2\n",
    "Iris-versicolor,61,5,2,3.5,1\n",
    "Iris-virginica,149,6.2,3.4,5.4,2.3\n",
    "Iris-setosa,48,4.6,3.2,1.4,0.2\n",
    "Iris-setosa,22,5.1,3.7,1.5,0.4\n",
    "Iris-setosa,30,4.7,3.2,1.6,0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./iris_notebook_workspace/eval.csv\n"
     ]
    }
   ],
   "source": [
    "%writefile {LOCAL_EVAL_FILE}\n",
    "Iris-virginica,107,4.9,2.5,4.5,1.7\n",
    "Iris-versicolor,100,5.7,2.8,4.1,1.3\n",
    "Iris-versicolor,99,5.1,2.5,3,1.1\n",
    "Iris-setosa,13,4.8,3,1.4,0.1\n",
    "Iris-versicolor,70,5.6,2.5,3.9,1.1\n",
    "Iris-setosa,11,5.4,3.7,1.5,0.2\n",
    "Iris-setosa,37,5.5,3.5,1.3,0.2\n",
    "Iris-versicolor,69,6.2,2.2,4.5,1.5\n",
    "Iris-setosa,40,5.1,3.4,1.5,0.2\n",
    "Iris-virginica,101,6.3,3.3,6,2.5\n",
    "Iris-setosa,39,4.4,3,1.3,0.2\n",
    "Iris-versicolor,74,6.1,2.8,4.7,1.2\n",
    "Iris-versicolor,97,5.7,2.9,4.2,1.3\n",
    "Iris-setosa,50,5,3.3,1.4,0.2\n",
    "Iris-versicolor,95,5.6,2.7,4.2,1.3\n",
    "Iris-setosa,44,5,3.5,1.6,0.6\n",
    "Iris-virginica,123,7.7,2.8,6.7,2\n",
    "Iris-setosa,23,4.6,3.6,1,0.2\n",
    "Iris-versicolor,59,6.6,2.9,4.6,1.3\n",
    "Iris-virginica,148,6.5,3,5.2,2\n",
    "Iris-versicolor,55,6.5,2.8,4.6,1.5\n",
    "Iris-setosa,49,5.3,3.7,1.5,0.2\n",
    "Iris-versicolor,78,6.7,3,5,1.7\n",
    "Iris-versicolor,73,6.3,2.5,4.9,1.5\n",
    "Iris-virginica,136,7.7,3,6.1,2.3\n",
    "Iris-setosa,33,5.2,4.1,1.5,0.1\n",
    "Iris-virginica,125,6.7,3.3,5.7,2.1\n",
    "Iris-virginica,143,5.8,2.7,5.1,1.9\n",
    "Iris-setosa,21,5.4,3.4,1.7,0.2\n",
    "Iris-setosa,5,5,3.6,1.4,0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "hiddenCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./iris_notebook_workspace/predict.csv\n"
     ]
    }
   ],
   "source": [
    "%writefile {LOCAL_PREDICT_FILE}\n",
    "107,4.9,2.5,4.5,1.7\n",
    "100,5.7,2.8,4.1,1.3\n",
    "99,5.1,2.5,3,1.1\n",
    "13,4.8,3,1.4,0.1\n",
    "70,5.6,2.5,3.9,1.1\n",
    "11,5.4,3.7,1.5,0.2\n",
    "37,5.5,3.5,1.3,0.2\n",
    "69,6.2,2.2,4.5,1.5\n",
    "40,5.1,3.4,1.5,0.2\n",
    "101,6.3,3.3,6,2.5\n",
    "39,4.4,3,1.3,0.2\n",
    "74,6.1,2.8,4.7,1.2\n",
    "97,5.7,2.9,4.2,1.3\n",
    "50,5,3.3,1.4,0.2\n",
    "95,5.6,2.7,4.2,1.3\n",
    "44,5,3.5,1.6,0.6\n",
    "123,7.7,2.8,6.7,2\n",
    "23,4.6,3.6,1,0.2\n",
    "59,6.6,2.9,4.6,1.3\n",
    "148,6.5,3,5.2,2\n",
    "55,6.5,2.8,4.6,1.5\n",
    "49,5.3,3.7,1.5,0.2\n",
    "78,6.7,3,5,1.7\n",
    "73,6.3,2.5,4.9,1.5\n",
    "136,7.7,3,6.1,2.3\n",
    "33,5.2,4.1,1.5,0.1\n",
    "125,6.7,3.3,5.7,2.1\n",
    "143,5.8,2.7,5.1,1.9\n",
    "21,5.4,3.4,1.7,0.2\n",
    "5,5,3.6,1.4,0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local preprocessing starting from csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A schema file is used to describe each column of the csv files. It is assumed that the train, eval, and prediction csv files all have the same schema, but the prediction file has a missing target column. The format of the  schema file is a valid BigQuery table schema file. This allows BigQuery to be used later in cloud preprocessing. Only 3 BigQuery types are supported: STRING (for categorical columns) and INTEGER and FLOAT (for numerical columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schema = [\n",
    "    {\n",
    "        \"name\": \"flower\",\n",
    "        \"type\": \"STRING\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"key\",\n",
    "        \"type\": \"INTEGER\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"sepal_length\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"sepal_width\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"petal_length\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"petal_width\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    }   \n",
    "]\n",
    "\n",
    "# Write schema to a file so that the cloud notebooks can use it.\n",
    "file_io.write_string_to_file(\n",
    "  LOCAL_SCHEMA_FILE,\n",
    "  json.dumps(schema, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -fr {LOCAL_PREPROCESSING_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_csv = ml.CsvDataSet(\n",
    "  file_pattern=LOCAL_TRAIN_FILE,\n",
    "  schema=schema)\n",
    "eval_csv = ml.CsvDataSet(\n",
    "  file_pattern=LOCAL_EVAL_FILE,\n",
    "  schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job e5b7d7f6-c02d-4406-95c7-35aaf1188d59 completed"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = sd.analyze(\n",
    "  dataset=train_csv,\n",
    "  output_dir=LOCAL_PREPROCESSING_DIR,\n",
    ")\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of preprocessing is a numerical_analysis file that contains analysis from the numerical columns, and a vocab file from each categorical column. The files preoduced by preprocessing are consumed in training, and you should not have to worry about these files. Just for fun, lets look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_analysis.json  schema.json  vocab_flower.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls  {LOCAL_PREPROCESSING_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"sepal_width\": {\r\n",
      "    \"max\": 4.4,\r\n",
      "    \"mean\": 3.050833333333332,\r\n",
      "    \"min\": 2.0\r\n",
      "  },\r\n",
      "  \"petal_width\": {\r\n",
      "    \"max\": 2.5,\r\n",
      "    \"mean\": 1.2324999999999995,\r\n",
      "    \"min\": 0.1\r\n",
      "  },\r\n",
      "  \"sepal_length\": {\r\n",
      "    \"max\": 7.9,\r\n",
      "    \"mean\": 5.867500000000002,\r\n",
      "    \"min\": 4.3\r\n",
      "  },\r\n",
      "  \"key\": {\r\n",
      "    \"max\": 150.0,\r\n",
      "    \"mean\": 76.73333333333333,\r\n",
      "    \"min\": 1.0\r\n",
      "  },\r\n",
      "  \"petal_length\": {\r\n",
      "    \"max\": 6.9,\r\n",
      "    \"mean\": 3.830833333333335,\r\n",
      "    \"min\": 1.1\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat {LOCAL_PREPROCESSING_DIR}/numerical_analysis.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"type\": \"STRING\", \"name\": \"flower\"}, {\"type\": \"INTEGER\", \"name\": \"key\"}, {\"type\": \"FLOAT\", \"name\": \"sepal_length\"}, {\"type\": \"FLOAT\", \"name\": \"sepal_width\"}, {\"type\": \"FLOAT\", \"name\": \"petal_length\"}, {\"type\": \"FLOAT\", \"name\": \"petal_width\"}]"
     ]
    }
   ],
   "source": [
    "!cat {LOCAL_PREPROCESSING_DIR}/schema.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-virginica\r\n",
      "Iris-setosa\r\n",
      "Iris-versicolor"
     ]
    }
   ],
   "source": [
    "!cat {LOCAL_PREPROCESSING_DIR}/vocab_flower.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files in the output folder of preprocessing are consumed by the trainer. Training requires a transform config file to describe what transforms to apply on the data. The key and target transform are the only required transform, a default transform will be applied to every other column if it is not listed in the transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = {\n",
    "  \"sepal_length\": {\"transform\": \"scale\"},\n",
    "  \"sepal_width\": {\"transform\": \"scale\"},\n",
    "  \"key\": {\"transform\": \"key\"},\n",
    "  \"flower\": {\"transform\": \"target\"}\n",
    " }\n",
    "\n",
    "# Write the features to a file so that the cloud notebooks can use the same features.\n",
    "file_io.write_string_to_file(\n",
    "  LOCAL_FEATURES_FILE,\n",
    "  json.dumps(features, indent=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -fr {LOCAL_TRAINING_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd19ea67690>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': ''}\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:322: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /content/notebooks/tutorials/Machine Learning/structured_data/Iris Classification/iris_notebook_workspace/training/train/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.124, step = 1\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-03-03-00:54:55\n",
      "INFO:tensorflow:Finished evaluation at 2017-03-03-00:54:56\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.375, auc = 0.803711, global_step = 1, loss = 0.494178\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "INFO:tensorflow:Validation (step 100): loss = 0.494178, auc = 0.803711, global_step = 1, accuracy = 0.375\n",
      "INFO:tensorflow:global_step/sec: 68.199\n",
      "INFO:tensorflow:loss = 0.208334, step = 101\n",
      "INFO:tensorflow:global_step/sec: 334.183\n",
      "INFO:tensorflow:loss = 0.11476, step = 201\n",
      "INFO:tensorflow:global_step/sec: 308.512\n",
      "INFO:tensorflow:loss = 0.0675955, step = 301\n",
      "INFO:tensorflow:global_step/sec: 294.224\n",
      "INFO:tensorflow:loss = 0.0538032, step = 401\n",
      "INFO:tensorflow:global_step/sec: 305.388\n",
      "INFO:tensorflow:loss = 0.0387325, step = 501\n",
      "INFO:tensorflow:global_step/sec: 313.941\n",
      "INFO:tensorflow:loss = 0.111646, step = 601\n",
      "INFO:tensorflow:global_step/sec: 311.979\n",
      "INFO:tensorflow:loss = 0.0607005, step = 701\n",
      "INFO:tensorflow:global_step/sec: 299.533\n",
      "INFO:tensorflow:loss = 0.0393549, step = 801\n",
      "INFO:tensorflow:global_step/sec: 325.108\n",
      "INFO:tensorflow:loss = 0.0805399, step = 901\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /content/notebooks/tutorials/Machine Learning/structured_data/Iris Classification/iris_notebook_workspace/training/train/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0170662.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-03-03-00:55:00\n",
      "INFO:tensorflow:Finished evaluation at 2017-03-03-00:55:00\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.4375, auc = 0.992188, global_step = 1000, loss = 0.0932031\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/notebooks/tutorials/Machine Learning/structured_data/Iris Classification/iris_notebook_workspace/training/train/export/intermediate_evaluation_models/1488502501086/saved_model.pb\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/notebooks/tutorials/Machine Learning/structured_data/Iris Classification/iris_notebook_workspace/training/train/export/intermediate_prediction_models/1488502501626/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Job f6af413a-25aa-451f-82de-bdc0f3d4a640 completed"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = sd.train(\n",
    "  train_dataset=train_csv,\n",
    "  eval_dataset=eval_csv,\n",
    "  features=features,\n",
    "  analysis_output_dir=LOCAL_PREPROCESSING_DIR,\n",
    "  output_dir=LOCAL_TRAINING_DIR,\n",
    "  top_n=3,\n",
    "  layer_sizes=[10, 10],\n",
    "  max_steps=1000,\n",
    ")\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation_model  features_file.json  model  train\r\n"
     ]
    }
   ],
   "source": [
    "!ls {LOCAL_TRAINING_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local predict uses the model produced by training. The input data can be a csv string or Pandas DataFrame, but the schema must match the data set used for training, except the target column is missing. That is, if the training dataset had the values \"id,target,value1,value2\", the prediction data must be in the form \"id,value1,value2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting local prediction.\n",
      "Local prediction done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>top_1_label</th>\n",
       "      <th>top_1_score</th>\n",
       "      <th>top_2_label</th>\n",
       "      <th>top_2_score</th>\n",
       "      <th>top_3_label</th>\n",
       "      <th>top_3_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>2.896025e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.803121</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.196794</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>8.497430e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>5.577452e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key      top_1_label  top_1_score      top_2_label  top_2_score  \\\n",
       "0  101   Iris-virginica     0.999971  Iris-versicolor     0.000029   \n",
       "1  107  Iris-versicolor     0.803121   Iris-virginica     0.196794   \n",
       "2  100  Iris-versicolor     0.999803      Iris-setosa     0.000141   \n",
       "\n",
       "      top_3_label   top_3_score  \n",
       "0     Iris-setosa  2.896025e-10  \n",
       "1     Iris-setosa  8.497430e-05  \n",
       "2  Iris-virginica  5.577452e-05  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.predict(\n",
    "  cloud=False,\n",
    "  training_output_dir=LOCAL_TRAINING_DIR,\n",
    "  data=['101,6.3,3.3,6,2.5',\n",
    "        '107,4.9,2.5,4.5,1.7',\n",
    "        '100,5.7,2.8,4.1,1.3']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /tmp/tmpkjkyaL/csv_schema.json: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "cat /tmp/tmpkjkyaL/csv_schema.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting local prediction.\n",
      "Local prediction done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>top_1_label</th>\n",
       "      <th>top_1_score</th>\n",
       "      <th>top_2_label</th>\n",
       "      <th>top_2_score</th>\n",
       "      <th>top_3_label</th>\n",
       "      <th>top_3_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>2.896025e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.803121</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.196794</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>8.497430e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>5.577452e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key      top_1_label  top_1_score      top_2_label  top_2_score  \\\n",
       "0  101   Iris-virginica     0.999971  Iris-versicolor     0.000029   \n",
       "1  107  Iris-versicolor     0.803121   Iris-virginica     0.196794   \n",
       "2  100  Iris-versicolor     0.999803      Iris-setosa     0.000141   \n",
       "\n",
       "      top_3_label   top_3_score  \n",
       "0     Iris-setosa  2.896025e-10  \n",
       "1     Iris-setosa  8.497430e-05  \n",
       "2  Iris-virginica  5.577452e-05  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sd.predict(\n",
    "  cloud=False,\n",
    "  training_output_dir=LOCAL_TRAINING_DIR,\n",
    "  data=pd.DataFrame(\n",
    "    [[101,6.3,3.3,6,2.5],\n",
    "     [107,4.9,2.5,4.5,1.7],\n",
    "     [100,5.7,2.8,4.1,1.3]])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local batch prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local batch prediction runs prediction on batched input data. This is ideal if the input dataset is very large or you have limited available main memory. However, for very large datasets, it is better to run batch prediction using the Google Cloud Machine Learning Engine services. Two output formats are supported, csv and json. The output may also be shardded. Another feature of batch prediction is the option to run evaluation--prediction on data that contains the target column. Like local_predict, the input data must batch the schema used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -fr {LOCAL_BATCH_PREDICTION_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job 35b91da8-5530-44cc-b7e1-cb499d2e9579 completed"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = sd.batch_predict(\n",
    "  cloud=False,\n",
    "  training_output_dir=LOCAL_TRAINING_DIR,\n",
    "  prediction_input_file=LOCAL_EVAL_FILE,\n",
    "  output_dir=LOCAL_BATCH_PREDICTION_DIR,\n",
    "  output_format='csv',\n",
    "  mode='evaluation'\n",
    ")\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_schema.json  errors-00000-of-00001.txt  predictions-00000-of-00001.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {LOCAL_BATCH_PREDICTION_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"type\": \"INTEGER\", \r\n",
      "    \"mode\": \"NULLABLE\", \r\n",
      "    \"name\": \"key\"\r\n",
      "  }, \r\n",
      "  {\r\n",
      "    \"type\": \"STRING\", \r\n",
      "    \"mode\": \"NULLABLE\", \r\n",
      "    \"name\": \"target_from_input\"\r\n",
      "  }, \r\n",
      "  {\r\n",
      "    \"type\": \"STRING\", \r\n",
      "    \"mode\": \"NULLABLE\", \r\n",
      "    \"name\": \"top_1_label\"\r\n",
      "  }, \r\n",
      "  {\r\n",
      "    \"type\": \"FLOAT\", \r\n",
      "    \"mode\": \"NULLABLE\", \r\n",
      "    \"name\": \"top_1_score\"\r\n",
      "  }, \r\n",
      "  {\r\n",
      "    \"type\": \"STRING\", \r\n",
      "    \"mode\": \"NULLABLE\", \r\n",
      "    \"name\": \"top_2_label\"\r\n",
      "  }, \r\n",
      "  {\r\n",
      "    \"type\": \"FLOAT\", \r\n",
      "    \"mode\": \"NULLABLE\", \r\n",
      "    \"name\": \"top_2_score\"\r\n",
      "  }, \r\n",
      "  {\r\n",
      "    \"type\": \"STRING\", \r\n",
      "    \"mode\": \"NULLABLE\", \r\n",
      "    \"name\": \"top_3_label\"\r\n",
      "  }, \r\n",
      "  {\r\n",
      "    \"type\": \"FLOAT\", \r\n",
      "    \"mode\": \"NULLABLE\", \r\n",
      "    \"name\": \"top_3_score\"\r\n",
      "  }\r\n",
      "]\r\n"
     ]
    }
   ],
   "source": [
    "!cat  {LOCAL_BATCH_PREDICTION_DIR}/csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat {LOCAL_BATCH_PREDICTION_DIR}/errors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107,Iris-virginica,Iris-versicolor,0.803120791912,Iris-virginica,0.196794211864,Iris-setosa,8.49743009894e-05\r\n",
      "100,Iris-versicolor,Iris-versicolor,0.999803364277,Iris-setosa,0.000140914460644,Iris-virginica,5.57745697733e-05\r\n",
      "99,Iris-versicolor,Iris-versicolor,0.984274089336,Iris-setosa,0.015725729987,Iris-virginica,1.904159177e-07\r\n",
      "13,Iris-setosa,Iris-setosa,0.999907493591,Iris-versicolor,9.24779014895e-05,Iris-virginica,1.01339642195e-17\r\n",
      "70,Iris-versicolor,Iris-versicolor,0.999890208244,Iris-setosa,0.000102081758087,Iris-virginica,7.73878218752e-06\r\n",
      "11,Iris-setosa,Iris-setosa,0.999899029732,Iris-versicolor,0.00010092723096,Iris-virginica,4.58209462493e-18\r\n",
      "37,Iris-setosa,Iris-setosa,0.999865531921,Iris-versicolor,0.000134391040774,Iris-virginica,1.84053410383e-17\r\n",
      "69,Iris-versicolor,Iris-virginica,0.737833559513,Iris-versicolor,0.26216211915,Iris-setosa,4.2966885303e-06\r\n",
      "40,Iris-setosa,Iris-setosa,0.999894499779,Iris-versicolor,0.000105524923129,Iris-virginica,9.60426091627e-18\r\n",
      "101,Iris-virginica,Iris-virginica,0.999970793724,Iris-versicolor,2.91914202535e-05,Iris-setosa,2.89602536396e-10\r\n"
     ]
    }
   ],
   "source": [
    "!head {LOCAL_BATCH_PREDICTION_DIR}/predictions-00000*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -fr {LOCAL_BATCH_PREDICTION_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job 743d0766-90be-48af-912c-1461d71797a4 completed"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = sd.batch_predict(\n",
    "  cloud=False,\n",
    "  training_output_dir=LOCAL_TRAINING_DIR,\n",
    "  prediction_input_file=LOCAL_PREDICT_FILE,\n",
    "  output_dir=LOCAL_BATCH_PREDICTION_DIR,\n",
    "  output_format='json',\n",
    "  mode='prediction'\n",
    ")\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors-00000-of-00001.txt  predictions-00000-of-00001.json\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls {LOCAL_BATCH_PREDICTION_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"top_2_label\": \"Iris-virginica\",\"top_3_score\": 8.49743009894155e-05,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.19679421186447144,\"top_3_label\": \"Iris-setosa\",\"top_1_score\": 0.8031207919120789,\"key\": 107}\r\n",
      "{\"top_2_label\": \"Iris-setosa\",\"top_3_score\": 5.577456977334805e-05,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.00014091446064412594,\"top_3_label\": \"Iris-virginica\",\"top_1_score\": 0.999803364276886,\"key\": 100}\r\n",
      "{\"top_2_label\": \"Iris-setosa\",\"top_3_score\": 1.9041591770019295e-07,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.01572572998702526,\"top_3_label\": \"Iris-virginica\",\"top_1_score\": 0.9842740893363953,\"key\": 99}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 1.013396421949639e-17,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 9.247790148947388e-05,\"top_3_label\": \"Iris-virginica\",\"top_1_score\": 0.9999074935913086,\"key\": 13}\r\n",
      "{\"top_2_label\": \"Iris-setosa\",\"top_3_score\": 7.738782187516335e-06,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.00010208175808656961,\"top_3_label\": \"Iris-virginica\",\"top_1_score\": 0.9998902082443237,\"key\": 70}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 4.5820946249338984e-18,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 0.00010092723096022382,\"top_3_label\": \"Iris-virginica\",\"top_1_score\": 0.9998990297317505,\"key\": 11}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 1.8405341038288752e-17,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 0.00013439104077406228,\"top_3_label\": \"Iris-virginica\",\"top_1_score\": 0.9998655319213867,\"key\": 37}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 4.296688530303072e-06,\"top_1_label\": \"Iris-virginica\",\"top_2_score\": 0.26216211915016174,\"top_3_label\": \"Iris-setosa\",\"top_1_score\": 0.737833559513092,\"key\": 69}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 9.604260916274583e-18,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 0.00010552492312854156,\"top_3_label\": \"Iris-virginica\",\"top_1_score\": 0.9998944997787476,\"key\": 40}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 2.8960253639631617e-10,\"top_1_label\": \"Iris-virginica\",\"top_2_score\": 2.9191420253482647e-05,\"top_3_label\": \"Iris-setosa\",\"top_1_score\": 0.9999707937240601,\"key\": 101}\r\n"
     ]
    }
   ],
   "source": [
    "!head {LOCAL_BATCH_PREDICTION_DIR}/predictions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As everything was written to LOCAL_ROOT, we can simply remove this folder. If you want to delete those files, uncomment and run the next cell. If you want to run any Service notebook, don't delete LOCAL_ROOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!rm -fr {LOCAL_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
