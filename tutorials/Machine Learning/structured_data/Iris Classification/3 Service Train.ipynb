{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "\n",
    "\n",
    "This notebook assumes you have ran the local Iris classification notebook (\"1 Local End to End\") and you have not deleted the LOCAL_ROOT folder. In this notebook, we will use the ML Engine to train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "Setting things up\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mltoolbox.classification.dnn as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import datalab.ml as ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will write files during training. Please give a root folder you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://cloud-ml-dev-iris-classification-datalab/...\n",
      "ServiceException: 409 Bucket cloud-ml-dev-iris-classification-datalab already exists.\n"
     ]
    }
   ],
   "source": [
    "LOCAL_ROOT = './iris_notebook_workspace' # This should be the same as what was used in the local notebook\n",
    "CLOUD_ROOT = 'gs://' + datalab_project_id() + '-iris-classification-datalab' # Feel free to change this line.\n",
    "\n",
    "# No need to edit anything else in this cell.\n",
    "LOCAL_PREPROCESSING_DIR = os.path.join(LOCAL_ROOT, 'preprocessing')\n",
    "CLOUD_PREPROCESSING_DIR = os.path.join(CLOUD_ROOT, 'preprocessing')\n",
    "\n",
    "CLOUD_TRAINING_DIR = os.path.join(CLOUD_ROOT, 'cloud_training')\n",
    "\n",
    "LOCAL_TRAIN_FILE = os.path.join(LOCAL_ROOT, 'train.csv')\n",
    "CLOUD_TRAIN_FILE = os.path.join(CLOUD_ROOT, 'train.csv')\n",
    "\n",
    "LOCAL_EVAL_FILE = os.path.join(LOCAL_ROOT, 'eval.csv')\n",
    "CLOUD_EVAL_FILE = os.path.join(CLOUD_ROOT, 'eval.csv')\n",
    "\n",
    "LOCAL_SCHEMA_FILE = os.path.join(LOCAL_ROOT, 'schema.json')\n",
    "CLOUD_SCHEMA_FILE = os.path.join(CLOUD_ROOT, 'schema.json')\n",
    "\n",
    "LOCAL_FEATURES_FILE = os.path.join(LOCAL_ROOT, 'features.json')\n",
    "CLOUD_FEATURES_FILE = os.path.join(CLOUD_ROOT, 'features.json')\n",
    "\n",
    "if not file_io.file_exists(LOCAL_ROOT):\n",
    "  raise ValueError('LOCAL_ROOT not found. Did you run the local notebook?')\n",
    "  \n",
    "!gsutil mb {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us put the csv files on GCS and the output of preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./iris_notebook_workspace/train.csv [Content-Type=text/csv]...\n",
      "/ [1/1 files][  3.8 KiB/  3.8 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/3.8 KiB.                                      \n",
      "Copying file://./iris_notebook_workspace/eval.csv [Content-Type=text/csv]...\n",
      "/ [1/1 files][  973.0 B/  973.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/973.0 B.                                      \n",
      "Copying file://./iris_notebook_workspace/features.json [Content-Type=application/json]...\n",
      "/ [1/1 files][  188.0 B/  188.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/188.0 B.                                      \n",
      "Copying file://./iris_notebook_workspace/schema.json [Content-Type=application/json]...\n",
      "/ [1/1 files][  341.0 B/  341.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/341.0 B.                                      \n",
      "Copying file://./iris_notebook_workspace/preprocessing/numerical_analysis.json [Content-Type=application/json]...\n",
      "Copying file://./iris_notebook_workspace/preprocessing/vocab_flower.csv [Content-Type=text/csv]...\n",
      "Copying file://./iris_notebook_workspace/preprocessing/schema.json [Content-Type=application/json]...\n",
      "/ [3/3 files][  715.0 B/  715.0 B] 100% Done                                    \n",
      "Operation completed over 3 objects/715.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp {LOCAL_TRAIN_FILE} {CLOUD_TRAIN_FILE}\n",
    "!gsutil -m cp {LOCAL_EVAL_FILE} {CLOUD_EVAL_FILE}\n",
    "!gsutil -m cp {LOCAL_FEATURES_FILE} {CLOUD_FEATURES_FILE}\n",
    "!gsutil -m cp {LOCAL_SCHEMA_FILE} {CLOUD_SCHEMA_FILE}\n",
    "!gsutil -m cp -r {LOCAL_PREPROCESSING_DIR} {CLOUD_PREPROCESSING_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-iris-classification-datalab/eval.csv\r\n",
      "gs://cloud-ml-dev-iris-classification-datalab/features.json\r\n",
      "gs://cloud-ml-dev-iris-classification-datalab/schema.json\r\n",
      "gs://cloud-ml-dev-iris-classification-datalab/train.csv\r\n",
      "gs://cloud-ml-dev-iris-classification-datalab/cloud_preprocessing/\r\n",
      "gs://cloud-ml-dev-iris-classification-datalab/preprocessing/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training using the ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -r {CLOUD_TRAINING_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_csv = ml.CsvDataSet(\n",
    "  file_pattern=CLOUD_TRAIN_FILE,\n",
    "  schema_file=CLOUD_SCHEMA_FILE)\n",
    "eval_csv = ml.CsvDataSet(\n",
    "  file_pattern=CLOUD_EVAL_FILE,\n",
    "  schema_file=CLOUD_SCHEMA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctc = ml.CloudTrainingConfig(\n",
    "  region='us-central1',\n",
    "  scale_tier='STANDARD_1' #See https://cloud.google.com/ml/reference/rest/v1beta1/projects.jobs#ScaleTier\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://cloud-ml-dev-iris-classification-datalab/cloud_training/staging/sd.tar.gz\n",
      "Job request send. View status of job at\n",
      "https://console.developers.google.com/ml/jobs?project=cloud-ml-dev\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Job structured_data_train_170303_184356 completed"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = sd.train(\n",
    "  train_dataset=train_csv,\n",
    "  eval_dataset=eval_csv,\n",
    "  features=CLOUD_FEATURES_FILE,\n",
    "  analysis_output_dir=CLOUD_PREPROCESSING_DIR,\n",
    "  output_dir=CLOUD_TRAINING_DIR,\n",
    "  max_steps=2000,\n",
    "  layer_sizes=[5, 3, 2],\n",
    "  cloud=ctc,\n",
    ")\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training is done, {CLOUD_TRAINING_DIR} should contain the folders train, model, evaluation_model, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-iris-classification-datalab/cloud_training/evaluation_model/\r\n",
      "gs://cloud-ml-dev-iris-classification-datalab/cloud_training/model/\r\n",
      "gs://cloud-ml-dev-iris-classification-datalab/cloud_training/staging/\r\n",
      "gs://cloud-ml-dev-iris-classification-datalab/cloud_training/train/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls  {CLOUD_TRAINING_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning things up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to delete the files you made on GCS, uncomment and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!gsutil rm -fr {CLOUD_ROOT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
