{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"about\"></a>\n",
    "About this notebook\n",
    "======\n",
    "\n",
    "This notebook assumes you have ran the local Iris notebook and you have not deleted the LOCAL_ROOT folder. In this notebook, we will use batch prediction on a pre-trained Tensorflow model using Google Cloud Machine Learning Engine services. This notebook will does not assume that the notebook \"4. Iris Classification Cloud Prediction\" was executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "Setting things up\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datalab_structured_data as sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the versions of structured_data and TF we have. Make sure TF is 1.0.0, and SD is 0.0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf 1.0.0\n",
      "sd 0.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "print('tf ' + str(tf.__version__))\n",
    "print('sd ' + str(sd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will write files during prediction. Please give a root folder you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://cloud-ml-deviris-classification-datalab/...\n",
      "ServiceException: 409 Bucket cloud-ml-deviris-classification-datalab already exists.\n"
     ]
    }
   ],
   "source": [
    "LOCAL_ROOT = './iris_notebook_workspace' # This should be the same as what was used in the local iris notebook\n",
    "CLOUD_ROOT = 'gs://' + datalab_project_id() + 'iris-classification-datalab'\n",
    "\n",
    "if not file_io.file_exists(LOCAL_ROOT):\n",
    "  raise ValueError('LOCAL_ROOT not found. Did you run the local notebook?')\n",
    "!gsutil mb {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us put the csv files on GCS and the output of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: Syntax error: \"(\" unexpected\n",
      "/bin/sh: 1: Syntax error: \"(\" unexpected\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp {os.path.join(LOCAL_ROOT, '*_data.csv')} {CLOUD_ROOT}\n",
    "!gsutil -m cp -r {os.path.join(LOCAL_ROOT, 'training')} {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: \"ls\" command does not support \"file://\" URLs. Did you mean to use a gs:// URL?\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {CLOUD_ROOT}/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"local_preprocessing\"></a>\n",
    "ML Engine Batch Prediction\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch prediction has two modes. In the 'evaluation' mode, the input data is expected to 100% match the training schema, meaning the target column should exist in the data. In 'prediction' mode, the input data files must match the training schema except that the target column is missing. Note that batch prediction can be slow on small datasets because it takes a while for a Dataflow job to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: \"rm\" command does not support \"file://\" URLs. Did you mean to use a gs:// URL?\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -r {CLOUD_ROOT}/batch_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://cloud-ml-deviris-classification-datalab/batch_prediction/staging/sd.tar.gz\n",
      "Starting cloud batch prediction.\n",
      "Dataflow Job submitted, see Job structured-data-batch-prediction-20170224184750 at https://console.developers.google.com/dataflow?project=cloud-ml-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/apache_beam/coders/typecoders.py:136: UserWarning: Using fallback coder for typehint: Any.\n",
      "  warnings.warn('Using fallback coder for typehint: %r.' % typehint)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See above link for job status.\n"
     ]
    }
   ],
   "source": [
    "sd.cloud_batch_predict(\n",
    "  training_ouput_dir=os.path.join(CLOUD_ROOT, 'training'),\n",
    "  prediction_input_file=os.path.join(CLOUD_ROOT, 'eval.csv'),\n",
    "  output_dir=str(os.path.join(CLOUD_ROOT, 'batch_prediction')),\n",
    "  mode='evaluation',\n",
    "  output_format='json'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When prediction is done, {CLOUD_ROOT}/batch_prediction should contain the prediction files and an errors file (that should be empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-deviris-classification-datalab/batch_prediction/errors-00000-of-00001.txt\r\n",
      "gs://cloud-ml-deviris-classification-datalab/batch_prediction/predictions-00000-of-00003.json\r\n",
      "gs://cloud-ml-deviris-classification-datalab/batch_prediction/predictions-00001-of-00003.json\r\n",
      "gs://cloud-ml-deviris-classification-datalab/batch_prediction/predictions-00002-of-00003.json\r\n",
      "gs://cloud-ml-deviris-classification-datalab/batch_prediction/staging/\r\n",
      "gs://cloud-ml-deviris-classification-datalab/batch_prediction/tmp/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls  {CLOUD_ROOT}/batch_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!gsutil cat gs://cloud-ml-deviris-classification-datalab/batch_prediction/errors-00000-of-00001.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 2.0761335690622218e-05,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 0.017889974638819695,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"Iris-setosa\",\"top_1_score\": 0.9820892810821533,\"key_from_input\": 39}\r\n",
      "{\"top_2_label\": \"Iris-virginica\",\"top_3_score\": 0.002998097101226449,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.17065127193927765,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"Iris-versicolor\",\"top_1_score\": 0.8263506889343262,\"key_from_input\": 74}\r\n",
      "{\"top_2_label\": \"Iris-virginica\",\"top_3_score\": 0.017729466781020164,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.161696195602417,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"Iris-versicolor\",\"top_1_score\": 0.8205742835998535,\"key_from_input\": 97}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 6.431270594475791e-05,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 0.0320427305996418,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"Iris-setosa\",\"top_1_score\": 0.9678930640220642,\"key_from_input\": 50}\r\n",
      "{\"top_2_label\": \"Iris-virginica\",\"top_3_score\": 0.012133738957345486,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.16165784001350403,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"Iris-versicolor\",\"top_1_score\": 0.8262084126472473,\"key_from_input\": 95}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 0.0002391392335994169,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 0.03061252273619175,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"Iris-setosa\",\"top_1_score\": 0.9691483378410339,\"key_from_input\": 44}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 1.8489404851607105e-07,\"top_1_label\": \"Iris-virginica\",\"top_2_score\": 0.04918140918016434,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"Iris-virginica\",\"top_1_score\": 0.9508183002471924,\"key_from_input\": 123}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 3.519561687426176e-06,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 0.0031114264857023954,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"Iris-setosa\",\"top_1_score\": 0.9968850016593933,\"key_from_input\": 23}\r\n",
      "{\"top_2_label\": \"Iris-virginica\",\"top_3_score\": 0.0010347787756472826,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.3535001873970032,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"Iris-versicolor\",\"top_1_score\": 0.6454650163650513,\"key_from_input\": 59}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 0.00011158420966239646,\"top_1_label\": \"Iris-virginica\",\"top_2_score\": 0.15015801787376404,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"Iris-virginica\",\"top_1_score\": 0.849730372428894,\"key_from_input\": 148}\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat gs://cloud-ml-deviris-classification-datalab/batch_prediction/predictions-00000-of-00003.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning things up\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to delete the files you made on GCS, uncomment and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!gsutil rm -fr {CLOUD_ROOT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
