{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"about\"></a>\n",
    "About this notebook\n",
    "======\n",
    "\n",
    "This notebook assumes you have ran the local Census Regression notebook and you have not deleted the LOCAL_ROOT folder. In this notebook, we will use BigQuery to preprocess the data files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "Setting things up\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datalab_structured_data as sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the versions of structured_data and TF we have. Make sure TF is 1.0.0, and SD is 0.0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf 1.0.0\n",
      "sd 0.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "import datalab.ml as ml\n",
    "\n",
    "print('tf ' + str(tf.__version__))\n",
    "print('sd ' + str(sd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will write files during preprocessing. Please give a root folder you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://cloud-ml-dev-census-regression-datalab/...\n",
      "ServiceException: 409 Bucket cloud-ml-dev-census-regression-datalab already exists.\n"
     ]
    }
   ],
   "source": [
    "LOCAL_ROOT = './census_regression_workspace' # This should be the same as what was used in the local census notebook\n",
    "CLOUD_ROOT = 'gs://' + datalab_project_id() + '-census-regression-datalab'\n",
    "\n",
    "if not file_io.file_exists(LOCAL_ROOT):\n",
    "  raise ValueError('LOCAL_ROOT not found. Did you run the local notebook?')\n",
    "!gsutil mb {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us put the csv files on GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./census_regression_workspace/eval_data.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/predict_data.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/train_data.csv [Content-Type=text/csv]...\n",
      "- [3 files][200.1 KiB/200.1 KiB]                                                \n",
      "Operation completed over 3 objects/200.1 KiB.                                    \n",
      "Copying file://./census_regression_workspace/schema.json [Content-Type=application/json]...\n",
      "/ [1 files][  1.4 KiB/  1.4 KiB]                                                \n",
      "Operation completed over 1 objects/1.4 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {os.path.join(LOCAL_ROOT, '*_data.csv')} {CLOUD_ROOT}\n",
    "!gsutil cp {os.path.join(LOCAL_ROOT, 'schema.json')} {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"local_preprocessing\"></a>\n",
    "Preprocessing with BigQuery starting from csv files on GCS\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/numerical_analysis.json#1487874068723727...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/schema.json#1487874111183352...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_AGEP.csv#1487874073942074...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_COW.csv#1487874076399053...\n",
      "/ [4 objects]                                                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m -o ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_ESP.csv#1487874078769735...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_ESR.csv#1487874081184682...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_FOD1P.csv#1487874083738293...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_HINS4.csv#1487874085912585...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_INDP.csv#1487874087780713...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_JWMNP.csv#1487874089886243...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_JWTR.csv#1487874091817672...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_MAR.csv#1487874093846781...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_POWPUMA.csv#1487874097504803...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_PUMA.csv#1487874099366372...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_RAC1P.csv#1487874101130129...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SCHL.csv#1487874103706053...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SCIENGRLP.csv#1487874105761576...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SERIALNO.csv#1487874071086847...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SEX.csv#1487874107845908...\n",
      "Removing gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_WKW.csv#1487874110502222...\n",
      "\n",
      "Operation completed over 20 objects.                                             \n"
     ]
    }
   ],
   "source": [
    "!gsutil rm -fr {CLOUD_ROOT}/preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_csv = ml.CsvDataSet(\n",
    "  file_pattern=os.path.join(CLOUD_ROOT, 'train_data.csv'),\n",
    "  schema_file=os.path.join(CLOUD_ROOT, 'schema.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cloud preprocessing.\n",
      "Track BigQuery status at\n",
      "https://bigquery.cloud.google.com/queries/cloud-ml-dev\n",
      "Running numerical analysis...done.\n",
      "Running categorical analysis...done.\n",
      "Cloud preprocessing done.\n"
     ]
    }
   ],
   "source": [
    "sd.cloud_preprocess(\n",
    "  dataset=train_csv,\n",
    "  output_dir=os.path.join(CLOUD_ROOT, 'preprocess'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of preprocessing is a numerical_analysis file that contains analysis from the numerical columns, and a vocab file from each categorical column. The files produced by preprocessing are consumed in training, and you should not have to worry about these files. Just for fun, lets look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/numerical_analysis.json\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/schema.json\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_AGEP.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_COW.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_ESP.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_ESR.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_FOD1P.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_HINS4.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_INDP.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_JWMNP.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_JWTR.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_MAR.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_POWPUMA.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_PUMA.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_RAC1P.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SCHL.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SCIENGRLP.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SERIALNO.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SEX.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_WKW.csv\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls  {CLOUD_ROOT}/preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"SERIALNO\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"FLOAT\",\r\n",
      "    \"name\": \"WAGP\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"AGEP\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"COW\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"ESP\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"ESR\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"FOD1P\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"HINS4\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"INDP\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"JWMNP\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"JWTR\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"MAR\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"POWPUMA\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"PUMA\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"RAC1P\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"SCHL\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"SCIENGRLP\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"SEX\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"type\": \"STRING\",\r\n",
      "    \"name\": \"WKW\",\r\n",
      "    \"mode\": \"NULLABLE\"\r\n",
      "  }\r\n",
      "]"
     ]
    }
   ],
   "source": [
    "!gsutil cat  {CLOUD_ROOT}/preprocess/schema.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning things up\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to delete the files you made on GCS, uncomment and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!gsutil rm -fr {CLOUD_ROOT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
