{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"about\"></a>\n",
    "About this notebook\n",
    "======\n",
    "\n",
    "This notebook assumes you have ran the local Census Regression notebook and you have not deleted the LOCAL_ROOT folder. In this notebook, we will train a Tensorflow model using the Google Cloud Machine Learning Engine training service. This notebook will does not assume that the notebook \"2. Census Regression Cloud Preprocessing\" was executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "Setting things up\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datalab_structured_data as sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the versions of structured_data and TF we have. Make sure TF is 1.0.0, and SD is 0.0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf 1.0.0\n",
      "sd 0.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "import datalab.ml as ml\n",
    "\n",
    "print('tf ' + str(tf.__version__))\n",
    "print('sd ' + str(sd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will write files during training. Please give a root folder you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://cloud-ml-dev-census-regression-datalab/...\n",
      "ServiceException: 409 Bucket cloud-ml-dev-census-regression-datalab already exists.\n"
     ]
    }
   ],
   "source": [
    "LOCAL_ROOT = './census_regression_workspace' # This should be the same as what was used in the local census notebook\n",
    "CLOUD_ROOT = 'gs://' + datalab_project_id() + '-census-regression-datalab'\n",
    "\n",
    "if not file_io.file_exists(LOCAL_ROOT):\n",
    "  raise ValueError('LOCAL_ROOT not found. Did you run the local notebook?')\n",
    "!gsutil mb {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us put the csv files on GCS and the output of preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./census_regression_workspace/predict_data.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/train_data.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/eval_data.csv [Content-Type=text/csv]...\n",
      "/ [3/3 files][200.1 KiB/200.1 KiB] 100% Done                                    \n",
      "Operation completed over 3 objects/200.1 KiB.                                    \n",
      "Copying file://./census_regression_workspace/schema.json [Content-Type=application/json]...\n",
      "/ [1 files][  1.4 KiB/  1.4 KiB]                                                \n",
      "Operation completed over 1 objects/1.4 KiB.                                      \n",
      "Copying file://./census_regression_workspace/transforms.json [Content-Type=application/json]...\n",
      "/ [1 files][  1.0 KiB/  1.0 KiB]                                                \n",
      "Operation completed over 1 objects/1.0 KiB.                                      \n",
      "Copying file://./census_regression_workspace/preprocess/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_COW.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_HINS4.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_ESP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_AGEP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_SEX.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_PUMA.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_RAC1P.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_ESR.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_JWTR.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_SCIENGRLP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_SCHL.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_INDP.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_SERIALNO.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_FOD1P.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_POWPUMA.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_WKW.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/numerical_analysis.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_MAR.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/preprocess/vocab_JWMNP.csv [Content-Type=text/csv]...\n",
      "-\n",
      "Operation completed over 20 objects/17.2 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp {os.path.join(LOCAL_ROOT, '*_data.csv')} {CLOUD_ROOT}\n",
    "!gsutil cp {os.path.join(LOCAL_ROOT, 'schema.json')} {CLOUD_ROOT}\n",
    "!gsutil cp {os.path.join(LOCAL_ROOT, 'transforms.json')} {CLOUD_ROOT}\n",
    "!gsutil -m cp -r {os.path.join(LOCAL_ROOT, 'preprocess')} {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/numerical_analysis.json\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/schema.json\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_AGEP.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_COW.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_ESP.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_ESR.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_FOD1P.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_HINS4.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_INDP.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_JWMNP.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_JWTR.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_MAR.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_POWPUMA.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_PUMA.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_RAC1P.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SCHL.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SCIENGRLP.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SERIALNO.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_SEX.csv\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/preprocess/vocab_WKW.csv\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {CLOUD_ROOT}/preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"local_preprocessing\"></a>\n",
    "Training using the ML Engine\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -r {CLOUD_ROOT}/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_csv = ml.CsvDataSet(\n",
    "  file_pattern=os.path.join(CLOUD_ROOT, 'train_data.csv'),\n",
    "  schema_file=os.path.join(CLOUD_ROOT, 'schema.json'))\n",
    "eval_csv = ml.CsvDataSet(\n",
    "  file_pattern=os.path.join(CLOUD_ROOT, 'eval_data.csv'),\n",
    "  schema_file=os.path.join(CLOUD_ROOT, 'schema.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctc = ml.CloudTrainingConfig(\n",
    "  region='us-central1',\n",
    "  scale_tier='STANDARD_1' #See https://cloud.google.com/ml/reference/rest/v1beta1/projects.jobs#ScaleTier\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://cloud-ml-dev-census-regression-datalab/training/staging/sd.tar.gz\n",
      "Job request send. View status of job at\n",
      "https://console.developers.google.com/ml/jobs?project=cloud-ml-dev\n",
      "createTime: '2017-02-23T18:27:16Z'\n",
      "jobId: structured_data_train_170223_182715\n",
      "state: QUEUED\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --train_data_paths=gs://cloud-ml-dev-census-regression-datalab/train_data.csv\n",
      "  - --eval_data_paths=gs://cloud-ml-dev-census-regression-datalab/eval_data.csv\n",
      "  - --output_path=gs://cloud-ml-dev-census-regression-datalab/training\n",
      "  - --preprocess_output_dir=gs://cloud-ml-dev-census-regression-datalab/preprocess\n",
      "  - --transforms_file=gs://cloud-ml-dev-census-regression-datalab/transforms.json\n",
      "  - --model_type=dnn_regression\n",
      "  - --max_steps=2000\n",
      "  - --train_batch_size=100\n",
      "  - --eval_batch_size=100\n",
      "  - --min_eval_frequency=100\n",
      "  - --learning_rate=0.01\n",
      "  - --epsilon=0.0005\n",
      "  - --layer_size1=5\n",
      "  - --layer_size2=5\n",
      "  - --layer_size3=5\n",
      "  packageUris:\n",
      "  - gs://cloud-ml-dev-census-regression-datalab/training/staging/sd.tar.gz\n",
      "  pythonModule: datalab_solutions.structured_data.trainer.task\n",
      "  region: us-central1\n",
      "  scaleTier: STANDARD_1\n",
      "trainingOutput: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job = sd.cloud_train(\n",
    "  train_dataset=train_csv,\n",
    "  eval_dataset=eval_csv,\n",
    "  transforms=os.path.join(CLOUD_ROOT, 'transforms.json'),\n",
    "  preprocess_output_dir=os.path.join(CLOUD_ROOT, 'preprocess'),\n",
    "  output_dir=os.path.join(CLOUD_ROOT, 'training'),\n",
    "  model_type='dnn_regression',\n",
    "  max_steps=2000,\n",
    "  layer_sizes=[5, 5, 5],\n",
    "  cloud_training_config=ctc,\n",
    ")\n",
    "job.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training is done, {CLOUD_ROOT}/training should contain the folders train, model, evaluation_model, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-census-regression-datalab/training/staging/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls  {CLOUD_ROOT}/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning things up\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to delete the files you made on GCS, uncomment and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!gsutil rm -fr {CLOUD_ROOT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
