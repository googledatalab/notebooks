{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Batch prediction and evaluation are very similar. They are based on DataFlow pipeline and CloudML provides Evaluate and Prediction DataFlow transform. Datalab can generate DataFlow pipeline code template for you, just like Preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run \"%mlalpha evaluate\" to generate input cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mlalpha evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fill in the required fields, you will have:\n",
    "```\n",
    "%%ml evaluate\n",
    "preprocessed_eval_data_path: /content/datalab/tmp/ml/iris/preprocessed/features_eval.tfrecord.Z\n",
    "metadata_path: /content/datalab/tmp/ml/iris/preprocessed/metadata.yaml\n",
    "model_dir: /content/datalab/tmp/ml/iris/model/model\n",
    "output_dir: /content/datalab/tmp/ml/iris/evaluate\n",
    "output_prediction_name: predictions\n",
    "output_score_name: scores\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the generated code. Optionally uncomment the code after the comment \"View Confusion Matrix with the following code\" to also create confusion matrix graph. Note that the confusionmatrix code is only generated if Datalab detects it is a classficiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Direct usage of TextFileSink is deprecated. Please use 'textio.WriteToText()' instead of directly instantiating a TextFileSink object.\n",
      "WARNING:root:Direct usage of TextFileSink is deprecated. Please use 'textio.WriteToText()' instead of directly instantiating a TextFileSink object.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"79b045dd-89ac-4dfe-8e76-5b1b58047ea9\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"79b045dd-89ac-4dfe-8e76-5b1b58047ea9\", [{\"y\": [\"Iris-virginica\", \"Iris-versicolor\", \"Iris-setosa\"], \"x\": [\"Iris-virginica\", \"Iris-versicolor\", \"Iris-setosa\"], \"z\": [[6, 1, 0], [3, 8, 0], [0, 0, 12]], \"type\": \"heatmap\", \"colorscale\": \"YlGnBu\"}], {\"title\": \"Confusion Matrix\", \"xaxis\": {\"title\": \"Predicted value\"}, \"yaxis\": {\"title\": \"True Value\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# header\n",
    "\"\"\"\n",
    "Following code is generated from command line:\n",
    "%%mlalpha evaluate\n",
    "preprocessed_eval_data_path: /content/datalab/tmp/ml/iris/preprocessed/features_eval.tfrecord.gz\n",
    "metadata_path: /content/datalab/tmp/ml/iris/preprocessed/metadata.yaml\n",
    "model_dir: /content/datalab/tmp/ml/iris/model/model\n",
    "output_dir: /content/datalab/tmp/ml/iris/evaluate\n",
    "output_prediction_name: predicted_index\n",
    "output_score_name: scores\n",
    "\n",
    "Please modify as appropriate!!!\n",
    "\"\"\"\n",
    "\n",
    "# imports\n",
    "import apache_beam as beam\n",
    "import google.cloud.ml as ml\n",
    "import google.cloud.ml.analysis as analysis\n",
    "import google.cloud.ml.io as io\n",
    "import json\n",
    "import os\n",
    "\n",
    "# defines\n",
    "def extract_values((example, prediction)):\n",
    "  import tensorflow as tf\n",
    "  tf_example = tf.train.Example()\n",
    "  tf_example.ParseFromString(example.values()[0])\n",
    "  feature_map = tf_example.features.feature\n",
    "  values = {'target': feature_map['species'].int64_list.value[0]}\n",
    "  values.update(prediction)\n",
    "  return values\n",
    "\n",
    "OUTPUT_DIR = '/content/datalab/tmp/ml/iris/evaluate'\n",
    "pipeline = beam.Pipeline('DirectPipelineRunner')\n",
    "\n",
    "\n",
    "# evaluation\n",
    "\n",
    "eval_features = (pipeline | 'ReadEval' >> io.LoadFeatures('/content/datalab/tmp/ml/iris/preprocessed/features_eval.tfrecord.gz'))\n",
    "trained_model = pipeline | 'LoadModel' >> io.LoadModel('/content/datalab/tmp/ml/iris/model/model')\n",
    "evaluations = (eval_features | 'Evaluate' >> ml.Evaluate(trained_model) |\n",
    "    beam.Map('ExtractEvaluationResults', extract_values))\n",
    "eval_data_sink = beam.io.TextFileSink(os.path.join(OUTPUT_DIR, 'eval'), shard_name_template='')\n",
    "evaluations | beam.io.textio.WriteToText(os.path.join(OUTPUT_DIR, 'eval'), shard_name_template='')\n",
    "\n",
    "# analysis\n",
    "def make_data_for_analysis(values):\n",
    "  return {\n",
    "      'target': values['target'],\n",
    "      'predicted': values['predicted_index'],\n",
    "      'score': values['scores'][values['predicted_index']],\n",
    "  }\n",
    "\n",
    "metadata = pipeline | io.LoadMetadata('/content/datalab/tmp/ml/iris/preprocessed/metadata.yaml')\n",
    "analysis_source = evaluations | beam.Map('CreateAnalysisSource', make_data_for_analysis)\n",
    "confusion_matrix, precision_recall, logloss = (analysis_source |\n",
    "    'Analyze Model' >> analysis.AnalyzeModel(metadata))\n",
    "confusion_matrix_file = os.path.join(OUTPUT_DIR, 'analyze_cm.json')\n",
    "confusion_matrix_sink = beam.io.TextFileSink(confusion_matrix_file, shard_name_template='')\n",
    "confusion_matrix | beam.io.Write('WriteConfusionMatrix', confusion_matrix_sink)\n",
    "\n",
    "# run pipeline\n",
    "pipeline.run()\n",
    "\n",
    "# View Confusion Matrix with the following code:\n",
    "#\n",
    "import datalab.mlalpha\n",
    "import yaml\n",
    "with ml.util._file.open_local_or_gcs(confusion_matrix_file, 'r') as f:\n",
    "  data = [yaml.load(line) for line in f.read().rstrip().split('\\n')]\n",
    "datalab.mlalpha.ConfusionMatrix([d['predicted'] for d in data],\n",
    "                           [d['target'] for d in data],\n",
    "                           [d['count'] for d in data]).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also check the eval output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'predicted_index': 1, u'predicted_label': 'versicolor', 'target': 2L, u'key': '107', u'scores': [0.00020953394414391369, 0.9861494302749634, 0.013641098514199257]}\r\n",
      "{u'predicted_index': 1, u'predicted_label': 'versicolor', 'target': 1L, u'key': '100', u'scores': [3.5766664950642735e-05, 0.9999605417251587, 3.7191889532550704e-06]}\r\n",
      "{u'predicted_index': 1, u'predicted_label': 'versicolor', 'target': 1L, u'key': '99', u'scores': [0.0016989074647426605, 0.998301088809967, 5.1294335889906506e-08]}\r\n",
      "{u'predicted_index': 0, u'predicted_label': 'setosa', 'target': 0L, u'key': '13', u'scores': [0.9999939203262329, 6.045279405952897e-06, 7.037634122755438e-16]}\r\n",
      "{u'predicted_index': 1, u'predicted_label': 'versicolor', 'target': 1L, u'key': '70', u'scores': [1.6221962141571566e-05, 0.999983549118042, 2.96937997745772e-07]}\r\n",
      "{u'predicted_index': 0, u'predicted_label': 'setosa', 'target': 0L, u'key': '11', u'scores': [0.9999990463256836, 8.985851991383242e-07, 7.794925517434922e-16]}\r\n",
      "{u'predicted_index': 0, u'predicted_label': 'setosa', 'target': 0L, u'key': '37', u'scores': [0.9999970197677612, 2.939526893896982e-06, 1.1425030267285443e-15]}\r\n",
      "{u'predicted_index': 2, u'predicted_label': 'virginica', 'target': 1L, u'key': '69', u'scores': [0.00010263374861096963, 0.354478120803833, 0.6454192399978638]}\r\n",
      "{u'predicted_index': 0, u'predicted_label': 'setosa', 'target': 0L, u'key': '40', u'scores': [0.9999971389770508, 2.893468490583473e-06, 1.4014270226605542e-15]}\r\n",
      "{u'predicted_index': 2, u'predicted_label': 'virginica', 'target': 2L, u'key': '101', u'scores': [6.003609831495282e-10, 4.572869194419127e-09, 1.0]}\r\n"
     ]
    }
   ],
   "source": [
    "!head /content/datalab/tmp/ml/iris/evaluate/eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a pipeline that runs in cloud, simply run \"%mlalpha evaluate --cloud\". Also all paths need to be GCS paths. Let's define the variables first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "bucket = 'gs://' + datalab_project_id() + '-sampledata'\n",
    "eval_data_path = os.path.join(bucket, 'iris', 'preprocessed', 'features_eval.tfrecord.gz')\n",
    "metadata_path = os.path.join(bucket, 'iris', 'preprocessed', 'metadata.yaml')\n",
    "model_path = os.path.join(bucket, 'iris', 'trained', 'model')\n",
    "output_dir = os.path.join(bucket, 'iris', 'evaluate')\n",
    "eval_file = os.path.join(output_dir, 'eval*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then copy the following to generate the Cloud DataFlow pipeline. Note that we don't provide \"output_prediction_name\" this time, so the generated pipeline code does not include eval analysis.\n",
    "```\n",
    "%%mlalpha evaluate --cloud\n",
    "preprocessed_eval_data_path: $eval_data_path\n",
    "metadata_path: $metadata_path\n",
    "model_dir: $model_path\n",
    "output_dir: $output_dir\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Direct usage of TextFileSink is deprecated. Please use 'textio.WriteToText()' instead of directly instantiating a TextFileSink object.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DataflowPipelineResult <Job\n",
       " id: u'2016-09-28_23_36_18-16258675668926611840'\n",
       " projectId: u'cloud-ml-test-automated'\n",
       " steps: []\n",
       " tempFiles: []\n",
       " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)> at 0x7ff47804bb50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# header\n",
    "\"\"\"\n",
    "Following code is generated from command line:\n",
    "%%mlalpha evaluate --cloud\n",
    "preprocessed_eval_data_path: $eval_data_path\n",
    "metadata_path: $metadata_path\n",
    "model_dir: $model_path\n",
    "output_dir: $output_dir\n",
    "\n",
    "Please modify as appropriate!!!\n",
    "\"\"\"\n",
    "\n",
    "# imports\n",
    "import apache_beam as beam\n",
    "import google.cloud.ml as ml\n",
    "import google.cloud.ml.analysis as analysis\n",
    "import google.cloud.ml.io as io\n",
    "import json\n",
    "import os\n",
    "\n",
    "# defines\n",
    "def extract_values((example, prediction)):\n",
    "  import tensorflow as tf\n",
    "  tf_example = tf.train.Example()\n",
    "  tf_example.ParseFromString(example.values()[0])\n",
    "  feature_map = tf_example.features.feature\n",
    "  values = {'target': feature_map['species'].int64_list.value[0]}\n",
    "  values.update(prediction)\n",
    "  return values\n",
    "\n",
    "OUTPUT_DIR = 'gs://cloud-ml-test-automated-sampledata/iris/evaluate'\n",
    "import datetime\n",
    "options = {\n",
    "    'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "    'job_name': 'evaluate' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S'),\n",
    "    'project': 'cloud-ml-test-automated',\n",
    "    'extra_packages': ['gs://cloud-ml/sdk/cloudml-0.1.6-alpha.tar.gz'],\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'no_save_main_session': True\n",
    "}\n",
    "opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "pipeline = beam.Pipeline('DataflowPipelineRunner', options=opts)\n",
    "\n",
    "\n",
    "# evaluation\n",
    "\n",
    "eval_features = (pipeline | 'ReadEval' >> io.LoadFeatures('gs://cloud-ml-test-automated-sampledata/iris/preprocessed/features_eval.tfrecord.gz'))\n",
    "trained_model = pipeline | 'LoadModel' >> io.LoadModel('gs://cloud-ml-test-automated-sampledata/iris/trained/model')\n",
    "evaluations = (eval_features | 'Evaluate' >> ml.Evaluate(trained_model) |\n",
    "    beam.Map('ExtractEvaluationResults', extract_values))\n",
    "eval_data_sink = beam.io.TextFileSink(os.path.join(OUTPUT_DIR, 'eval'), shard_name_template='')\n",
    "evaluations | beam.io.textio.WriteToText(os.path.join(OUTPUT_DIR, 'eval'), shard_name_template='')\n",
    "\n",
    "# analysis\n",
    "\n",
    "# run pipeline\n",
    "pipeline.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run the above generated code, you can go to Developer Console to see the DataFlow job: https://pantheon.corp.google.com/dataflow (and select the right project). Also you can check the results as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'score': [0.9643456935882568, 0.03509025275707245, 0.000563996727578342], 'target': 0L, u'key': ['4'], u'predictions': 0}\n",
      "{u'score': [0.985572099685669, 0.013915198855102062, 0.0005126940086483955], 'target': 0L, u'key': ['20'], u'predictions': 0}\n",
      "{u'score': [0.9754565358161926, 0.024147897958755493, 0.00039562786696478724], 'target': 0L, u'key': ['43'], u'predictions': 0}\n",
      "{u'score': [0.019101984798908234, 0.7742735147476196, 0.20662443339824677], 'target': 1L, u'key': ['88'], u'predictions': 1}\n",
      "{u'score': [0.05851663649082184, 0.6017542481422424, 0.33972907066345215], 'target': 1L, u'key': ['76'], u'predictions': 1}\n",
      "{u'score': [0.038775887340307236, 0.9083987474441528, 0.05282538756728172], 'target': 1L, u'key': ['63'], u'predictions': 1}\n",
      "{u'score': [0.9870647192001343, 0.012523564510047436, 0.00041171154589392245], 'target': 0L, u'key': ['47'], u'predictions': 0}\n",
      "{u'score': [0.0019517333712428808, 0.08908909559249878, 0.9089592099189758], 'target': 2L, u'key': ['146'], u'predictions': 2}\n",
      "{u'score': [0.029388712719082832, 0.3492112159729004, 0.6214000582695007], 'target': 1L, u'key': ['53'], u'predictions': 2}\n",
      "{u'score': [0.013716676272451878, 0.33357346057891846, 0.6527097821235657], 'target': 1L, u'key': ['71'], u'predictions': 2}\n",
      "close failed in file object destructor:\n",
      "sys.excepthook is missing\n",
      "lost sys.stderr\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat $eval_file | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
