{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is still under construction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Batch prediction and evaluation are very similar. They are based on DataFlow pipeline and CloudML provides Evaluate and Prediction DataFlow transform. Datalab can generate DataFlow pipeline code template for you, just like Preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run \"%ml evaluate\" to generate input cell. After fill in the required fields, run it to generate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml evaluate\n",
    "preprocessed_eval_data_path: /content/datalab/tmp/ml/census/preprocessed/features_eval\n",
    "metadata_path: /content/datalab/tmp/ml/census/preprocessed/metadata.yaml\n",
    "model_dir: /content/datalab/tmp/ml/census/model/model\n",
    "output_dir: /content/datalab/tmp/ml/census/evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.direct_runner.DirectPipelineResult at 0x7ff3ef768b50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# header\n",
    "\"\"\"\n",
    "Following code is generated from command line:\n",
    "%%ml evaluate\n",
    "preprocessed_eval_data_path: /content/datalab/tmp/ml/census/preprocessed/features_eval\n",
    "metadata_path: /content/datalab/tmp/ml/census/preprocessed/metadata.yaml\n",
    "model_dir: /content/datalab/tmp/ml/census/model/model\n",
    "output_dir: /content/datalab/tmp/ml/census/evaluate\n",
    "\n",
    "Please modify as appropriate!!!\n",
    "\"\"\"\n",
    "\n",
    "# imports\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import fileio\n",
    "import google.cloud.ml as ml\n",
    "import google.cloud.ml.analysis as analysis\n",
    "import google.cloud.ml.dataflow.io.tfrecordio as tfrecordio\n",
    "import google.cloud.ml.io as io\n",
    "import json\n",
    "import os\n",
    "\n",
    "# defines\n",
    "def extract_values((example, prediction)):\n",
    "  import tensorflow as tf\n",
    "  tf_example = tf.train.Example()\n",
    "  tf_example.ParseFromString(example.values()[0])\n",
    "  feature_map = tf_example.features.feature\n",
    "  values = {'target': feature_map['target'].float_list.value[0]}\n",
    "  values.update(prediction)\n",
    "  return values\n",
    "\n",
    "OUTPUT_DIR = '/content/datalab/tmp/ml/census/evaluate'\n",
    "pipeline = beam.Pipeline('DirectPipelineRunner')\n",
    "\n",
    "\n",
    "# evaluation\n",
    "eval_parameters = tfrecordio.TFRecordParameters(\n",
    "    file_path_prefix='/content/datalab/tmp/ml/census/preprocessed/features_eval',\n",
    "    file_name_suffix='',\n",
    "    shard_file=False,\n",
    "    compress_file=True)\n",
    "eval_features = pipeline | io.LoadFeatures('LoadEvalFeatures', eval_parameters)\n",
    "trained_model = pipeline | io.LoadModel('LoadModel', '/content/datalab/tmp/ml/census/model/model')\n",
    "evaluations = (eval_features | ml.Evaluate(trained_model, label='Evaluate')\n",
    "    | beam.Map('ExtractEvaluationResults', extract_values))\n",
    "eval_data_sink = beam.io.TextFileSink(os.path.join(OUTPUT_DIR, 'eval'))\n",
    "evaluations | beam.Write('WriteEval', eval_data_sink)\n",
    "\n",
    "# analysis\n",
    "\n",
    "# run pipeline\n",
    "pipeline.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the output eval file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'score': [58987.35546875], 'target': 172300.0, u'key': ['705']}\r\n",
      "{u'score': [45260.84375], 'target': 28000.0, u'key': ['1204']}\r\n",
      "{u'score': [34258.0546875], 'target': 37300.0, u'key': ['1758']}\r\n",
      "{u'score': [66288.8828125], 'target': 42400.0, u'key': ['2534']}\r\n",
      "{u'score': [59149.06640625], 'target': 100000.0, u'key': ['3172']}\r\n",
      "{u'score': [63032.22265625], 'target': 53000.0, u'key': ['3823']}\r\n",
      "{u'score': [60508.41015625], 'target': 63300.0, u'key': ['4245']}\r\n",
      "{u'score': [67393.390625], 'target': 56200.0, u'key': ['4918']}\r\n",
      "{u'score': [47335.28515625], 'target': 132000.0, u'key': ['5352']}\r\n",
      "{u'score': [41844.171875], 'target': 55000.0, u'key': ['6111']}\r\n"
     ]
    }
   ],
   "source": [
    "!head /content/datalab/tmp/ml/census/evaluate/eval*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a pipeline that runs in cloud, simply add --cloud to \"%ml evaluate\". Also all paths need to be GCS paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "bucket = 'gs://' + datalab_project_id() + '-sampledata'\n",
    "eval_data_path = os.path.join(bucket, 'census', 'preprocessed', 'features_eval')\n",
    "metadata_path = os.path.join(bucket, 'census', 'preprocessed', 'metadata.yaml')\n",
    "model_path = os.path.join(bucket, 'census', 'trained', 'model')\n",
    "output_dir = os.path.join(bucket, 'census', 'evaluate')\n",
    "eval_file = os.path.join(output_dir, 'eval*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%ml evaluate --cloud\n",
    "preprocessed_eval_data_path: $eval_data_path\n",
    "metadata_path: $metadata_path\n",
    "model_dir: $model_path\n",
    "output_dir: $output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated code is like the following:\n",
    "\n",
    "```\n",
    "\n",
    "# header\n",
    "\"\"\"\n",
    "Following code is generated from command line:\n",
    "%%ml evaluate --cloud\n",
    "preprocessed_eval_data_path: $eval_data_path\n",
    "metadata_path: $metadata_path\n",
    "model_dir: $model_path\n",
    "output_dir: $output_dir\n",
    "\n",
    "Please modify as appropriate!!!\n",
    "\"\"\"\n",
    "\n",
    "# imports\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import fileio\n",
    "import google.cloud.ml as ml\n",
    "import google.cloud.ml.analysis as analysis\n",
    "import google.cloud.ml.dataflow.io.tfrecordio as tfrecordio\n",
    "import google.cloud.ml.io as io\n",
    "import json\n",
    "import os\n",
    "\n",
    "# defines\n",
    "def extract_values((example, prediction)):\n",
    "  import tensorflow as tf\n",
    "  tf_example = tf.train.Example()\n",
    "  tf_example.ParseFromString(example.values()[0])\n",
    "  feature_map = tf_example.features.feature\n",
    "  values = {'target': feature_map['target'].float_list.value[0]}\n",
    "  values.update(prediction)\n",
    "  return values\n",
    "\n",
    "OUTPUT_DIR = 'gs://cloud-ml-test-automated-sampledata/census/evaluate'\n",
    "import datetime\n",
    "options = {\n",
    "    'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "    'job_name': 'evaluate' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S'),\n",
    "    'project': 'cloud-ml-test-automated',\n",
    "    'extra_packages': ['gs://cloud-ml/sdk/cloudml-0.1.2.latest.tar.gz'],\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'no_save_main_session': True\n",
    "}\n",
    "opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "pipeline = beam.Pipeline('DataflowPipelineRunner', options=opts)\n",
    "\n",
    "\n",
    "# evaluation\n",
    "eval_parameters = tfrecordio.TFRecordParameters(\n",
    "    file_path_prefix='gs://cloud-ml-test-automated-sampledata/census/preprocessed/features_eval',\n",
    "    file_name_suffix='',\n",
    "    shard_file=False,\n",
    "    compress_file=True)\n",
    "eval_features = pipeline | io.LoadFeatures('LoadEvalFeatures', eval_parameters)\n",
    "trained_model = pipeline | io.LoadModel('LoadModel', 'gs://cloud-ml-test-automated-sampledata/census/trained/model')\n",
    "evaluations = (eval_features | ml.Evaluate(trained_model, label='Evaluate')\n",
    "    | beam.Map('ExtractEvaluationResults', extract_values))\n",
    "eval_data_sink = beam.io.TextFileSink(os.path.join(OUTPUT_DIR, 'eval'))\n",
    "evaluations | beam.Write('WriteEval', eval_data_sink)\n",
    "\n",
    "# analysis\n",
    "\n",
    "# run pipeline\n",
    "pipeline.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run the above generated code, you can go to Developer Console to see the DataFlow job: https://pantheon.corp.google.com/dataflow (and select the right project). Also you can check the results as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'score': [62152.2109375], 'target': 172300.0, u'key': ['705']}\r\n",
      "{u'score': [50811.1875], 'target': 28000.0, u'key': ['1204']}\r\n",
      "{u'score': [41454.01953125], 'target': 37300.0, u'key': ['1758']}\r\n",
      "{u'score': [70818.65625], 'target': 42400.0, u'key': ['2534']}\r\n",
      "{u'score': [63665.48046875], 'target': 100000.0, u'key': ['3172']}\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat $eval_file | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
